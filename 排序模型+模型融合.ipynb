{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 排序模型\n",
    "通过召回的操作， 我们已经进行了问题规模的缩减， 对于每个用户， 选择出了N篇文章作为了候选集，并基于召回的候选集构建了与用户历史相关的特征，以及用户本身的属性特征，文章本省的属性特征，以及用户与文章之间的特征，下面就是使用机器学习模型来对构造好的特征进行学习，然后对测试集进行预测，得到测试集中的每个候选集用户点击的概率，返回点击概率最大的topk个文章，作为最终的结果。\n",
    "\n",
    "排序阶段选择了三个比较有代表性的排序模型，它们分别是：\n",
    "\n",
    "1. LGB的排序模型\n",
    "2. LGB的分类模型\n",
    "3. 深度学习的分类模型DIN\n",
    "\n",
    "得到了最终的排序模型输出的结果之后，还选择了两种比较经典的模型集成的方法：\n",
    "\n",
    "1. 输出结果加权融合\n",
    "2. Staking（将模型的输出结果再使用一个简单模型进行预测）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:20:39.770642Z",
     "start_time": "2020-11-18T04:20:38.500875Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取排序特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:20:41.843180Z",
     "start_time": "2020-11-18T04:20:41.837287Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = './data_raw/'\n",
    "save_path = './tmp_results/'\n",
    "offline = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:20:53.358138Z",
     "start_time": "2020-11-18T04:20:44.232944Z"
    }
   },
   "outputs": [],
   "source": [
    "# 重新读取数据的时候，发现click_article_id是一个浮点数，所以将其转换成int类型\n",
    "trn_user_item_feats_df = pd.read_csv(save_path + 'trn_user_item_feats_df.csv')\n",
    "trn_user_item_feats_df['click_article_id'] = trn_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df = pd.read_csv(save_path + 'val_user_item_feats_df.csv')\n",
    "    val_user_item_feats_df['click_article_id'] = val_user_item_feats_df['click_article_id'].astype(int)\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "tst_user_item_feats_df = pd.read_csv(save_path + 'tst_user_item_feats_df.csv')\n",
    "tst_user_item_feats_df['click_article_id'] = tst_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "# 做特征的时候为了方便，给测试集也打上了一个无效的标签，这里直接删掉就行\n",
    "del tst_user_item_feats_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 返回排序后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:21:01.809368Z",
     "start_time": "2020-11-18T04:21:01.799641Z"
    }
   },
   "outputs": [],
   "source": [
    "def submit(recall_df, topk=5, model_name=None):\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 判断是不是每个用户都有5篇文章及以上\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    assert tmp.min() >= topk\n",
    "    \n",
    "    del recall_df['pred_score']\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    \n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    # 按照提交格式定义列名\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    \n",
    "    save_name = save_path + model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:21:04.332198Z",
     "start_time": "2020-11-18T04:21:04.325020Z"
    }
   },
   "outputs": [],
   "source": [
    "# 排序结果归一化\n",
    "def norm_sim(sim_df, weight=0.0):\n",
    "    # print(sim_df.head())\n",
    "    min_sim = sim_df.min()\n",
    "    max_sim = sim_df.max()\n",
    "    if max_sim == min_sim:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0)\n",
    "    else:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0 * (sim - min_sim) / (max_sim - min_sim))\n",
    "\n",
    "    sim_df = sim_df.apply(lambda sim: sim + weight)  # plus one\n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB排序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:21:07.787698Z",
     "start_time": "2020-11-18T04:21:07.536514Z"
    }
   },
   "outputs": [],
   "source": [
    "# 防止中间出错之后重新读取数据\n",
    "trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model = val_user_item_feats_df.copy()\n",
    "    \n",
    "tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:21:10.839656Z",
     "start_time": "2020-11-18T04:21:10.833109Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义特征列\n",
    "lgb_cols = ['sim0', 'time_diff0', 'word_diff0','sim_max', 'sim_min', 'sim_sum', \n",
    "            'sim_mean', 'score','click_size', 'time_diff_mean', 'active_level',\n",
    "            'click_environment','click_deviceGroup', 'click_os', 'click_country', \n",
    "            'click_region','click_referrer_type', 'user_time_hob1', 'user_time_hob2',\n",
    "            'words_hbo', 'category_id', 'created_at_ts','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:21:14.126608Z",
     "start_time": "2020-11-18T04:21:13.493653Z"
    }
   },
   "outputs": [],
   "source": [
    "# 排序模型分组\n",
    "trn_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "g_train = trn_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = val_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:21:16.136151Z",
     "start_time": "2020-11-18T04:21:16.124444Z"
    }
   },
   "outputs": [],
   "source": [
    "# 排序模型定义\n",
    "lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:21:22.965433Z",
     "start_time": "2020-11-18T04:21:17.799127Z"
    }
   },
   "outputs": [],
   "source": [
    "# 排序模型训练\n",
    "if offline:\n",
    "    lgb_ranker.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'], group=g_train,\n",
    "                eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                eval_group= [g_val], eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_ranker.fit(trn_user_item_feats_df[lgb_cols], trn_user_item_feats_df['label'], group=g_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:21:28.616665Z",
     "start_time": "2020-11-18T04:21:24.672280Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df['pred_score'] = lgb_ranker.predict(tst_user_item_feats_df[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "\n",
    "# 将这里的排序结果保存一份，用户后面的模型融合\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'lgb_ranker_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:21:40.253692Z",
     "start_time": "2020-11-18T04:21:30.546587Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:22:26.195838Z",
     "start_time": "2020-11-18T04:21:46.115002Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@1: 0.91205\tvalid_0's ndcg@2: 0.963487\tvalid_0's ndcg@3: 0.966062\tvalid_0's ndcg@4: 0.96646\tvalid_0's ndcg@5: 0.966537\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.91785\tvalid_0's ndcg@2: 0.966069\tvalid_0's ndcg@3: 0.968294\tvalid_0's ndcg@4: 0.968649\tvalid_0's ndcg@5: 0.968765\n",
      "[3]\tvalid_0's ndcg@1: 0.92255\tvalid_0's ndcg@2: 0.968166\tvalid_0's ndcg@3: 0.970179\tvalid_0's ndcg@4: 0.970491\tvalid_0's ndcg@5: 0.970588\n",
      "[4]\tvalid_0's ndcg@1: 0.924475\tvalid_0's ndcg@2: 0.968829\tvalid_0's ndcg@3: 0.970867\tvalid_0's ndcg@4: 0.97119\tvalid_0's ndcg@5: 0.971287\n",
      "[5]\tvalid_0's ndcg@1: 0.925025\tvalid_0's ndcg@2: 0.969127\tvalid_0's ndcg@3: 0.971114\tvalid_0's ndcg@4: 0.971427\tvalid_0's ndcg@5: 0.971514\n",
      "[6]\tvalid_0's ndcg@1: 0.9268\tvalid_0's ndcg@2: 0.969908\tvalid_0's ndcg@3: 0.971783\tvalid_0's ndcg@4: 0.972117\tvalid_0's ndcg@5: 0.972214\n",
      "[7]\tvalid_0's ndcg@1: 0.926825\tvalid_0's ndcg@2: 0.969902\tvalid_0's ndcg@3: 0.971802\tvalid_0's ndcg@4: 0.972125\tvalid_0's ndcg@5: 0.972221\n",
      "[8]\tvalid_0's ndcg@1: 0.92925\tvalid_0's ndcg@2: 0.970797\tvalid_0's ndcg@3: 0.972647\tvalid_0's ndcg@4: 0.973045\tvalid_0's ndcg@5: 0.973113\n",
      "[9]\tvalid_0's ndcg@1: 0.9301\tvalid_0's ndcg@2: 0.971126\tvalid_0's ndcg@3: 0.972989\tvalid_0's ndcg@4: 0.973366\tvalid_0's ndcg@5: 0.973433\n",
      "[10]\tvalid_0's ndcg@1: 0.9303\tvalid_0's ndcg@2: 0.971216\tvalid_0's ndcg@3: 0.973091\tvalid_0's ndcg@4: 0.973446\tvalid_0's ndcg@5: 0.973523\n",
      "[11]\tvalid_0's ndcg@1: 0.931525\tvalid_0's ndcg@2: 0.971652\tvalid_0's ndcg@3: 0.973515\tvalid_0's ndcg@4: 0.97387\tvalid_0's ndcg@5: 0.973967\n",
      "[12]\tvalid_0's ndcg@1: 0.9323\tvalid_0's ndcg@2: 0.971765\tvalid_0's ndcg@3: 0.973752\tvalid_0's ndcg@4: 0.974129\tvalid_0's ndcg@5: 0.974216\n",
      "[13]\tvalid_0's ndcg@1: 0.932125\tvalid_0's ndcg@2: 0.9717\tvalid_0's ndcg@3: 0.973663\tvalid_0's ndcg@4: 0.974082\tvalid_0's ndcg@5: 0.974131\n",
      "[14]\tvalid_0's ndcg@1: 0.933775\tvalid_0's ndcg@2: 0.972293\tvalid_0's ndcg@3: 0.974306\tvalid_0's ndcg@4: 0.974693\tvalid_0's ndcg@5: 0.974751\n",
      "[15]\tvalid_0's ndcg@1: 0.93385\tvalid_0's ndcg@2: 0.972289\tvalid_0's ndcg@3: 0.974339\tvalid_0's ndcg@4: 0.974684\tvalid_0's ndcg@5: 0.974771\n",
      "[16]\tvalid_0's ndcg@1: 0.934275\tvalid_0's ndcg@2: 0.972478\tvalid_0's ndcg@3: 0.974515\tvalid_0's ndcg@4: 0.97486\tvalid_0's ndcg@5: 0.974937\n",
      "[17]\tvalid_0's ndcg@1: 0.93405\tvalid_0's ndcg@2: 0.972395\tvalid_0's ndcg@3: 0.974432\tvalid_0's ndcg@4: 0.974766\tvalid_0's ndcg@5: 0.974853\n",
      "[18]\tvalid_0's ndcg@1: 0.934625\tvalid_0's ndcg@2: 0.97278\tvalid_0's ndcg@3: 0.974718\tvalid_0's ndcg@4: 0.975052\tvalid_0's ndcg@5: 0.97511\n",
      "[19]\tvalid_0's ndcg@1: 0.93485\tvalid_0's ndcg@2: 0.972879\tvalid_0's ndcg@3: 0.974817\tvalid_0's ndcg@4: 0.975129\tvalid_0's ndcg@5: 0.975197\n",
      "[20]\tvalid_0's ndcg@1: 0.93545\tvalid_0's ndcg@2: 0.973085\tvalid_0's ndcg@3: 0.975085\tvalid_0's ndcg@4: 0.975354\tvalid_0's ndcg@5: 0.975422\n",
      "[21]\tvalid_0's ndcg@1: 0.9359\tvalid_0's ndcg@2: 0.973267\tvalid_0's ndcg@3: 0.975279\tvalid_0's ndcg@4: 0.975527\tvalid_0's ndcg@5: 0.975595\n",
      "[22]\tvalid_0's ndcg@1: 0.9359\tvalid_0's ndcg@2: 0.973219\tvalid_0's ndcg@3: 0.975257\tvalid_0's ndcg@4: 0.975526\tvalid_0's ndcg@5: 0.975584\n",
      "[23]\tvalid_0's ndcg@1: 0.93585\tvalid_0's ndcg@2: 0.973264\tvalid_0's ndcg@3: 0.975239\tvalid_0's ndcg@4: 0.975519\tvalid_0's ndcg@5: 0.975577\n",
      "[24]\tvalid_0's ndcg@1: 0.9361\tvalid_0's ndcg@2: 0.973419\tvalid_0's ndcg@3: 0.975357\tvalid_0's ndcg@4: 0.975626\tvalid_0's ndcg@5: 0.975684\n",
      "[25]\tvalid_0's ndcg@1: 0.936375\tvalid_0's ndcg@2: 0.973474\tvalid_0's ndcg@3: 0.975436\tvalid_0's ndcg@4: 0.975716\tvalid_0's ndcg@5: 0.975774\n",
      "[26]\tvalid_0's ndcg@1: 0.936125\tvalid_0's ndcg@2: 0.973381\tvalid_0's ndcg@3: 0.975356\tvalid_0's ndcg@4: 0.975626\tvalid_0's ndcg@5: 0.975684\n",
      "[27]\tvalid_0's ndcg@1: 0.9363\tvalid_0's ndcg@2: 0.973414\tvalid_0's ndcg@3: 0.975402\tvalid_0's ndcg@4: 0.975682\tvalid_0's ndcg@5: 0.97574\n",
      "[28]\tvalid_0's ndcg@1: 0.93665\tvalid_0's ndcg@2: 0.973686\tvalid_0's ndcg@3: 0.975586\tvalid_0's ndcg@4: 0.975844\tvalid_0's ndcg@5: 0.975902\n",
      "[29]\tvalid_0's ndcg@1: 0.93695\tvalid_0's ndcg@2: 0.973828\tvalid_0's ndcg@3: 0.975715\tvalid_0's ndcg@4: 0.975963\tvalid_0's ndcg@5: 0.976021\n",
      "[30]\tvalid_0's ndcg@1: 0.93705\tvalid_0's ndcg@2: 0.973881\tvalid_0's ndcg@3: 0.975756\tvalid_0's ndcg@4: 0.976003\tvalid_0's ndcg@5: 0.976061\n",
      "[31]\tvalid_0's ndcg@1: 0.938025\tvalid_0's ndcg@2: 0.974256\tvalid_0's ndcg@3: 0.976119\tvalid_0's ndcg@4: 0.976366\tvalid_0's ndcg@5: 0.976424\n",
      "[32]\tvalid_0's ndcg@1: 0.938175\tvalid_0's ndcg@2: 0.974312\tvalid_0's ndcg@3: 0.976174\tvalid_0's ndcg@4: 0.976422\tvalid_0's ndcg@5: 0.97648\n",
      "[33]\tvalid_0's ndcg@1: 0.938775\tvalid_0's ndcg@2: 0.974564\tvalid_0's ndcg@3: 0.976402\tvalid_0's ndcg@4: 0.97665\tvalid_0's ndcg@5: 0.976708\n",
      "[34]\tvalid_0's ndcg@1: 0.93925\tvalid_0's ndcg@2: 0.97474\tvalid_0's ndcg@3: 0.976552\tvalid_0's ndcg@4: 0.976821\tvalid_0's ndcg@5: 0.976879\n",
      "[35]\tvalid_0's ndcg@1: 0.93895\tvalid_0's ndcg@2: 0.974566\tvalid_0's ndcg@3: 0.976428\tvalid_0's ndcg@4: 0.976698\tvalid_0's ndcg@5: 0.976756\n",
      "[36]\tvalid_0's ndcg@1: 0.939025\tvalid_0's ndcg@2: 0.974594\tvalid_0's ndcg@3: 0.976456\tvalid_0's ndcg@4: 0.976747\tvalid_0's ndcg@5: 0.976786\n",
      "[37]\tvalid_0's ndcg@1: 0.939925\tvalid_0's ndcg@2: 0.975005\tvalid_0's ndcg@3: 0.976792\tvalid_0's ndcg@4: 0.977094\tvalid_0's ndcg@5: 0.977132\n",
      "[38]\tvalid_0's ndcg@1: 0.940125\tvalid_0's ndcg@2: 0.975094\tvalid_0's ndcg@3: 0.976869\tvalid_0's ndcg@4: 0.977171\tvalid_0's ndcg@5: 0.977209\n",
      "[39]\tvalid_0's ndcg@1: 0.9405\tvalid_0's ndcg@2: 0.975233\tvalid_0's ndcg@3: 0.977008\tvalid_0's ndcg@4: 0.977309\tvalid_0's ndcg@5: 0.977348\n",
      "[40]\tvalid_0's ndcg@1: 0.9413\tvalid_0's ndcg@2: 0.975591\tvalid_0's ndcg@3: 0.977341\tvalid_0's ndcg@4: 0.977621\tvalid_0's ndcg@5: 0.97766\n",
      "[41]\tvalid_0's ndcg@1: 0.94155\tvalid_0's ndcg@2: 0.975715\tvalid_0's ndcg@3: 0.977427\tvalid_0's ndcg@4: 0.977718\tvalid_0's ndcg@5: 0.977757\n",
      "[42]\tvalid_0's ndcg@1: 0.94165\tvalid_0's ndcg@2: 0.975815\tvalid_0's ndcg@3: 0.97749\tvalid_0's ndcg@4: 0.97777\tvalid_0's ndcg@5: 0.977808\n",
      "[43]\tvalid_0's ndcg@1: 0.941675\tvalid_0's ndcg@2: 0.975808\tvalid_0's ndcg@3: 0.977471\tvalid_0's ndcg@4: 0.977772\tvalid_0's ndcg@5: 0.977811\n",
      "[44]\tvalid_0's ndcg@1: 0.941875\tvalid_0's ndcg@2: 0.975851\tvalid_0's ndcg@3: 0.977538\tvalid_0's ndcg@4: 0.97784\tvalid_0's ndcg@5: 0.977878\n",
      "[45]\tvalid_0's ndcg@1: 0.941875\tvalid_0's ndcg@2: 0.975851\tvalid_0's ndcg@3: 0.977563\tvalid_0's ndcg@4: 0.977843\tvalid_0's ndcg@5: 0.977882\n",
      "[46]\tvalid_0's ndcg@1: 0.94205\tvalid_0's ndcg@2: 0.975931\tvalid_0's ndcg@3: 0.977631\tvalid_0's ndcg@4: 0.977911\tvalid_0's ndcg@5: 0.97795\n",
      "[47]\tvalid_0's ndcg@1: 0.941875\tvalid_0's ndcg@2: 0.975882\tvalid_0's ndcg@3: 0.97757\tvalid_0's ndcg@4: 0.97785\tvalid_0's ndcg@5: 0.977888\n",
      "[48]\tvalid_0's ndcg@1: 0.941775\tvalid_0's ndcg@2: 0.975829\tvalid_0's ndcg@3: 0.977529\tvalid_0's ndcg@4: 0.977809\tvalid_0's ndcg@5: 0.977848\n",
      "[49]\tvalid_0's ndcg@1: 0.9425\tvalid_0's ndcg@2: 0.976081\tvalid_0's ndcg@3: 0.977806\tvalid_0's ndcg@4: 0.978075\tvalid_0's ndcg@5: 0.978114\n",
      "[50]\tvalid_0's ndcg@1: 0.94255\tvalid_0's ndcg@2: 0.976226\tvalid_0's ndcg@3: 0.977826\tvalid_0's ndcg@4: 0.978106\tvalid_0's ndcg@5: 0.978154\n",
      "[51]\tvalid_0's ndcg@1: 0.94255\tvalid_0's ndcg@2: 0.976226\tvalid_0's ndcg@3: 0.977826\tvalid_0's ndcg@4: 0.978106\tvalid_0's ndcg@5: 0.978154\n",
      "[52]\tvalid_0's ndcg@1: 0.942575\tvalid_0's ndcg@2: 0.976219\tvalid_0's ndcg@3: 0.977832\tvalid_0's ndcg@4: 0.978112\tvalid_0's ndcg@5: 0.97816\n",
      "[53]\tvalid_0's ndcg@1: 0.942475\tvalid_0's ndcg@2: 0.976198\tvalid_0's ndcg@3: 0.977798\tvalid_0's ndcg@4: 0.978078\tvalid_0's ndcg@5: 0.978126\n",
      "[54]\tvalid_0's ndcg@1: 0.94295\tvalid_0's ndcg@2: 0.976437\tvalid_0's ndcg@3: 0.977999\tvalid_0's ndcg@4: 0.978268\tvalid_0's ndcg@5: 0.978317\n",
      "[55]\tvalid_0's ndcg@1: 0.942825\tvalid_0's ndcg@2: 0.976264\tvalid_0's ndcg@3: 0.977927\tvalid_0's ndcg@4: 0.978196\tvalid_0's ndcg@5: 0.978244\n",
      "[56]\tvalid_0's ndcg@1: 0.94285\tvalid_0's ndcg@2: 0.976258\tvalid_0's ndcg@3: 0.977945\tvalid_0's ndcg@4: 0.978214\tvalid_0's ndcg@5: 0.978253\n",
      "[57]\tvalid_0's ndcg@1: 0.94325\tvalid_0's ndcg@2: 0.97639\tvalid_0's ndcg@3: 0.978065\tvalid_0's ndcg@4: 0.978355\tvalid_0's ndcg@5: 0.978394\n",
      "[58]\tvalid_0's ndcg@1: 0.943375\tvalid_0's ndcg@2: 0.976436\tvalid_0's ndcg@3: 0.978123\tvalid_0's ndcg@4: 0.978403\tvalid_0's ndcg@5: 0.978442\n",
      "[59]\tvalid_0's ndcg@1: 0.94385\tvalid_0's ndcg@2: 0.976643\tvalid_0's ndcg@3: 0.978305\tvalid_0's ndcg@4: 0.978585\tvalid_0's ndcg@5: 0.978624\n",
      "[60]\tvalid_0's ndcg@1: 0.943675\tvalid_0's ndcg@2: 0.976562\tvalid_0's ndcg@3: 0.978237\tvalid_0's ndcg@4: 0.978506\tvalid_0's ndcg@5: 0.978555\n",
      "[61]\tvalid_0's ndcg@1: 0.94365\tvalid_0's ndcg@2: 0.976585\tvalid_0's ndcg@3: 0.978247\tvalid_0's ndcg@4: 0.978505\tvalid_0's ndcg@5: 0.978554\n",
      "[62]\tvalid_0's ndcg@1: 0.944\tvalid_0's ndcg@2: 0.976745\tvalid_0's ndcg@3: 0.978383\tvalid_0's ndcg@4: 0.978641\tvalid_0's ndcg@5: 0.97869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63]\tvalid_0's ndcg@1: 0.944025\tvalid_0's ndcg@2: 0.976739\tvalid_0's ndcg@3: 0.978376\tvalid_0's ndcg@4: 0.978645\tvalid_0's ndcg@5: 0.978694\n",
      "[64]\tvalid_0's ndcg@1: 0.94375\tvalid_0's ndcg@2: 0.976621\tvalid_0's ndcg@3: 0.978271\tvalid_0's ndcg@4: 0.978541\tvalid_0's ndcg@5: 0.978589\n",
      "[65]\tvalid_0's ndcg@1: 0.94395\tvalid_0's ndcg@2: 0.976695\tvalid_0's ndcg@3: 0.978345\tvalid_0's ndcg@4: 0.978614\tvalid_0's ndcg@5: 0.978663\n",
      "[66]\tvalid_0's ndcg@1: 0.944025\tvalid_0's ndcg@2: 0.976739\tvalid_0's ndcg@3: 0.978376\tvalid_0's ndcg@4: 0.978645\tvalid_0's ndcg@5: 0.978694\n",
      "[67]\tvalid_0's ndcg@1: 0.944275\tvalid_0's ndcg@2: 0.976815\tvalid_0's ndcg@3: 0.978465\tvalid_0's ndcg@4: 0.978734\tvalid_0's ndcg@5: 0.978783\n",
      "[68]\tvalid_0's ndcg@1: 0.94445\tvalid_0's ndcg@2: 0.976848\tvalid_0's ndcg@3: 0.978536\tvalid_0's ndcg@4: 0.978794\tvalid_0's ndcg@5: 0.978843\n",
      "[69]\tvalid_0's ndcg@1: 0.9444\tvalid_0's ndcg@2: 0.97683\tvalid_0's ndcg@3: 0.978517\tvalid_0's ndcg@4: 0.978776\tvalid_0's ndcg@5: 0.978824\n",
      "[70]\tvalid_0's ndcg@1: 0.944725\tvalid_0's ndcg@2: 0.976934\tvalid_0's ndcg@3: 0.978634\tvalid_0's ndcg@4: 0.978892\tvalid_0's ndcg@5: 0.978941\n",
      "[71]\tvalid_0's ndcg@1: 0.94485\tvalid_0's ndcg@2: 0.977012\tvalid_0's ndcg@3: 0.978712\tvalid_0's ndcg@4: 0.978949\tvalid_0's ndcg@5: 0.978997\n",
      "[72]\tvalid_0's ndcg@1: 0.945125\tvalid_0's ndcg@2: 0.977113\tvalid_0's ndcg@3: 0.978813\tvalid_0's ndcg@4: 0.97905\tvalid_0's ndcg@5: 0.979098\n",
      "[73]\tvalid_0's ndcg@1: 0.945125\tvalid_0's ndcg@2: 0.977113\tvalid_0's ndcg@3: 0.978813\tvalid_0's ndcg@4: 0.97905\tvalid_0's ndcg@5: 0.979098\n",
      "[74]\tvalid_0's ndcg@1: 0.94515\tvalid_0's ndcg@2: 0.977122\tvalid_0's ndcg@3: 0.97881\tvalid_0's ndcg@4: 0.979058\tvalid_0's ndcg@5: 0.979106\n",
      "[75]\tvalid_0's ndcg@1: 0.945125\tvalid_0's ndcg@2: 0.977113\tvalid_0's ndcg@3: 0.978788\tvalid_0's ndcg@4: 0.979047\tvalid_0's ndcg@5: 0.979095\n",
      "[76]\tvalid_0's ndcg@1: 0.9451\tvalid_0's ndcg@2: 0.977088\tvalid_0's ndcg@3: 0.978776\tvalid_0's ndcg@4: 0.979034\tvalid_0's ndcg@5: 0.979082\n",
      "[77]\tvalid_0's ndcg@1: 0.94545\tvalid_0's ndcg@2: 0.977233\tvalid_0's ndcg@3: 0.978908\tvalid_0's ndcg@4: 0.979177\tvalid_0's ndcg@5: 0.979216\n",
      "[78]\tvalid_0's ndcg@1: 0.94525\tvalid_0's ndcg@2: 0.977175\tvalid_0's ndcg@3: 0.978838\tvalid_0's ndcg@4: 0.979107\tvalid_0's ndcg@5: 0.979145\n",
      "[79]\tvalid_0's ndcg@1: 0.9453\tvalid_0's ndcg@2: 0.977225\tvalid_0's ndcg@3: 0.978875\tvalid_0's ndcg@4: 0.979133\tvalid_0's ndcg@5: 0.979172\n",
      "[80]\tvalid_0's ndcg@1: 0.9453\tvalid_0's ndcg@2: 0.977209\tvalid_0's ndcg@3: 0.978884\tvalid_0's ndcg@4: 0.979132\tvalid_0's ndcg@5: 0.979171\n",
      "[81]\tvalid_0's ndcg@1: 0.94525\tvalid_0's ndcg@2: 0.977207\tvalid_0's ndcg@3: 0.978869\tvalid_0's ndcg@4: 0.979117\tvalid_0's ndcg@5: 0.979155\n",
      "[82]\tvalid_0's ndcg@1: 0.945175\tvalid_0's ndcg@2: 0.977195\tvalid_0's ndcg@3: 0.978845\tvalid_0's ndcg@4: 0.979092\tvalid_0's ndcg@5: 0.979131\n",
      "[83]\tvalid_0's ndcg@1: 0.94535\tvalid_0's ndcg@2: 0.977259\tvalid_0's ndcg@3: 0.978909\tvalid_0's ndcg@4: 0.979157\tvalid_0's ndcg@5: 0.979196\n",
      "[84]\tvalid_0's ndcg@1: 0.945325\tvalid_0's ndcg@2: 0.97725\tvalid_0's ndcg@3: 0.9789\tvalid_0's ndcg@4: 0.979148\tvalid_0's ndcg@5: 0.979186\n",
      "[85]\tvalid_0's ndcg@1: 0.945625\tvalid_0's ndcg@2: 0.977377\tvalid_0's ndcg@3: 0.979014\tvalid_0's ndcg@4: 0.979262\tvalid_0's ndcg@5: 0.9793\n",
      "[86]\tvalid_0's ndcg@1: 0.9457\tvalid_0's ndcg@2: 0.977404\tvalid_0's ndcg@3: 0.979042\tvalid_0's ndcg@4: 0.979289\tvalid_0's ndcg@5: 0.979328\n",
      "[87]\tvalid_0's ndcg@1: 0.9457\tvalid_0's ndcg@2: 0.977404\tvalid_0's ndcg@3: 0.979042\tvalid_0's ndcg@4: 0.979289\tvalid_0's ndcg@5: 0.979328\n",
      "[88]\tvalid_0's ndcg@1: 0.94585\tvalid_0's ndcg@2: 0.977538\tvalid_0's ndcg@3: 0.979113\tvalid_0's ndcg@4: 0.979361\tvalid_0's ndcg@5: 0.9794\n",
      "[89]\tvalid_0's ndcg@1: 0.946075\tvalid_0's ndcg@2: 0.977606\tvalid_0's ndcg@3: 0.979193\tvalid_0's ndcg@4: 0.979441\tvalid_0's ndcg@5: 0.97948\n",
      "[90]\tvalid_0's ndcg@1: 0.94605\tvalid_0's ndcg@2: 0.977581\tvalid_0's ndcg@3: 0.979181\tvalid_0's ndcg@4: 0.979428\tvalid_0's ndcg@5: 0.979467\n",
      "[91]\tvalid_0's ndcg@1: 0.9462\tvalid_0's ndcg@2: 0.97762\tvalid_0's ndcg@3: 0.979233\tvalid_0's ndcg@4: 0.97948\tvalid_0's ndcg@5: 0.979519\n",
      "[92]\tvalid_0's ndcg@1: 0.945975\tvalid_0's ndcg@2: 0.977553\tvalid_0's ndcg@3: 0.979153\tvalid_0's ndcg@4: 0.979401\tvalid_0's ndcg@5: 0.979439\n",
      "[93]\tvalid_0's ndcg@1: 0.94605\tvalid_0's ndcg@2: 0.977565\tvalid_0's ndcg@3: 0.979177\tvalid_0's ndcg@4: 0.979425\tvalid_0's ndcg@5: 0.979464\n",
      "[94]\tvalid_0's ndcg@1: 0.9462\tvalid_0's ndcg@2: 0.977683\tvalid_0's ndcg@3: 0.979258\tvalid_0's ndcg@4: 0.979495\tvalid_0's ndcg@5: 0.979534\n",
      "[95]\tvalid_0's ndcg@1: 0.946425\tvalid_0's ndcg@2: 0.977766\tvalid_0's ndcg@3: 0.979341\tvalid_0's ndcg@4: 0.979589\tvalid_0's ndcg@5: 0.979618\n",
      "[96]\tvalid_0's ndcg@1: 0.9465\tvalid_0's ndcg@2: 0.977794\tvalid_0's ndcg@3: 0.979382\tvalid_0's ndcg@4: 0.979618\tvalid_0's ndcg@5: 0.979648\n",
      "[97]\tvalid_0's ndcg@1: 0.9468\tvalid_0's ndcg@2: 0.977889\tvalid_0's ndcg@3: 0.979489\tvalid_0's ndcg@4: 0.979726\tvalid_0's ndcg@5: 0.979755\n",
      "[98]\tvalid_0's ndcg@1: 0.946725\tvalid_0's ndcg@2: 0.977814\tvalid_0's ndcg@3: 0.979452\tvalid_0's ndcg@4: 0.979688\tvalid_0's ndcg@5: 0.979717\n",
      "[99]\tvalid_0's ndcg@1: 0.9468\tvalid_0's ndcg@2: 0.977842\tvalid_0's ndcg@3: 0.979492\tvalid_0's ndcg@4: 0.979718\tvalid_0's ndcg@5: 0.979747\n",
      "[100]\tvalid_0's ndcg@1: 0.9469\tvalid_0's ndcg@2: 0.977879\tvalid_0's ndcg@3: 0.979529\tvalid_0's ndcg@4: 0.979755\tvalid_0's ndcg@5: 0.979784\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's ndcg@1: 0.9469\tvalid_0's ndcg@2: 0.977879\tvalid_0's ndcg@3: 0.979529\tvalid_0's ndcg@4: 0.979755\tvalid_0's ndcg@5: 0.979784\n",
      "[1]\tvalid_0's ndcg@1: 0.908725\tvalid_0's ndcg@2: 0.962433\tvalid_0's ndcg@3: 0.964758\tvalid_0's ndcg@4: 0.965221\tvalid_0's ndcg@5: 0.965318\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.9143\tvalid_0's ndcg@2: 0.965027\tvalid_0's ndcg@3: 0.967114\tvalid_0's ndcg@4: 0.967426\tvalid_0's ndcg@5: 0.967523\n",
      "[3]\tvalid_0's ndcg@1: 0.919125\tvalid_0's ndcg@2: 0.966792\tvalid_0's ndcg@3: 0.968879\tvalid_0's ndcg@4: 0.969213\tvalid_0's ndcg@5: 0.96931\n",
      "[4]\tvalid_0's ndcg@1: 0.9224\tvalid_0's ndcg@2: 0.968253\tvalid_0's ndcg@3: 0.970203\tvalid_0's ndcg@4: 0.970504\tvalid_0's ndcg@5: 0.970591\n",
      "[5]\tvalid_0's ndcg@1: 0.924275\tvalid_0's ndcg@2: 0.969071\tvalid_0's ndcg@3: 0.970921\tvalid_0's ndcg@4: 0.971233\tvalid_0's ndcg@5: 0.971311\n",
      "[6]\tvalid_0's ndcg@1: 0.925675\tvalid_0's ndcg@2: 0.969556\tvalid_0's ndcg@3: 0.971431\tvalid_0's ndcg@4: 0.971743\tvalid_0's ndcg@5: 0.971821\n",
      "[7]\tvalid_0's ndcg@1: 0.927775\tvalid_0's ndcg@2: 0.970347\tvalid_0's ndcg@3: 0.972209\tvalid_0's ndcg@4: 0.972522\tvalid_0's ndcg@5: 0.972599\n",
      "[8]\tvalid_0's ndcg@1: 0.9294\tvalid_0's ndcg@2: 0.970947\tvalid_0's ndcg@3: 0.972809\tvalid_0's ndcg@4: 0.973143\tvalid_0's ndcg@5: 0.973201\n",
      "[9]\tvalid_0's ndcg@1: 0.929875\tvalid_0's ndcg@2: 0.97109\tvalid_0's ndcg@3: 0.97299\tvalid_0's ndcg@4: 0.973313\tvalid_0's ndcg@5: 0.973372\n",
      "[10]\tvalid_0's ndcg@1: 0.93005\tvalid_0's ndcg@2: 0.971187\tvalid_0's ndcg@3: 0.973037\tvalid_0's ndcg@4: 0.97337\tvalid_0's ndcg@5: 0.973428\n",
      "[11]\tvalid_0's ndcg@1: 0.930975\tvalid_0's ndcg@2: 0.971607\tvalid_0's ndcg@3: 0.973394\tvalid_0's ndcg@4: 0.97375\tvalid_0's ndcg@5: 0.973798\n",
      "[12]\tvalid_0's ndcg@1: 0.93115\tvalid_0's ndcg@2: 0.971671\tvalid_0's ndcg@3: 0.973459\tvalid_0's ndcg@4: 0.973804\tvalid_0's ndcg@5: 0.973862\n",
      "[13]\tvalid_0's ndcg@1: 0.931175\tvalid_0's ndcg@2: 0.971507\tvalid_0's ndcg@3: 0.973432\tvalid_0's ndcg@4: 0.973787\tvalid_0's ndcg@5: 0.973836\n",
      "[14]\tvalid_0's ndcg@1: 0.9318\tvalid_0's ndcg@2: 0.971738\tvalid_0's ndcg@3: 0.973675\tvalid_0's ndcg@4: 0.97402\tvalid_0's ndcg@5: 0.974068\n",
      "[15]\tvalid_0's ndcg@1: 0.932675\tvalid_0's ndcg@2: 0.97214\tvalid_0's ndcg@3: 0.97404\tvalid_0's ndcg@4: 0.974363\tvalid_0's ndcg@5: 0.974421\n",
      "[16]\tvalid_0's ndcg@1: 0.93395\tvalid_0's ndcg@2: 0.972563\tvalid_0's ndcg@3: 0.974463\tvalid_0's ndcg@4: 0.974818\tvalid_0's ndcg@5: 0.974876\n",
      "[17]\tvalid_0's ndcg@1: 0.93385\tvalid_0's ndcg@2: 0.972542\tvalid_0's ndcg@3: 0.974442\tvalid_0's ndcg@4: 0.974786\tvalid_0's ndcg@5: 0.974844\n",
      "[18]\tvalid_0's ndcg@1: 0.934525\tvalid_0's ndcg@2: 0.972854\tvalid_0's ndcg@3: 0.974716\tvalid_0's ndcg@4: 0.975039\tvalid_0's ndcg@5: 0.975107\n",
      "[19]\tvalid_0's ndcg@1: 0.935025\tvalid_0's ndcg@2: 0.973086\tvalid_0's ndcg@3: 0.974898\tvalid_0's ndcg@4: 0.975232\tvalid_0's ndcg@5: 0.9753\n",
      "[20]\tvalid_0's ndcg@1: 0.9355\tvalid_0's ndcg@2: 0.973277\tvalid_0's ndcg@3: 0.975077\tvalid_0's ndcg@4: 0.975389\tvalid_0's ndcg@5: 0.975457\n",
      "[21]\tvalid_0's ndcg@1: 0.935825\tvalid_0's ndcg@2: 0.973428\tvalid_0's ndcg@3: 0.975216\tvalid_0's ndcg@4: 0.975517\tvalid_0's ndcg@5: 0.975585\n",
      "[22]\tvalid_0's ndcg@1: 0.936\tvalid_0's ndcg@2: 0.973461\tvalid_0's ndcg@3: 0.975249\tvalid_0's ndcg@4: 0.975561\tvalid_0's ndcg@5: 0.975639\n",
      "[23]\tvalid_0's ndcg@1: 0.93665\tvalid_0's ndcg@2: 0.973717\tvalid_0's ndcg@3: 0.975505\tvalid_0's ndcg@4: 0.975795\tvalid_0's ndcg@5: 0.975882\n",
      "[24]\tvalid_0's ndcg@1: 0.93705\tvalid_0's ndcg@2: 0.973912\tvalid_0's ndcg@3: 0.97565\tvalid_0's ndcg@4: 0.975951\tvalid_0's ndcg@5: 0.976038\n",
      "[25]\tvalid_0's ndcg@1: 0.937025\tvalid_0's ndcg@2: 0.973871\tvalid_0's ndcg@3: 0.975621\tvalid_0's ndcg@4: 0.975923\tvalid_0's ndcg@5: 0.976019\n",
      "[26]\tvalid_0's ndcg@1: 0.93695\tvalid_0's ndcg@2: 0.973828\tvalid_0's ndcg@3: 0.97559\tvalid_0's ndcg@4: 0.975892\tvalid_0's ndcg@5: 0.975998\n",
      "[27]\tvalid_0's ndcg@1: 0.936875\tvalid_0's ndcg@2: 0.973721\tvalid_0's ndcg@3: 0.975521\tvalid_0's ndcg@4: 0.975855\tvalid_0's ndcg@5: 0.975952\n",
      "[28]\tvalid_0's ndcg@1: 0.937275\tvalid_0's ndcg@2: 0.973869\tvalid_0's ndcg@3: 0.975681\tvalid_0's ndcg@4: 0.976015\tvalid_0's ndcg@5: 0.976112\n",
      "[29]\tvalid_0's ndcg@1: 0.937425\tvalid_0's ndcg@2: 0.973956\tvalid_0's ndcg@3: 0.975756\tvalid_0's ndcg@4: 0.976079\tvalid_0's ndcg@5: 0.976176\n",
      "[30]\tvalid_0's ndcg@1: 0.9375\tvalid_0's ndcg@2: 0.973999\tvalid_0's ndcg@3: 0.975787\tvalid_0's ndcg@4: 0.97611\tvalid_0's ndcg@5: 0.976207\n",
      "[31]\tvalid_0's ndcg@1: 0.937825\tvalid_0's ndcg@2: 0.974072\tvalid_0's ndcg@3: 0.975872\tvalid_0's ndcg@4: 0.976206\tvalid_0's ndcg@5: 0.976302\n",
      "[32]\tvalid_0's ndcg@1: 0.938175\tvalid_0's ndcg@2: 0.974264\tvalid_0's ndcg@3: 0.976014\tvalid_0's ndcg@4: 0.976348\tvalid_0's ndcg@5: 0.976445\n",
      "[33]\tvalid_0's ndcg@1: 0.938625\tvalid_0's ndcg@2: 0.974462\tvalid_0's ndcg@3: 0.976162\tvalid_0's ndcg@4: 0.976517\tvalid_0's ndcg@5: 0.976614\n",
      "[34]\tvalid_0's ndcg@1: 0.938775\tvalid_0's ndcg@2: 0.974564\tvalid_0's ndcg@3: 0.976239\tvalid_0's ndcg@4: 0.976595\tvalid_0's ndcg@5: 0.976692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\tvalid_0's ndcg@1: 0.939475\tvalid_0's ndcg@2: 0.974823\tvalid_0's ndcg@3: 0.97651\tvalid_0's ndcg@4: 0.976866\tvalid_0's ndcg@5: 0.976953\n",
      "[36]\tvalid_0's ndcg@1: 0.93955\tvalid_0's ndcg@2: 0.974835\tvalid_0's ndcg@3: 0.976572\tvalid_0's ndcg@4: 0.976895\tvalid_0's ndcg@5: 0.976982\n",
      "[37]\tvalid_0's ndcg@1: 0.940475\tvalid_0's ndcg@2: 0.97516\tvalid_0's ndcg@3: 0.97691\tvalid_0's ndcg@4: 0.977233\tvalid_0's ndcg@5: 0.97732\n",
      "[38]\tvalid_0's ndcg@1: 0.94035\tvalid_0's ndcg@2: 0.975114\tvalid_0's ndcg@3: 0.976877\tvalid_0's ndcg@4: 0.977189\tvalid_0's ndcg@5: 0.977276\n",
      "[39]\tvalid_0's ndcg@1: 0.94025\tvalid_0's ndcg@2: 0.975093\tvalid_0's ndcg@3: 0.976843\tvalid_0's ndcg@4: 0.977155\tvalid_0's ndcg@5: 0.977242\n",
      "[40]\tvalid_0's ndcg@1: 0.940775\tvalid_0's ndcg@2: 0.975271\tvalid_0's ndcg@3: 0.977034\tvalid_0's ndcg@4: 0.977346\tvalid_0's ndcg@5: 0.977433\n",
      "[41]\tvalid_0's ndcg@1: 0.941275\tvalid_0's ndcg@2: 0.975519\tvalid_0's ndcg@3: 0.977231\tvalid_0's ndcg@4: 0.977554\tvalid_0's ndcg@5: 0.977632\n",
      "[42]\tvalid_0's ndcg@1: 0.94105\tvalid_0's ndcg@2: 0.975483\tvalid_0's ndcg@3: 0.977158\tvalid_0's ndcg@4: 0.977481\tvalid_0's ndcg@5: 0.977558\n",
      "[43]\tvalid_0's ndcg@1: 0.941325\tvalid_0's ndcg@2: 0.975537\tvalid_0's ndcg@3: 0.97725\tvalid_0's ndcg@4: 0.977573\tvalid_0's ndcg@5: 0.97765\n",
      "[44]\tvalid_0's ndcg@1: 0.9418\tvalid_0's ndcg@2: 0.975649\tvalid_0's ndcg@3: 0.977412\tvalid_0's ndcg@4: 0.977735\tvalid_0's ndcg@5: 0.977812\n",
      "[45]\tvalid_0's ndcg@1: 0.942525\tvalid_0's ndcg@2: 0.97598\tvalid_0's ndcg@3: 0.97768\tvalid_0's ndcg@4: 0.978014\tvalid_0's ndcg@5: 0.978091\n",
      "[46]\tvalid_0's ndcg@1: 0.9426\tvalid_0's ndcg@2: 0.976008\tvalid_0's ndcg@3: 0.97772\tvalid_0's ndcg@4: 0.978043\tvalid_0's ndcg@5: 0.978121\n",
      "[47]\tvalid_0's ndcg@1: 0.942625\tvalid_0's ndcg@2: 0.975985\tvalid_0's ndcg@3: 0.977735\tvalid_0's ndcg@4: 0.978058\tvalid_0's ndcg@5: 0.978126\n",
      "[48]\tvalid_0's ndcg@1: 0.942875\tvalid_0's ndcg@2: 0.976062\tvalid_0's ndcg@3: 0.977824\tvalid_0's ndcg@4: 0.978147\tvalid_0's ndcg@5: 0.978215\n",
      "[49]\tvalid_0's ndcg@1: 0.94295\tvalid_0's ndcg@2: 0.976074\tvalid_0's ndcg@3: 0.977849\tvalid_0's ndcg@4: 0.978172\tvalid_0's ndcg@5: 0.97824\n",
      "[50]\tvalid_0's ndcg@1: 0.9429\tvalid_0's ndcg@2: 0.976071\tvalid_0's ndcg@3: 0.977834\tvalid_0's ndcg@4: 0.978157\tvalid_0's ndcg@5: 0.978224\n",
      "[51]\tvalid_0's ndcg@1: 0.94335\tvalid_0's ndcg@2: 0.9763\tvalid_0's ndcg@3: 0.978\tvalid_0's ndcg@4: 0.978334\tvalid_0's ndcg@5: 0.978411\n",
      "[52]\tvalid_0's ndcg@1: 0.943075\tvalid_0's ndcg@2: 0.976246\tvalid_0's ndcg@3: 0.977909\tvalid_0's ndcg@4: 0.978242\tvalid_0's ndcg@5: 0.97832\n",
      "[53]\tvalid_0's ndcg@1: 0.943325\tvalid_0's ndcg@2: 0.976307\tvalid_0's ndcg@3: 0.977994\tvalid_0's ndcg@4: 0.978328\tvalid_0's ndcg@5: 0.978405\n",
      "[54]\tvalid_0's ndcg@1: 0.942975\tvalid_0's ndcg@2: 0.976178\tvalid_0's ndcg@3: 0.977865\tvalid_0's ndcg@4: 0.978199\tvalid_0's ndcg@5: 0.978276\n",
      "[55]\tvalid_0's ndcg@1: 0.943225\tvalid_0's ndcg@2: 0.976286\tvalid_0's ndcg@3: 0.977948\tvalid_0's ndcg@4: 0.978293\tvalid_0's ndcg@5: 0.97837\n",
      "[56]\tvalid_0's ndcg@1: 0.94315\tvalid_0's ndcg@2: 0.976274\tvalid_0's ndcg@3: 0.977924\tvalid_0's ndcg@4: 0.978268\tvalid_0's ndcg@5: 0.978346\n",
      "[57]\tvalid_0's ndcg@1: 0.9431\tvalid_0's ndcg@2: 0.97624\tvalid_0's ndcg@3: 0.97789\tvalid_0's ndcg@4: 0.978234\tvalid_0's ndcg@5: 0.978321\n",
      "[58]\tvalid_0's ndcg@1: 0.943175\tvalid_0's ndcg@2: 0.976299\tvalid_0's ndcg@3: 0.977924\tvalid_0's ndcg@4: 0.978279\tvalid_0's ndcg@5: 0.978356\n",
      "[59]\tvalid_0's ndcg@1: 0.943025\tvalid_0's ndcg@2: 0.976228\tvalid_0's ndcg@3: 0.977865\tvalid_0's ndcg@4: 0.97822\tvalid_0's ndcg@5: 0.978298\n",
      "[60]\tvalid_0's ndcg@1: 0.942975\tvalid_0's ndcg@2: 0.976225\tvalid_0's ndcg@3: 0.977862\tvalid_0's ndcg@4: 0.978207\tvalid_0's ndcg@5: 0.978284\n",
      "[61]\tvalid_0's ndcg@1: 0.94295\tvalid_0's ndcg@2: 0.976295\tvalid_0's ndcg@3: 0.97787\tvalid_0's ndcg@4: 0.978214\tvalid_0's ndcg@5: 0.978292\n",
      "[62]\tvalid_0's ndcg@1: 0.943075\tvalid_0's ndcg@2: 0.976404\tvalid_0's ndcg@3: 0.977929\tvalid_0's ndcg@4: 0.978284\tvalid_0's ndcg@5: 0.978352\n",
      "[63]\tvalid_0's ndcg@1: 0.943575\tvalid_0's ndcg@2: 0.97651\tvalid_0's ndcg@3: 0.978085\tvalid_0's ndcg@4: 0.97844\tvalid_0's ndcg@5: 0.978517\n",
      "[64]\tvalid_0's ndcg@1: 0.943825\tvalid_0's ndcg@2: 0.976618\tvalid_0's ndcg@3: 0.97818\tvalid_0's ndcg@4: 0.978535\tvalid_0's ndcg@5: 0.978613\n",
      "[65]\tvalid_0's ndcg@1: 0.9441\tvalid_0's ndcg@2: 0.976719\tvalid_0's ndcg@3: 0.978294\tvalid_0's ndcg@4: 0.978639\tvalid_0's ndcg@5: 0.978716\n",
      "[66]\tvalid_0's ndcg@1: 0.944175\tvalid_0's ndcg@2: 0.976731\tvalid_0's ndcg@3: 0.978306\tvalid_0's ndcg@4: 0.978651\tvalid_0's ndcg@5: 0.978728\n",
      "[67]\tvalid_0's ndcg@1: 0.944425\tvalid_0's ndcg@2: 0.976807\tvalid_0's ndcg@3: 0.978407\tvalid_0's ndcg@4: 0.978741\tvalid_0's ndcg@5: 0.978819\n",
      "[68]\tvalid_0's ndcg@1: 0.944575\tvalid_0's ndcg@2: 0.976816\tvalid_0's ndcg@3: 0.978453\tvalid_0's ndcg@4: 0.978787\tvalid_0's ndcg@5: 0.978864\n",
      "[69]\tvalid_0's ndcg@1: 0.944725\tvalid_0's ndcg@2: 0.976871\tvalid_0's ndcg@3: 0.978508\tvalid_0's ndcg@4: 0.978842\tvalid_0's ndcg@5: 0.97892\n",
      "[70]\tvalid_0's ndcg@1: 0.9445\tvalid_0's ndcg@2: 0.976819\tvalid_0's ndcg@3: 0.978432\tvalid_0's ndcg@4: 0.978755\tvalid_0's ndcg@5: 0.978842\n",
      "[71]\tvalid_0's ndcg@1: 0.945\tvalid_0's ndcg@2: 0.97702\tvalid_0's ndcg@3: 0.97862\tvalid_0's ndcg@4: 0.978943\tvalid_0's ndcg@5: 0.97903\n",
      "[72]\tvalid_0's ndcg@1: 0.945075\tvalid_0's ndcg@2: 0.977063\tvalid_0's ndcg@3: 0.978651\tvalid_0's ndcg@4: 0.978974\tvalid_0's ndcg@5: 0.979061\n",
      "[73]\tvalid_0's ndcg@1: 0.94545\tvalid_0's ndcg@2: 0.977202\tvalid_0's ndcg@3: 0.978789\tvalid_0's ndcg@4: 0.979112\tvalid_0's ndcg@5: 0.979199\n",
      "[74]\tvalid_0's ndcg@1: 0.945625\tvalid_0's ndcg@2: 0.977266\tvalid_0's ndcg@3: 0.978854\tvalid_0's ndcg@4: 0.979177\tvalid_0's ndcg@5: 0.979264\n",
      "[75]\tvalid_0's ndcg@1: 0.945825\tvalid_0's ndcg@2: 0.97734\tvalid_0's ndcg@3: 0.978927\tvalid_0's ndcg@4: 0.97925\tvalid_0's ndcg@5: 0.979337\n",
      "[76]\tvalid_0's ndcg@1: 0.9465\tvalid_0's ndcg@2: 0.977589\tvalid_0's ndcg@3: 0.979189\tvalid_0's ndcg@4: 0.979512\tvalid_0's ndcg@5: 0.979589\n",
      "[77]\tvalid_0's ndcg@1: 0.946575\tvalid_0's ndcg@2: 0.977617\tvalid_0's ndcg@3: 0.979217\tvalid_0's ndcg@4: 0.97954\tvalid_0's ndcg@5: 0.979617\n",
      "[78]\tvalid_0's ndcg@1: 0.946525\tvalid_0's ndcg@2: 0.977661\tvalid_0's ndcg@3: 0.979199\tvalid_0's ndcg@4: 0.979543\tvalid_0's ndcg@5: 0.979611\n",
      "[79]\tvalid_0's ndcg@1: 0.9466\tvalid_0's ndcg@2: 0.977673\tvalid_0's ndcg@3: 0.979236\tvalid_0's ndcg@4: 0.97958\tvalid_0's ndcg@5: 0.979638\n",
      "[80]\tvalid_0's ndcg@1: 0.946725\tvalid_0's ndcg@2: 0.977719\tvalid_0's ndcg@3: 0.979294\tvalid_0's ndcg@4: 0.979628\tvalid_0's ndcg@5: 0.979686\n",
      "[81]\tvalid_0's ndcg@1: 0.94715\tvalid_0's ndcg@2: 0.977876\tvalid_0's ndcg@3: 0.979439\tvalid_0's ndcg@4: 0.979773\tvalid_0's ndcg@5: 0.97985\n",
      "[82]\tvalid_0's ndcg@1: 0.9472\tvalid_0's ndcg@2: 0.977847\tvalid_0's ndcg@3: 0.979435\tvalid_0's ndcg@4: 0.979769\tvalid_0's ndcg@5: 0.979846\n",
      "[83]\tvalid_0's ndcg@1: 0.947275\tvalid_0's ndcg@2: 0.977891\tvalid_0's ndcg@3: 0.979466\tvalid_0's ndcg@4: 0.9798\tvalid_0's ndcg@5: 0.979877\n",
      "[84]\tvalid_0's ndcg@1: 0.947125\tvalid_0's ndcg@2: 0.977851\tvalid_0's ndcg@3: 0.979414\tvalid_0's ndcg@4: 0.979748\tvalid_0's ndcg@5: 0.979825\n",
      "[85]\tvalid_0's ndcg@1: 0.94735\tvalid_0's ndcg@2: 0.977934\tvalid_0's ndcg@3: 0.979522\tvalid_0's ndcg@4: 0.979845\tvalid_0's ndcg@5: 0.979922\n",
      "[86]\tvalid_0's ndcg@1: 0.947375\tvalid_0's ndcg@2: 0.977928\tvalid_0's ndcg@3: 0.97954\tvalid_0's ndcg@4: 0.979863\tvalid_0's ndcg@5: 0.979931\n",
      "[87]\tvalid_0's ndcg@1: 0.9474\tvalid_0's ndcg@2: 0.977953\tvalid_0's ndcg@3: 0.979565\tvalid_0's ndcg@4: 0.979878\tvalid_0's ndcg@5: 0.979945\n",
      "[88]\tvalid_0's ndcg@1: 0.94775\tvalid_0's ndcg@2: 0.978098\tvalid_0's ndcg@3: 0.979698\tvalid_0's ndcg@4: 0.98001\tvalid_0's ndcg@5: 0.980078\n",
      "[89]\tvalid_0's ndcg@1: 0.947875\tvalid_0's ndcg@2: 0.97816\tvalid_0's ndcg@3: 0.979735\tvalid_0's ndcg@4: 0.980058\tvalid_0's ndcg@5: 0.980125\n",
      "[90]\tvalid_0's ndcg@1: 0.94785\tvalid_0's ndcg@2: 0.978135\tvalid_0's ndcg@3: 0.97971\tvalid_0's ndcg@4: 0.980033\tvalid_0's ndcg@5: 0.9801\n",
      "[91]\tvalid_0's ndcg@1: 0.94805\tvalid_0's ndcg@2: 0.978208\tvalid_0's ndcg@3: 0.979783\tvalid_0's ndcg@4: 0.980106\tvalid_0's ndcg@5: 0.980174\n",
      "[92]\tvalid_0's ndcg@1: 0.94805\tvalid_0's ndcg@2: 0.978208\tvalid_0's ndcg@3: 0.979783\tvalid_0's ndcg@4: 0.980106\tvalid_0's ndcg@5: 0.980174\n",
      "[93]\tvalid_0's ndcg@1: 0.947975\tvalid_0's ndcg@2: 0.978181\tvalid_0's ndcg@3: 0.979756\tvalid_0's ndcg@4: 0.980079\tvalid_0's ndcg@5: 0.980146\n",
      "[94]\tvalid_0's ndcg@1: 0.9481\tvalid_0's ndcg@2: 0.978227\tvalid_0's ndcg@3: 0.979814\tvalid_0's ndcg@4: 0.980127\tvalid_0's ndcg@5: 0.980194\n",
      "[95]\tvalid_0's ndcg@1: 0.948175\tvalid_0's ndcg@2: 0.978239\tvalid_0's ndcg@3: 0.979826\tvalid_0's ndcg@4: 0.980149\tvalid_0's ndcg@5: 0.980217\n",
      "[96]\tvalid_0's ndcg@1: 0.9483\tvalid_0's ndcg@2: 0.978316\tvalid_0's ndcg@3: 0.979879\tvalid_0's ndcg@4: 0.980202\tvalid_0's ndcg@5: 0.98027\n",
      "[97]\tvalid_0's ndcg@1: 0.948275\tvalid_0's ndcg@2: 0.978291\tvalid_0's ndcg@3: 0.979854\tvalid_0's ndcg@4: 0.980188\tvalid_0's ndcg@5: 0.980255\n",
      "[98]\tvalid_0's ndcg@1: 0.948475\tvalid_0's ndcg@2: 0.978381\tvalid_0's ndcg@3: 0.979931\tvalid_0's ndcg@4: 0.980265\tvalid_0's ndcg@5: 0.980333\n",
      "[99]\tvalid_0's ndcg@1: 0.948625\tvalid_0's ndcg@2: 0.978436\tvalid_0's ndcg@3: 0.979986\tvalid_0's ndcg@4: 0.98032\tvalid_0's ndcg@5: 0.980388\n",
      "[100]\tvalid_0's ndcg@1: 0.948775\tvalid_0's ndcg@2: 0.978476\tvalid_0's ndcg@3: 0.980051\tvalid_0's ndcg@4: 0.980374\tvalid_0's ndcg@5: 0.980442\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's ndcg@1: 0.948775\tvalid_0's ndcg@2: 0.978476\tvalid_0's ndcg@3: 0.980051\tvalid_0's ndcg@4: 0.980374\tvalid_0's ndcg@5: 0.980442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@1: 0.9122\tvalid_0's ndcg@2: 0.964157\tvalid_0's ndcg@3: 0.966195\tvalid_0's ndcg@4: 0.966658\tvalid_0's ndcg@5: 0.966725\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.9159\tvalid_0's ndcg@2: 0.965854\tvalid_0's ndcg@3: 0.967791\tvalid_0's ndcg@4: 0.968147\tvalid_0's ndcg@5: 0.968224\n",
      "[3]\tvalid_0's ndcg@1: 0.9218\tvalid_0's ndcg@2: 0.968031\tvalid_0's ndcg@3: 0.970081\tvalid_0's ndcg@4: 0.970351\tvalid_0's ndcg@5: 0.970409\n",
      "[4]\tvalid_0's ndcg@1: 0.9247\tvalid_0's ndcg@2: 0.969196\tvalid_0's ndcg@3: 0.971196\tvalid_0's ndcg@4: 0.971433\tvalid_0's ndcg@5: 0.971501\n",
      "[5]\tvalid_0's ndcg@1: 0.9246\tvalid_0's ndcg@2: 0.969128\tvalid_0's ndcg@3: 0.971153\tvalid_0's ndcg@4: 0.971401\tvalid_0's ndcg@5: 0.971459\n",
      "[6]\tvalid_0's ndcg@1: 0.9262\tvalid_0's ndcg@2: 0.969908\tvalid_0's ndcg@3: 0.97182\tvalid_0's ndcg@4: 0.972046\tvalid_0's ndcg@5: 0.972114\n",
      "[7]\tvalid_0's ndcg@1: 0.9275\tvalid_0's ndcg@2: 0.970545\tvalid_0's ndcg@3: 0.972358\tvalid_0's ndcg@4: 0.972573\tvalid_0's ndcg@5: 0.972631\n",
      "[8]\tvalid_0's ndcg@1: 0.928925\tvalid_0's ndcg@2: 0.97115\tvalid_0's ndcg@3: 0.9729\tvalid_0's ndcg@4: 0.973126\tvalid_0's ndcg@5: 0.973174\n",
      "[9]\tvalid_0's ndcg@1: 0.92985\tvalid_0's ndcg@2: 0.97157\tvalid_0's ndcg@3: 0.973295\tvalid_0's ndcg@4: 0.9735\tvalid_0's ndcg@5: 0.973538\n",
      "[10]\tvalid_0's ndcg@1: 0.93105\tvalid_0's ndcg@2: 0.971997\tvalid_0's ndcg@3: 0.973722\tvalid_0's ndcg@4: 0.973927\tvalid_0's ndcg@5: 0.973975\n",
      "[11]\tvalid_0's ndcg@1: 0.931525\tvalid_0's ndcg@2: 0.972204\tvalid_0's ndcg@3: 0.973904\tvalid_0's ndcg@4: 0.974098\tvalid_0's ndcg@5: 0.974156\n",
      "[12]\tvalid_0's ndcg@1: 0.93165\tvalid_0's ndcg@2: 0.972203\tvalid_0's ndcg@3: 0.973928\tvalid_0's ndcg@4: 0.974143\tvalid_0's ndcg@5: 0.974192\n",
      "[13]\tvalid_0's ndcg@1: 0.93255\tvalid_0's ndcg@2: 0.972646\tvalid_0's ndcg@3: 0.974308\tvalid_0's ndcg@4: 0.974502\tvalid_0's ndcg@5: 0.97455\n",
      "[14]\tvalid_0's ndcg@1: 0.934475\tvalid_0's ndcg@2: 0.973403\tvalid_0's ndcg@3: 0.975066\tvalid_0's ndcg@4: 0.975238\tvalid_0's ndcg@5: 0.975277\n",
      "[15]\tvalid_0's ndcg@1: 0.934075\tvalid_0's ndcg@2: 0.973208\tvalid_0's ndcg@3: 0.974896\tvalid_0's ndcg@4: 0.975079\tvalid_0's ndcg@5: 0.975118\n",
      "[16]\tvalid_0's ndcg@1: 0.93675\tvalid_0's ndcg@2: 0.97418\tvalid_0's ndcg@3: 0.975917\tvalid_0's ndcg@4: 0.976079\tvalid_0's ndcg@5: 0.976108\n",
      "[17]\tvalid_0's ndcg@1: 0.93625\tvalid_0's ndcg@2: 0.974043\tvalid_0's ndcg@3: 0.97573\tvalid_0's ndcg@4: 0.975892\tvalid_0's ndcg@5: 0.97593\n",
      "[18]\tvalid_0's ndcg@1: 0.9368\tvalid_0's ndcg@2: 0.97423\tvalid_0's ndcg@3: 0.975917\tvalid_0's ndcg@4: 0.97609\tvalid_0's ndcg@5: 0.976128\n",
      "[19]\tvalid_0's ndcg@1: 0.93765\tvalid_0's ndcg@2: 0.974654\tvalid_0's ndcg@3: 0.976254\tvalid_0's ndcg@4: 0.976437\tvalid_0's ndcg@5: 0.976466\n",
      "[20]\tvalid_0's ndcg@1: 0.9376\tvalid_0's ndcg@2: 0.974714\tvalid_0's ndcg@3: 0.976264\tvalid_0's ndcg@4: 0.976437\tvalid_0's ndcg@5: 0.976466\n",
      "[21]\tvalid_0's ndcg@1: 0.9375\tvalid_0's ndcg@2: 0.974709\tvalid_0's ndcg@3: 0.976259\tvalid_0's ndcg@4: 0.97641\tvalid_0's ndcg@5: 0.976439\n",
      "[22]\tvalid_0's ndcg@1: 0.937225\tvalid_0's ndcg@2: 0.97456\tvalid_0's ndcg@3: 0.976148\tvalid_0's ndcg@4: 0.976288\tvalid_0's ndcg@5: 0.976326\n",
      "[23]\tvalid_0's ndcg@1: 0.937175\tvalid_0's ndcg@2: 0.974494\tvalid_0's ndcg@3: 0.976107\tvalid_0's ndcg@4: 0.976258\tvalid_0's ndcg@5: 0.976296\n",
      "[24]\tvalid_0's ndcg@1: 0.937375\tvalid_0's ndcg@2: 0.974616\tvalid_0's ndcg@3: 0.976191\tvalid_0's ndcg@4: 0.976341\tvalid_0's ndcg@5: 0.97638\n",
      "[25]\tvalid_0's ndcg@1: 0.937575\tvalid_0's ndcg@2: 0.974674\tvalid_0's ndcg@3: 0.976274\tvalid_0's ndcg@4: 0.976414\tvalid_0's ndcg@5: 0.976452\n",
      "[26]\tvalid_0's ndcg@1: 0.938075\tvalid_0's ndcg@2: 0.974937\tvalid_0's ndcg@3: 0.976462\tvalid_0's ndcg@4: 0.976613\tvalid_0's ndcg@5: 0.976651\n",
      "[27]\tvalid_0's ndcg@1: 0.9381\tvalid_0's ndcg@2: 0.974883\tvalid_0's ndcg@3: 0.976458\tvalid_0's ndcg@4: 0.976609\tvalid_0's ndcg@5: 0.976648\n",
      "[28]\tvalid_0's ndcg@1: 0.938575\tvalid_0's ndcg@2: 0.97509\tvalid_0's ndcg@3: 0.97664\tvalid_0's ndcg@4: 0.976791\tvalid_0's ndcg@5: 0.976829\n",
      "[29]\tvalid_0's ndcg@1: 0.93885\tvalid_0's ndcg@2: 0.975176\tvalid_0's ndcg@3: 0.976751\tvalid_0's ndcg@4: 0.976891\tvalid_0's ndcg@5: 0.976929\n",
      "[30]\tvalid_0's ndcg@1: 0.939175\tvalid_0's ndcg@2: 0.975327\tvalid_0's ndcg@3: 0.976865\tvalid_0's ndcg@4: 0.977016\tvalid_0's ndcg@5: 0.977054\n",
      "[31]\tvalid_0's ndcg@1: 0.939325\tvalid_0's ndcg@2: 0.975398\tvalid_0's ndcg@3: 0.976936\tvalid_0's ndcg@4: 0.977076\tvalid_0's ndcg@5: 0.977115\n",
      "[32]\tvalid_0's ndcg@1: 0.93955\tvalid_0's ndcg@2: 0.97545\tvalid_0's ndcg@3: 0.977012\tvalid_0's ndcg@4: 0.977152\tvalid_0's ndcg@5: 0.977191\n",
      "[33]\tvalid_0's ndcg@1: 0.939875\tvalid_0's ndcg@2: 0.975633\tvalid_0's ndcg@3: 0.977158\tvalid_0's ndcg@4: 0.977287\tvalid_0's ndcg@5: 0.977326\n",
      "[34]\tvalid_0's ndcg@1: 0.940225\tvalid_0's ndcg@2: 0.975762\tvalid_0's ndcg@3: 0.977275\tvalid_0's ndcg@4: 0.977415\tvalid_0's ndcg@5: 0.977453\n",
      "[35]\tvalid_0's ndcg@1: 0.94025\tvalid_0's ndcg@2: 0.975787\tvalid_0's ndcg@3: 0.977287\tvalid_0's ndcg@4: 0.977427\tvalid_0's ndcg@5: 0.977466\n",
      "[36]\tvalid_0's ndcg@1: 0.9405\tvalid_0's ndcg@2: 0.975879\tvalid_0's ndcg@3: 0.977379\tvalid_0's ndcg@4: 0.977519\tvalid_0's ndcg@5: 0.977548\n",
      "[37]\tvalid_0's ndcg@1: 0.940625\tvalid_0's ndcg@2: 0.975957\tvalid_0's ndcg@3: 0.977457\tvalid_0's ndcg@4: 0.977576\tvalid_0's ndcg@5: 0.977605\n",
      "[38]\tvalid_0's ndcg@1: 0.940675\tvalid_0's ndcg@2: 0.97596\tvalid_0's ndcg@3: 0.977472\tvalid_0's ndcg@4: 0.977591\tvalid_0's ndcg@5: 0.97762\n",
      "[39]\tvalid_0's ndcg@1: 0.940925\tvalid_0's ndcg@2: 0.976036\tvalid_0's ndcg@3: 0.977561\tvalid_0's ndcg@4: 0.977669\tvalid_0's ndcg@5: 0.977708\n",
      "[40]\tvalid_0's ndcg@1: 0.94145\tvalid_0's ndcg@2: 0.97623\tvalid_0's ndcg@3: 0.977755\tvalid_0's ndcg@4: 0.977873\tvalid_0's ndcg@5: 0.977902\n",
      "[41]\tvalid_0's ndcg@1: 0.94185\tvalid_0's ndcg@2: 0.976425\tvalid_0's ndcg@3: 0.977925\tvalid_0's ndcg@4: 0.978033\tvalid_0's ndcg@5: 0.978062\n",
      "[42]\tvalid_0's ndcg@1: 0.941975\tvalid_0's ndcg@2: 0.976487\tvalid_0's ndcg@3: 0.977974\tvalid_0's ndcg@4: 0.978082\tvalid_0's ndcg@5: 0.978111\n",
      "[43]\tvalid_0's ndcg@1: 0.942175\tvalid_0's ndcg@2: 0.976561\tvalid_0's ndcg@3: 0.978048\tvalid_0's ndcg@4: 0.978156\tvalid_0's ndcg@5: 0.978185\n",
      "[44]\tvalid_0's ndcg@1: 0.94215\tvalid_0's ndcg@2: 0.976536\tvalid_0's ndcg@3: 0.978036\tvalid_0's ndcg@4: 0.978143\tvalid_0's ndcg@5: 0.978172\n",
      "[45]\tvalid_0's ndcg@1: 0.94225\tvalid_0's ndcg@2: 0.976557\tvalid_0's ndcg@3: 0.978069\tvalid_0's ndcg@4: 0.978177\tvalid_0's ndcg@5: 0.978206\n",
      "[46]\tvalid_0's ndcg@1: 0.942175\tvalid_0's ndcg@2: 0.976545\tvalid_0's ndcg@3: 0.978057\tvalid_0's ndcg@4: 0.978154\tvalid_0's ndcg@5: 0.978183\n",
      "[47]\tvalid_0's ndcg@1: 0.942625\tvalid_0's ndcg@2: 0.976727\tvalid_0's ndcg@3: 0.978227\tvalid_0's ndcg@4: 0.978324\tvalid_0's ndcg@5: 0.978353\n",
      "[48]\tvalid_0's ndcg@1: 0.942525\tvalid_0's ndcg@2: 0.976658\tvalid_0's ndcg@3: 0.978183\tvalid_0's ndcg@4: 0.97828\tvalid_0's ndcg@5: 0.978309\n",
      "[49]\tvalid_0's ndcg@1: 0.942675\tvalid_0's ndcg@2: 0.976698\tvalid_0's ndcg@3: 0.978223\tvalid_0's ndcg@4: 0.978331\tvalid_0's ndcg@5: 0.97836\n",
      "[50]\tvalid_0's ndcg@1: 0.942875\tvalid_0's ndcg@2: 0.97674\tvalid_0's ndcg@3: 0.978278\tvalid_0's ndcg@4: 0.978396\tvalid_0's ndcg@5: 0.978425\n",
      "[51]\tvalid_0's ndcg@1: 0.94305\tvalid_0's ndcg@2: 0.976836\tvalid_0's ndcg@3: 0.978349\tvalid_0's ndcg@4: 0.978467\tvalid_0's ndcg@5: 0.978496\n",
      "[52]\tvalid_0's ndcg@1: 0.9434\tvalid_0's ndcg@2: 0.976981\tvalid_0's ndcg@3: 0.978481\tvalid_0's ndcg@4: 0.9786\tvalid_0's ndcg@5: 0.978629\n",
      "[53]\tvalid_0's ndcg@1: 0.943275\tvalid_0's ndcg@2: 0.976935\tvalid_0's ndcg@3: 0.978448\tvalid_0's ndcg@4: 0.978555\tvalid_0's ndcg@5: 0.978584\n",
      "[54]\tvalid_0's ndcg@1: 0.943675\tvalid_0's ndcg@2: 0.977099\tvalid_0's ndcg@3: 0.978599\tvalid_0's ndcg@4: 0.978706\tvalid_0's ndcg@5: 0.978735\n",
      "[55]\tvalid_0's ndcg@1: 0.94375\tvalid_0's ndcg@2: 0.977142\tvalid_0's ndcg@3: 0.978617\tvalid_0's ndcg@4: 0.978725\tvalid_0's ndcg@5: 0.978763\n",
      "[56]\tvalid_0's ndcg@1: 0.9437\tvalid_0's ndcg@2: 0.977124\tvalid_0's ndcg@3: 0.978599\tvalid_0's ndcg@4: 0.978706\tvalid_0's ndcg@5: 0.978745\n",
      "[57]\tvalid_0's ndcg@1: 0.944025\tvalid_0's ndcg@2: 0.977243\tvalid_0's ndcg@3: 0.978718\tvalid_0's ndcg@4: 0.978826\tvalid_0's ndcg@5: 0.978865\n",
      "[58]\tvalid_0's ndcg@1: 0.94445\tvalid_0's ndcg@2: 0.977353\tvalid_0's ndcg@3: 0.978865\tvalid_0's ndcg@4: 0.978973\tvalid_0's ndcg@5: 0.979012\n",
      "[59]\tvalid_0's ndcg@1: 0.944775\tvalid_0's ndcg@2: 0.977489\tvalid_0's ndcg@3: 0.978989\tvalid_0's ndcg@4: 0.979096\tvalid_0's ndcg@5: 0.979135\n",
      "[60]\tvalid_0's ndcg@1: 0.94445\tvalid_0's ndcg@2: 0.977337\tvalid_0's ndcg@3: 0.978862\tvalid_0's ndcg@4: 0.97897\tvalid_0's ndcg@5: 0.979009\n",
      "[61]\tvalid_0's ndcg@1: 0.944625\tvalid_0's ndcg@2: 0.977402\tvalid_0's ndcg@3: 0.978927\tvalid_0's ndcg@4: 0.979034\tvalid_0's ndcg@5: 0.979073\n",
      "[62]\tvalid_0's ndcg@1: 0.945125\tvalid_0's ndcg@2: 0.977602\tvalid_0's ndcg@3: 0.979115\tvalid_0's ndcg@4: 0.979222\tvalid_0's ndcg@5: 0.979261\n",
      "[63]\tvalid_0's ndcg@1: 0.945\tvalid_0's ndcg@2: 0.977619\tvalid_0's ndcg@3: 0.979107\tvalid_0's ndcg@4: 0.979193\tvalid_0's ndcg@5: 0.979241\n",
      "[64]\tvalid_0's ndcg@1: 0.94495\tvalid_0's ndcg@2: 0.977585\tvalid_0's ndcg@3: 0.979085\tvalid_0's ndcg@4: 0.979171\tvalid_0's ndcg@5: 0.979219\n",
      "[65]\tvalid_0's ndcg@1: 0.944925\tvalid_0's ndcg@2: 0.977623\tvalid_0's ndcg@3: 0.979085\tvalid_0's ndcg@4: 0.979172\tvalid_0's ndcg@5: 0.97922\n",
      "[66]\tvalid_0's ndcg@1: 0.9451\tvalid_0's ndcg@2: 0.977672\tvalid_0's ndcg@3: 0.979147\tvalid_0's ndcg@4: 0.979233\tvalid_0's ndcg@5: 0.979281\n",
      "[67]\tvalid_0's ndcg@1: 0.94485\tvalid_0's ndcg@2: 0.977579\tvalid_0's ndcg@3: 0.979042\tvalid_0's ndcg@4: 0.979139\tvalid_0's ndcg@5: 0.979187\n",
      "[68]\tvalid_0's ndcg@1: 0.945075\tvalid_0's ndcg@2: 0.977631\tvalid_0's ndcg@3: 0.979118\tvalid_0's ndcg@4: 0.979215\tvalid_0's ndcg@5: 0.979264\n",
      "[69]\tvalid_0's ndcg@1: 0.944825\tvalid_0's ndcg@2: 0.977554\tvalid_0's ndcg@3: 0.979029\tvalid_0's ndcg@4: 0.979126\tvalid_0's ndcg@5: 0.979175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalid_0's ndcg@1: 0.945025\tvalid_0's ndcg@2: 0.977628\tvalid_0's ndcg@3: 0.979103\tvalid_0's ndcg@4: 0.9792\tvalid_0's ndcg@5: 0.979249\n",
      "[71]\tvalid_0's ndcg@1: 0.945475\tvalid_0's ndcg@2: 0.977731\tvalid_0's ndcg@3: 0.979256\tvalid_0's ndcg@4: 0.979353\tvalid_0's ndcg@5: 0.979402\n",
      "[72]\tvalid_0's ndcg@1: 0.945475\tvalid_0's ndcg@2: 0.977747\tvalid_0's ndcg@3: 0.979272\tvalid_0's ndcg@4: 0.979358\tvalid_0's ndcg@5: 0.979407\n",
      "[73]\tvalid_0's ndcg@1: 0.9458\tvalid_0's ndcg@2: 0.977867\tvalid_0's ndcg@3: 0.979405\tvalid_0's ndcg@4: 0.97948\tvalid_0's ndcg@5: 0.979528\n",
      "[74]\tvalid_0's ndcg@1: 0.94585\tvalid_0's ndcg@2: 0.977885\tvalid_0's ndcg@3: 0.979423\tvalid_0's ndcg@4: 0.979498\tvalid_0's ndcg@5: 0.979547\n",
      "[75]\tvalid_0's ndcg@1: 0.946\tvalid_0's ndcg@2: 0.977957\tvalid_0's ndcg@3: 0.979482\tvalid_0's ndcg@4: 0.979557\tvalid_0's ndcg@5: 0.979605\n",
      "[76]\tvalid_0's ndcg@1: 0.946275\tvalid_0's ndcg@2: 0.978058\tvalid_0's ndcg@3: 0.979583\tvalid_0's ndcg@4: 0.979658\tvalid_0's ndcg@5: 0.979707\n",
      "[77]\tvalid_0's ndcg@1: 0.946275\tvalid_0's ndcg@2: 0.978042\tvalid_0's ndcg@3: 0.97958\tvalid_0's ndcg@4: 0.979655\tvalid_0's ndcg@5: 0.979704\n",
      "[78]\tvalid_0's ndcg@1: 0.946125\tvalid_0's ndcg@2: 0.977971\tvalid_0's ndcg@3: 0.979521\tvalid_0's ndcg@4: 0.979597\tvalid_0's ndcg@5: 0.979645\n",
      "[79]\tvalid_0's ndcg@1: 0.94615\tvalid_0's ndcg@2: 0.978028\tvalid_0's ndcg@3: 0.97954\tvalid_0's ndcg@4: 0.979616\tvalid_0's ndcg@5: 0.979664\n",
      "[80]\tvalid_0's ndcg@1: 0.94645\tvalid_0's ndcg@2: 0.978123\tvalid_0's ndcg@3: 0.979648\tvalid_0's ndcg@4: 0.979723\tvalid_0's ndcg@5: 0.979771\n",
      "[81]\tvalid_0's ndcg@1: 0.94675\tvalid_0's ndcg@2: 0.978249\tvalid_0's ndcg@3: 0.979762\tvalid_0's ndcg@4: 0.979837\tvalid_0's ndcg@5: 0.979885\n",
      "[82]\tvalid_0's ndcg@1: 0.94655\tvalid_0's ndcg@2: 0.978175\tvalid_0's ndcg@3: 0.979688\tvalid_0's ndcg@4: 0.979763\tvalid_0's ndcg@5: 0.979812\n",
      "[83]\tvalid_0's ndcg@1: 0.9466\tvalid_0's ndcg@2: 0.978194\tvalid_0's ndcg@3: 0.979706\tvalid_0's ndcg@4: 0.979782\tvalid_0's ndcg@5: 0.97983\n",
      "[84]\tvalid_0's ndcg@1: 0.94675\tvalid_0's ndcg@2: 0.978233\tvalid_0's ndcg@3: 0.979746\tvalid_0's ndcg@4: 0.979832\tvalid_0's ndcg@5: 0.97988\n",
      "[85]\tvalid_0's ndcg@1: 0.9468\tvalid_0's ndcg@2: 0.978315\tvalid_0's ndcg@3: 0.979765\tvalid_0's ndcg@4: 0.979862\tvalid_0's ndcg@5: 0.97991\n",
      "[86]\tvalid_0's ndcg@1: 0.946825\tvalid_0's ndcg@2: 0.978293\tvalid_0's ndcg@3: 0.97978\tvalid_0's ndcg@4: 0.979866\tvalid_0's ndcg@5: 0.979915\n",
      "[87]\tvalid_0's ndcg@1: 0.946825\tvalid_0's ndcg@2: 0.978293\tvalid_0's ndcg@3: 0.97978\tvalid_0's ndcg@4: 0.979866\tvalid_0's ndcg@5: 0.979915\n",
      "[88]\tvalid_0's ndcg@1: 0.947325\tvalid_0's ndcg@2: 0.978524\tvalid_0's ndcg@3: 0.979974\tvalid_0's ndcg@4: 0.980061\tvalid_0's ndcg@5: 0.980109\n",
      "[89]\tvalid_0's ndcg@1: 0.9473\tvalid_0's ndcg@2: 0.978531\tvalid_0's ndcg@3: 0.979969\tvalid_0's ndcg@4: 0.980055\tvalid_0's ndcg@5: 0.980103\n",
      "[90]\tvalid_0's ndcg@1: 0.947375\tvalid_0's ndcg@2: 0.978574\tvalid_0's ndcg@3: 0.979999\tvalid_0's ndcg@4: 0.980086\tvalid_0's ndcg@5: 0.980134\n",
      "[91]\tvalid_0's ndcg@1: 0.947475\tvalid_0's ndcg@2: 0.97858\tvalid_0's ndcg@3: 0.98003\tvalid_0's ndcg@4: 0.980116\tvalid_0's ndcg@5: 0.980164\n",
      "[92]\tvalid_0's ndcg@1: 0.947325\tvalid_0's ndcg@2: 0.978461\tvalid_0's ndcg@3: 0.979961\tvalid_0's ndcg@4: 0.980048\tvalid_0's ndcg@5: 0.980096\n",
      "[93]\tvalid_0's ndcg@1: 0.94735\tvalid_0's ndcg@2: 0.978471\tvalid_0's ndcg@3: 0.979971\tvalid_0's ndcg@4: 0.980057\tvalid_0's ndcg@5: 0.980105\n",
      "[94]\tvalid_0's ndcg@1: 0.9474\tvalid_0's ndcg@2: 0.978489\tvalid_0's ndcg@3: 0.979989\tvalid_0's ndcg@4: 0.980075\tvalid_0's ndcg@5: 0.980124\n",
      "[95]\tvalid_0's ndcg@1: 0.9476\tvalid_0's ndcg@2: 0.978579\tvalid_0's ndcg@3: 0.980066\tvalid_0's ndcg@4: 0.980152\tvalid_0's ndcg@5: 0.980201\n",
      "[96]\tvalid_0's ndcg@1: 0.9477\tvalid_0's ndcg@2: 0.978631\tvalid_0's ndcg@3: 0.980106\tvalid_0's ndcg@4: 0.980192\tvalid_0's ndcg@5: 0.980241\n",
      "[97]\tvalid_0's ndcg@1: 0.94785\tvalid_0's ndcg@2: 0.978781\tvalid_0's ndcg@3: 0.980181\tvalid_0's ndcg@4: 0.980267\tvalid_0's ndcg@5: 0.980316\n",
      "[98]\tvalid_0's ndcg@1: 0.947775\tvalid_0's ndcg@2: 0.978769\tvalid_0's ndcg@3: 0.980157\tvalid_0's ndcg@4: 0.980243\tvalid_0's ndcg@5: 0.980291\n",
      "[99]\tvalid_0's ndcg@1: 0.948\tvalid_0's ndcg@2: 0.978821\tvalid_0's ndcg@3: 0.980233\tvalid_0's ndcg@4: 0.98032\tvalid_0's ndcg@5: 0.980358\n",
      "[100]\tvalid_0's ndcg@1: 0.94825\tvalid_0's ndcg@2: 0.978913\tvalid_0's ndcg@3: 0.980326\tvalid_0's ndcg@4: 0.980412\tvalid_0's ndcg@5: 0.980451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's ndcg@1: 0.94825\tvalid_0's ndcg@2: 0.978913\tvalid_0's ndcg@3: 0.980326\tvalid_0's ndcg@4: 0.980412\tvalid_0's ndcg@5: 0.980451\n",
      "[1]\tvalid_0's ndcg@1: 0.90945\tvalid_0's ndcg@2: 0.962874\tvalid_0's ndcg@3: 0.965274\tvalid_0's ndcg@4: 0.965608\tvalid_0's ndcg@5: 0.965695\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.9133\tvalid_0's ndcg@2: 0.9648\tvalid_0's ndcg@3: 0.9669\tvalid_0's ndcg@4: 0.967147\tvalid_0's ndcg@5: 0.967244\n",
      "[3]\tvalid_0's ndcg@1: 0.921375\tvalid_0's ndcg@2: 0.96808\tvalid_0's ndcg@3: 0.969992\tvalid_0's ndcg@4: 0.97024\tvalid_0's ndcg@5: 0.970288\n",
      "[4]\tvalid_0's ndcg@1: 0.923425\tvalid_0's ndcg@2: 0.968962\tvalid_0's ndcg@3: 0.970787\tvalid_0's ndcg@4: 0.971024\tvalid_0's ndcg@5: 0.971073\n",
      "[5]\tvalid_0's ndcg@1: 0.92385\tvalid_0's ndcg@2: 0.96904\tvalid_0's ndcg@3: 0.970915\tvalid_0's ndcg@4: 0.971163\tvalid_0's ndcg@5: 0.971211\n",
      "[6]\tvalid_0's ndcg@1: 0.92585\tvalid_0's ndcg@2: 0.969889\tvalid_0's ndcg@3: 0.971689\tvalid_0's ndcg@4: 0.971926\tvalid_0's ndcg@5: 0.971974\n",
      "[7]\tvalid_0's ndcg@1: 0.9289\tvalid_0's ndcg@2: 0.971062\tvalid_0's ndcg@3: 0.972799\tvalid_0's ndcg@4: 0.973058\tvalid_0's ndcg@5: 0.973106\n",
      "[8]\tvalid_0's ndcg@1: 0.92985\tvalid_0's ndcg@2: 0.97116\tvalid_0's ndcg@3: 0.973135\tvalid_0's ndcg@4: 0.973383\tvalid_0's ndcg@5: 0.973412\n",
      "[9]\tvalid_0's ndcg@1: 0.930675\tvalid_0's ndcg@2: 0.971512\tvalid_0's ndcg@3: 0.973424\tvalid_0's ndcg@4: 0.973694\tvalid_0's ndcg@5: 0.973723\n",
      "[10]\tvalid_0's ndcg@1: 0.930775\tvalid_0's ndcg@2: 0.971549\tvalid_0's ndcg@3: 0.973499\tvalid_0's ndcg@4: 0.973736\tvalid_0's ndcg@5: 0.973765\n",
      "[11]\tvalid_0's ndcg@1: 0.9316\tvalid_0's ndcg@2: 0.971885\tvalid_0's ndcg@3: 0.973772\tvalid_0's ndcg@4: 0.974042\tvalid_0's ndcg@5: 0.974071\n",
      "[12]\tvalid_0's ndcg@1: 0.931475\tvalid_0's ndcg@2: 0.971744\tvalid_0's ndcg@3: 0.973694\tvalid_0's ndcg@4: 0.973963\tvalid_0's ndcg@5: 0.973983\n",
      "[13]\tvalid_0's ndcg@1: 0.93205\tvalid_0's ndcg@2: 0.971988\tvalid_0's ndcg@3: 0.97395\tvalid_0's ndcg@4: 0.974187\tvalid_0's ndcg@5: 0.974207\n",
      "[14]\tvalid_0's ndcg@1: 0.93275\tvalid_0's ndcg@2: 0.972325\tvalid_0's ndcg@3: 0.97425\tvalid_0's ndcg@4: 0.974465\tvalid_0's ndcg@5: 0.974485\n",
      "[15]\tvalid_0's ndcg@1: 0.933375\tvalid_0's ndcg@2: 0.97254\tvalid_0's ndcg@3: 0.974452\tvalid_0's ndcg@4: 0.974689\tvalid_0's ndcg@5: 0.974709\n",
      "[16]\tvalid_0's ndcg@1: 0.93355\tvalid_0's ndcg@2: 0.972589\tvalid_0's ndcg@3: 0.974501\tvalid_0's ndcg@4: 0.974749\tvalid_0's ndcg@5: 0.974768\n",
      "[17]\tvalid_0's ndcg@1: 0.93385\tvalid_0's ndcg@2: 0.972747\tvalid_0's ndcg@3: 0.974634\tvalid_0's ndcg@4: 0.974871\tvalid_0's ndcg@5: 0.974891\n",
      "[18]\tvalid_0's ndcg@1: 0.933475\tvalid_0's ndcg@2: 0.97253\tvalid_0's ndcg@3: 0.974492\tvalid_0's ndcg@4: 0.974718\tvalid_0's ndcg@5: 0.974737\n",
      "[19]\tvalid_0's ndcg@1: 0.93435\tvalid_0's ndcg@2: 0.972947\tvalid_0's ndcg@3: 0.974847\tvalid_0's ndcg@4: 0.975062\tvalid_0's ndcg@5: 0.975082\n",
      "[20]\tvalid_0's ndcg@1: 0.93525\tvalid_0's ndcg@2: 0.973232\tvalid_0's ndcg@3: 0.975157\tvalid_0's ndcg@4: 0.975372\tvalid_0's ndcg@5: 0.975401\n",
      "[21]\tvalid_0's ndcg@1: 0.9351\tvalid_0's ndcg@2: 0.97324\tvalid_0's ndcg@3: 0.975115\tvalid_0's ndcg@4: 0.97533\tvalid_0's ndcg@5: 0.975359\n",
      "[22]\tvalid_0's ndcg@1: 0.93525\tvalid_0's ndcg@2: 0.973342\tvalid_0's ndcg@3: 0.97518\tvalid_0's ndcg@4: 0.975395\tvalid_0's ndcg@5: 0.975424\n",
      "[23]\tvalid_0's ndcg@1: 0.93525\tvalid_0's ndcg@2: 0.973374\tvalid_0's ndcg@3: 0.975186\tvalid_0's ndcg@4: 0.975391\tvalid_0's ndcg@5: 0.97543\n",
      "[24]\tvalid_0's ndcg@1: 0.936\tvalid_0's ndcg@2: 0.973714\tvalid_0's ndcg@3: 0.975464\tvalid_0's ndcg@4: 0.97569\tvalid_0's ndcg@5: 0.975719\n",
      "[25]\tvalid_0's ndcg@1: 0.936375\tvalid_0's ndcg@2: 0.973884\tvalid_0's ndcg@3: 0.975634\tvalid_0's ndcg@4: 0.975838\tvalid_0's ndcg@5: 0.975867\n",
      "[26]\tvalid_0's ndcg@1: 0.936175\tvalid_0's ndcg@2: 0.973747\tvalid_0's ndcg@3: 0.975547\tvalid_0's ndcg@4: 0.975751\tvalid_0's ndcg@5: 0.97578\n",
      "[27]\tvalid_0's ndcg@1: 0.936\tvalid_0's ndcg@2: 0.973635\tvalid_0's ndcg@3: 0.975472\tvalid_0's ndcg@4: 0.975677\tvalid_0's ndcg@5: 0.975706\n",
      "[28]\tvalid_0's ndcg@1: 0.93655\tvalid_0's ndcg@2: 0.973933\tvalid_0's ndcg@3: 0.975695\tvalid_0's ndcg@4: 0.9759\tvalid_0's ndcg@5: 0.975929\n",
      "[29]\tvalid_0's ndcg@1: 0.93655\tvalid_0's ndcg@2: 0.973996\tvalid_0's ndcg@3: 0.975708\tvalid_0's ndcg@4: 0.975913\tvalid_0's ndcg@5: 0.975942\n",
      "[30]\tvalid_0's ndcg@1: 0.936475\tvalid_0's ndcg@2: 0.973921\tvalid_0's ndcg@3: 0.975683\tvalid_0's ndcg@4: 0.975877\tvalid_0's ndcg@5: 0.975916\n",
      "[31]\tvalid_0's ndcg@1: 0.937575\tvalid_0's ndcg@2: 0.974358\tvalid_0's ndcg@3: 0.976071\tvalid_0's ndcg@4: 0.976286\tvalid_0's ndcg@5: 0.976325\n",
      "[32]\tvalid_0's ndcg@1: 0.938125\tvalid_0's ndcg@2: 0.97453\tvalid_0's ndcg@3: 0.976267\tvalid_0's ndcg@4: 0.976482\tvalid_0's ndcg@5: 0.976521\n",
      "[33]\tvalid_0's ndcg@1: 0.93825\tvalid_0's ndcg@2: 0.97456\tvalid_0's ndcg@3: 0.976348\tvalid_0's ndcg@4: 0.976531\tvalid_0's ndcg@5: 0.976569\n",
      "[34]\tvalid_0's ndcg@1: 0.938575\tvalid_0's ndcg@2: 0.974648\tvalid_0's ndcg@3: 0.976448\tvalid_0's ndcg@4: 0.976642\tvalid_0's ndcg@5: 0.976681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\tvalid_0's ndcg@1: 0.9386\tvalid_0's ndcg@2: 0.974642\tvalid_0's ndcg@3: 0.976454\tvalid_0's ndcg@4: 0.976648\tvalid_0's ndcg@5: 0.976687\n",
      "[36]\tvalid_0's ndcg@1: 0.938625\tvalid_0's ndcg@2: 0.974698\tvalid_0's ndcg@3: 0.976473\tvalid_0's ndcg@4: 0.976667\tvalid_0's ndcg@5: 0.976696\n",
      "[37]\tvalid_0's ndcg@1: 0.939425\tvalid_0's ndcg@2: 0.974962\tvalid_0's ndcg@3: 0.97675\tvalid_0's ndcg@4: 0.976954\tvalid_0's ndcg@5: 0.976983\n",
      "[38]\tvalid_0's ndcg@1: 0.9394\tvalid_0's ndcg@2: 0.974969\tvalid_0's ndcg@3: 0.976744\tvalid_0's ndcg@4: 0.976948\tvalid_0's ndcg@5: 0.976977\n",
      "[39]\tvalid_0's ndcg@1: 0.939125\tvalid_0's ndcg@2: 0.974914\tvalid_0's ndcg@3: 0.976652\tvalid_0's ndcg@4: 0.976857\tvalid_0's ndcg@5: 0.976886\n",
      "[40]\tvalid_0's ndcg@1: 0.939675\tvalid_0's ndcg@2: 0.975133\tvalid_0's ndcg@3: 0.976858\tvalid_0's ndcg@4: 0.977063\tvalid_0's ndcg@5: 0.977102\n",
      "[41]\tvalid_0's ndcg@1: 0.939475\tvalid_0's ndcg@2: 0.975059\tvalid_0's ndcg@3: 0.976784\tvalid_0's ndcg@4: 0.976989\tvalid_0's ndcg@5: 0.977028\n",
      "[42]\tvalid_0's ndcg@1: 0.939875\tvalid_0's ndcg@2: 0.975239\tvalid_0's ndcg@3: 0.976939\tvalid_0's ndcg@4: 0.977143\tvalid_0's ndcg@5: 0.977182\n",
      "[43]\tvalid_0's ndcg@1: 0.940025\tvalid_0's ndcg@2: 0.975278\tvalid_0's ndcg@3: 0.976991\tvalid_0's ndcg@4: 0.977195\tvalid_0's ndcg@5: 0.977244\n",
      "[44]\tvalid_0's ndcg@1: 0.9403\tvalid_0's ndcg@2: 0.975364\tvalid_0's ndcg@3: 0.977089\tvalid_0's ndcg@4: 0.977293\tvalid_0's ndcg@5: 0.977342\n",
      "[45]\tvalid_0's ndcg@1: 0.940425\tvalid_0's ndcg@2: 0.97541\tvalid_0's ndcg@3: 0.977135\tvalid_0's ndcg@4: 0.97734\tvalid_0's ndcg@5: 0.977388\n",
      "[46]\tvalid_0's ndcg@1: 0.94045\tvalid_0's ndcg@2: 0.975467\tvalid_0's ndcg@3: 0.977142\tvalid_0's ndcg@4: 0.977357\tvalid_0's ndcg@5: 0.977415\n",
      "[47]\tvalid_0's ndcg@1: 0.940625\tvalid_0's ndcg@2: 0.975531\tvalid_0's ndcg@3: 0.977194\tvalid_0's ndcg@4: 0.97742\tvalid_0's ndcg@5: 0.977478\n",
      "[48]\tvalid_0's ndcg@1: 0.940525\tvalid_0's ndcg@2: 0.975479\tvalid_0's ndcg@3: 0.977154\tvalid_0's ndcg@4: 0.97739\tvalid_0's ndcg@5: 0.977439\n",
      "[49]\tvalid_0's ndcg@1: 0.94055\tvalid_0's ndcg@2: 0.975488\tvalid_0's ndcg@3: 0.977163\tvalid_0's ndcg@4: 0.97741\tvalid_0's ndcg@5: 0.977449\n",
      "[50]\tvalid_0's ndcg@1: 0.940475\tvalid_0's ndcg@2: 0.975523\tvalid_0's ndcg@3: 0.977161\tvalid_0's ndcg@4: 0.977398\tvalid_0's ndcg@5: 0.977427\n",
      "[51]\tvalid_0's ndcg@1: 0.94075\tvalid_0's ndcg@2: 0.97564\tvalid_0's ndcg@3: 0.977278\tvalid_0's ndcg@4: 0.977504\tvalid_0's ndcg@5: 0.977533\n",
      "[52]\tvalid_0's ndcg@1: 0.9408\tvalid_0's ndcg@2: 0.975659\tvalid_0's ndcg@3: 0.977296\tvalid_0's ndcg@4: 0.977522\tvalid_0's ndcg@5: 0.977551\n",
      "[53]\tvalid_0's ndcg@1: 0.941125\tvalid_0's ndcg@2: 0.975795\tvalid_0's ndcg@3: 0.97742\tvalid_0's ndcg@4: 0.977646\tvalid_0's ndcg@5: 0.977675\n",
      "[54]\tvalid_0's ndcg@1: 0.9411\tvalid_0's ndcg@2: 0.975833\tvalid_0's ndcg@3: 0.97742\tvalid_0's ndcg@4: 0.977646\tvalid_0's ndcg@5: 0.977675\n",
      "[55]\tvalid_0's ndcg@1: 0.941\tvalid_0's ndcg@2: 0.975812\tvalid_0's ndcg@3: 0.977387\tvalid_0's ndcg@4: 0.977613\tvalid_0's ndcg@5: 0.977642\n",
      "[56]\tvalid_0's ndcg@1: 0.941625\tvalid_0's ndcg@2: 0.976026\tvalid_0's ndcg@3: 0.977614\tvalid_0's ndcg@4: 0.97784\tvalid_0's ndcg@5: 0.977869\n",
      "[57]\tvalid_0's ndcg@1: 0.9421\tvalid_0's ndcg@2: 0.976218\tvalid_0's ndcg@3: 0.977805\tvalid_0's ndcg@4: 0.97802\tvalid_0's ndcg@5: 0.978049\n",
      "[58]\tvalid_0's ndcg@1: 0.942325\tvalid_0's ndcg@2: 0.976301\tvalid_0's ndcg@3: 0.977901\tvalid_0's ndcg@4: 0.978105\tvalid_0's ndcg@5: 0.978134\n",
      "[59]\tvalid_0's ndcg@1: 0.942025\tvalid_0's ndcg@2: 0.976221\tvalid_0's ndcg@3: 0.977784\tvalid_0's ndcg@4: 0.977999\tvalid_0's ndcg@5: 0.978028\n",
      "[60]\tvalid_0's ndcg@1: 0.942425\tvalid_0's ndcg@2: 0.976353\tvalid_0's ndcg@3: 0.977928\tvalid_0's ndcg@4: 0.978144\tvalid_0's ndcg@5: 0.978173\n",
      "[61]\tvalid_0's ndcg@1: 0.94265\tvalid_0's ndcg@2: 0.976436\tvalid_0's ndcg@3: 0.978011\tvalid_0's ndcg@4: 0.978227\tvalid_0's ndcg@5: 0.978256\n",
      "[62]\tvalid_0's ndcg@1: 0.942725\tvalid_0's ndcg@2: 0.976432\tvalid_0's ndcg@3: 0.978032\tvalid_0's ndcg@4: 0.978248\tvalid_0's ndcg@5: 0.978277\n",
      "[63]\tvalid_0's ndcg@1: 0.943225\tvalid_0's ndcg@2: 0.976633\tvalid_0's ndcg@3: 0.97822\tvalid_0's ndcg@4: 0.978436\tvalid_0's ndcg@5: 0.978465\n",
      "[64]\tvalid_0's ndcg@1: 0.943275\tvalid_0's ndcg@2: 0.976651\tvalid_0's ndcg@3: 0.978239\tvalid_0's ndcg@4: 0.978454\tvalid_0's ndcg@5: 0.978483\n",
      "[65]\tvalid_0's ndcg@1: 0.9435\tvalid_0's ndcg@2: 0.976734\tvalid_0's ndcg@3: 0.978322\tvalid_0's ndcg@4: 0.978537\tvalid_0's ndcg@5: 0.978566\n",
      "[66]\tvalid_0's ndcg@1: 0.943375\tvalid_0's ndcg@2: 0.976657\tvalid_0's ndcg@3: 0.978269\tvalid_0's ndcg@4: 0.978484\tvalid_0's ndcg@5: 0.978513\n",
      "[67]\tvalid_0's ndcg@1: 0.943575\tvalid_0's ndcg@2: 0.976746\tvalid_0's ndcg@3: 0.978346\tvalid_0's ndcg@4: 0.978561\tvalid_0's ndcg@5: 0.97859\n",
      "[68]\tvalid_0's ndcg@1: 0.9436\tvalid_0's ndcg@2: 0.976755\tvalid_0's ndcg@3: 0.978343\tvalid_0's ndcg@4: 0.978547\tvalid_0's ndcg@5: 0.978596\n",
      "[69]\tvalid_0's ndcg@1: 0.94355\tvalid_0's ndcg@2: 0.976737\tvalid_0's ndcg@3: 0.978312\tvalid_0's ndcg@4: 0.978516\tvalid_0's ndcg@5: 0.978575\n",
      "[70]\tvalid_0's ndcg@1: 0.9438\tvalid_0's ndcg@2: 0.976813\tvalid_0's ndcg@3: 0.978401\tvalid_0's ndcg@4: 0.978616\tvalid_0's ndcg@5: 0.978665\n",
      "[71]\tvalid_0's ndcg@1: 0.943875\tvalid_0's ndcg@2: 0.976841\tvalid_0's ndcg@3: 0.978429\tvalid_0's ndcg@4: 0.978644\tvalid_0's ndcg@5: 0.978692\n",
      "[72]\tvalid_0's ndcg@1: 0.94385\tvalid_0's ndcg@2: 0.976816\tvalid_0's ndcg@3: 0.978404\tvalid_0's ndcg@4: 0.97863\tvalid_0's ndcg@5: 0.978678\n",
      "[73]\tvalid_0's ndcg@1: 0.944\tvalid_0's ndcg@2: 0.976887\tvalid_0's ndcg@3: 0.978475\tvalid_0's ndcg@4: 0.97869\tvalid_0's ndcg@5: 0.978738\n",
      "[74]\tvalid_0's ndcg@1: 0.944\tvalid_0's ndcg@2: 0.976871\tvalid_0's ndcg@3: 0.978446\tvalid_0's ndcg@4: 0.978683\tvalid_0's ndcg@5: 0.978732\n",
      "[75]\tvalid_0's ndcg@1: 0.94385\tvalid_0's ndcg@2: 0.976785\tvalid_0's ndcg@3: 0.978385\tvalid_0's ndcg@4: 0.978621\tvalid_0's ndcg@5: 0.97867\n",
      "[76]\tvalid_0's ndcg@1: 0.943775\tvalid_0's ndcg@2: 0.976773\tvalid_0's ndcg@3: 0.978373\tvalid_0's ndcg@4: 0.978599\tvalid_0's ndcg@5: 0.978647\n",
      "[77]\tvalid_0's ndcg@1: 0.944275\tvalid_0's ndcg@2: 0.976941\tvalid_0's ndcg@3: 0.978566\tvalid_0's ndcg@4: 0.978782\tvalid_0's ndcg@5: 0.97883\n",
      "[78]\tvalid_0's ndcg@1: 0.9442\tvalid_0's ndcg@2: 0.976961\tvalid_0's ndcg@3: 0.978536\tvalid_0's ndcg@4: 0.978773\tvalid_0's ndcg@5: 0.978812\n",
      "[79]\tvalid_0's ndcg@1: 0.944225\tvalid_0's ndcg@2: 0.97697\tvalid_0's ndcg@3: 0.978545\tvalid_0's ndcg@4: 0.978782\tvalid_0's ndcg@5: 0.978821\n",
      "[80]\tvalid_0's ndcg@1: 0.944175\tvalid_0's ndcg@2: 0.976936\tvalid_0's ndcg@3: 0.978524\tvalid_0's ndcg@4: 0.97876\tvalid_0's ndcg@5: 0.978799\n",
      "[81]\tvalid_0's ndcg@1: 0.94435\tvalid_0's ndcg@2: 0.977016\tvalid_0's ndcg@3: 0.978591\tvalid_0's ndcg@4: 0.978828\tvalid_0's ndcg@5: 0.978867\n",
      "[82]\tvalid_0's ndcg@1: 0.94415\tvalid_0's ndcg@2: 0.976911\tvalid_0's ndcg@3: 0.978511\tvalid_0's ndcg@4: 0.978748\tvalid_0's ndcg@5: 0.978787\n",
      "[83]\tvalid_0's ndcg@1: 0.944425\tvalid_0's ndcg@2: 0.977028\tvalid_0's ndcg@3: 0.978616\tvalid_0's ndcg@4: 0.978853\tvalid_0's ndcg@5: 0.978891\n",
      "[84]\tvalid_0's ndcg@1: 0.944925\tvalid_0's ndcg@2: 0.977213\tvalid_0's ndcg@3: 0.978788\tvalid_0's ndcg@4: 0.979035\tvalid_0's ndcg@5: 0.979074\n",
      "[85]\tvalid_0's ndcg@1: 0.9449\tvalid_0's ndcg@2: 0.977219\tvalid_0's ndcg@3: 0.978782\tvalid_0's ndcg@4: 0.97903\tvalid_0's ndcg@5: 0.979068\n",
      "[86]\tvalid_0's ndcg@1: 0.944775\tvalid_0's ndcg@2: 0.977189\tvalid_0's ndcg@3: 0.978739\tvalid_0's ndcg@4: 0.978987\tvalid_0's ndcg@5: 0.979025\n",
      "[87]\tvalid_0's ndcg@1: 0.944975\tvalid_0's ndcg@2: 0.977263\tvalid_0's ndcg@3: 0.978813\tvalid_0's ndcg@4: 0.97906\tvalid_0's ndcg@5: 0.979099\n",
      "[88]\tvalid_0's ndcg@1: 0.945175\tvalid_0's ndcg@2: 0.977305\tvalid_0's ndcg@3: 0.978893\tvalid_0's ndcg@4: 0.979129\tvalid_0's ndcg@5: 0.979168\n",
      "[89]\tvalid_0's ndcg@1: 0.94505\tvalid_0's ndcg@2: 0.977275\tvalid_0's ndcg@3: 0.97885\tvalid_0's ndcg@4: 0.979087\tvalid_0's ndcg@5: 0.979125\n",
      "[90]\tvalid_0's ndcg@1: 0.945125\tvalid_0's ndcg@2: 0.977318\tvalid_0's ndcg@3: 0.978893\tvalid_0's ndcg@4: 0.979119\tvalid_0's ndcg@5: 0.979158\n",
      "[91]\tvalid_0's ndcg@1: 0.94515\tvalid_0's ndcg@2: 0.977327\tvalid_0's ndcg@3: 0.978902\tvalid_0's ndcg@4: 0.979129\tvalid_0's ndcg@5: 0.979167\n",
      "[92]\tvalid_0's ndcg@1: 0.94515\tvalid_0's ndcg@2: 0.977327\tvalid_0's ndcg@3: 0.978902\tvalid_0's ndcg@4: 0.979129\tvalid_0's ndcg@5: 0.979167\n",
      "[93]\tvalid_0's ndcg@1: 0.94525\tvalid_0's ndcg@2: 0.977412\tvalid_0's ndcg@3: 0.978949\tvalid_0's ndcg@4: 0.979175\tvalid_0's ndcg@5: 0.979214\n",
      "[94]\tvalid_0's ndcg@1: 0.945175\tvalid_0's ndcg@2: 0.9774\tvalid_0's ndcg@3: 0.978925\tvalid_0's ndcg@4: 0.979151\tvalid_0's ndcg@5: 0.97919\n",
      "[95]\tvalid_0's ndcg@1: 0.94515\tvalid_0's ndcg@2: 0.977375\tvalid_0's ndcg@3: 0.978912\tvalid_0's ndcg@4: 0.979138\tvalid_0's ndcg@5: 0.979177\n",
      "[96]\tvalid_0's ndcg@1: 0.945475\tvalid_0's ndcg@2: 0.977463\tvalid_0's ndcg@3: 0.979013\tvalid_0's ndcg@4: 0.97925\tvalid_0's ndcg@5: 0.979289\n",
      "[97]\tvalid_0's ndcg@1: 0.94605\tvalid_0's ndcg@2: 0.977691\tvalid_0's ndcg@3: 0.979241\tvalid_0's ndcg@4: 0.979456\tvalid_0's ndcg@5: 0.979514\n",
      "[98]\tvalid_0's ndcg@1: 0.946075\tvalid_0's ndcg@2: 0.977716\tvalid_0's ndcg@3: 0.979254\tvalid_0's ndcg@4: 0.979469\tvalid_0's ndcg@5: 0.979527\n",
      "[99]\tvalid_0's ndcg@1: 0.946025\tvalid_0's ndcg@2: 0.977682\tvalid_0's ndcg@3: 0.979232\tvalid_0's ndcg@4: 0.979458\tvalid_0's ndcg@5: 0.979506\n",
      "[100]\tvalid_0's ndcg@1: 0.946025\tvalid_0's ndcg@2: 0.977666\tvalid_0's ndcg@3: 0.979229\tvalid_0's ndcg@4: 0.979455\tvalid_0's ndcg@5: 0.979503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's ndcg@1: 0.946075\tvalid_0's ndcg@2: 0.977716\tvalid_0's ndcg@3: 0.979254\tvalid_0's ndcg@4: 0.979469\tvalid_0's ndcg@5: 0.979527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@1: 0.910825\tvalid_0's ndcg@2: 0.963949\tvalid_0's ndcg@3: 0.965824\tvalid_0's ndcg@4: 0.966244\tvalid_0's ndcg@5: 0.966302\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.915775\tvalid_0's ndcg@2: 0.965918\tvalid_0's ndcg@3: 0.967831\tvalid_0's ndcg@4: 0.968132\tvalid_0's ndcg@5: 0.968171\n",
      "[3]\tvalid_0's ndcg@1: 0.918325\tvalid_0's ndcg@2: 0.967206\tvalid_0's ndcg@3: 0.968819\tvalid_0's ndcg@4: 0.969142\tvalid_0's ndcg@5: 0.96918\n",
      "[4]\tvalid_0's ndcg@1: 0.922075\tvalid_0's ndcg@2: 0.968527\tvalid_0's ndcg@3: 0.970177\tvalid_0's ndcg@4: 0.9705\tvalid_0's ndcg@5: 0.970539\n",
      "[5]\tvalid_0's ndcg@1: 0.923675\tvalid_0's ndcg@2: 0.969007\tvalid_0's ndcg@3: 0.970757\tvalid_0's ndcg@4: 0.97108\tvalid_0's ndcg@5: 0.971109\n",
      "[6]\tvalid_0's ndcg@1: 0.925\tvalid_0's ndcg@2: 0.969701\tvalid_0's ndcg@3: 0.971301\tvalid_0's ndcg@4: 0.971603\tvalid_0's ndcg@5: 0.971651\n",
      "[7]\tvalid_0's ndcg@1: 0.92725\tvalid_0's ndcg@2: 0.97039\tvalid_0's ndcg@3: 0.972077\tvalid_0's ndcg@4: 0.972411\tvalid_0's ndcg@5: 0.97245\n",
      "[8]\tvalid_0's ndcg@1: 0.9282\tvalid_0's ndcg@2: 0.970851\tvalid_0's ndcg@3: 0.972451\tvalid_0's ndcg@4: 0.972785\tvalid_0's ndcg@5: 0.972823\n",
      "[9]\tvalid_0's ndcg@1: 0.9298\tvalid_0's ndcg@2: 0.971347\tvalid_0's ndcg@3: 0.973022\tvalid_0's ndcg@4: 0.973355\tvalid_0's ndcg@5: 0.973394\n",
      "[10]\tvalid_0's ndcg@1: 0.9302\tvalid_0's ndcg@2: 0.971431\tvalid_0's ndcg@3: 0.973131\tvalid_0's ndcg@4: 0.973476\tvalid_0's ndcg@5: 0.973524\n",
      "[11]\tvalid_0's ndcg@1: 0.930925\tvalid_0's ndcg@2: 0.97173\tvalid_0's ndcg@3: 0.973418\tvalid_0's ndcg@4: 0.973762\tvalid_0's ndcg@5: 0.973801\n",
      "[12]\tvalid_0's ndcg@1: 0.930975\tvalid_0's ndcg@2: 0.971812\tvalid_0's ndcg@3: 0.973412\tvalid_0's ndcg@4: 0.973789\tvalid_0's ndcg@5: 0.973827\n",
      "[13]\tvalid_0's ndcg@1: 0.931725\tvalid_0's ndcg@2: 0.972152\tvalid_0's ndcg@3: 0.973714\tvalid_0's ndcg@4: 0.974059\tvalid_0's ndcg@5: 0.974107\n",
      "[14]\tvalid_0's ndcg@1: 0.932325\tvalid_0's ndcg@2: 0.972436\tvalid_0's ndcg@3: 0.973949\tvalid_0's ndcg@4: 0.974293\tvalid_0's ndcg@5: 0.974342\n",
      "[15]\tvalid_0's ndcg@1: 0.932675\tvalid_0's ndcg@2: 0.972487\tvalid_0's ndcg@3: 0.974037\tvalid_0's ndcg@4: 0.974403\tvalid_0's ndcg@5: 0.974451\n",
      "[16]\tvalid_0's ndcg@1: 0.933075\tvalid_0's ndcg@2: 0.972634\tvalid_0's ndcg@3: 0.974234\tvalid_0's ndcg@4: 0.974547\tvalid_0's ndcg@5: 0.974605\n",
      "[17]\tvalid_0's ndcg@1: 0.9335\tvalid_0's ndcg@2: 0.972838\tvalid_0's ndcg@3: 0.974401\tvalid_0's ndcg@4: 0.974713\tvalid_0's ndcg@5: 0.974771\n",
      "[18]\tvalid_0's ndcg@1: 0.9344\tvalid_0's ndcg@2: 0.973171\tvalid_0's ndcg@3: 0.974758\tvalid_0's ndcg@4: 0.975049\tvalid_0's ndcg@5: 0.975107\n",
      "[19]\tvalid_0's ndcg@1: 0.93465\tvalid_0's ndcg@2: 0.973326\tvalid_0's ndcg@3: 0.974851\tvalid_0's ndcg@4: 0.975152\tvalid_0's ndcg@5: 0.97521\n",
      "[20]\tvalid_0's ndcg@1: 0.935\tvalid_0's ndcg@2: 0.973408\tvalid_0's ndcg@3: 0.974933\tvalid_0's ndcg@4: 0.975267\tvalid_0's ndcg@5: 0.975354\n",
      "[21]\tvalid_0's ndcg@1: 0.934975\tvalid_0's ndcg@2: 0.973351\tvalid_0's ndcg@3: 0.974889\tvalid_0's ndcg@4: 0.975233\tvalid_0's ndcg@5: 0.97533\n",
      "[22]\tvalid_0's ndcg@1: 0.935475\tvalid_0's ndcg@2: 0.973567\tvalid_0's ndcg@3: 0.975067\tvalid_0's ndcg@4: 0.975433\tvalid_0's ndcg@5: 0.975511\n",
      "[23]\tvalid_0's ndcg@1: 0.9356\tvalid_0's ndcg@2: 0.973614\tvalid_0's ndcg@3: 0.975139\tvalid_0's ndcg@4: 0.975483\tvalid_0's ndcg@5: 0.97556\n",
      "[24]\tvalid_0's ndcg@1: 0.93575\tvalid_0's ndcg@2: 0.973716\tvalid_0's ndcg@3: 0.975204\tvalid_0's ndcg@4: 0.975548\tvalid_0's ndcg@5: 0.975626\n",
      "[25]\tvalid_0's ndcg@1: 0.935975\tvalid_0's ndcg@2: 0.973783\tvalid_0's ndcg@3: 0.975283\tvalid_0's ndcg@4: 0.975628\tvalid_0's ndcg@5: 0.975705\n",
      "[26]\tvalid_0's ndcg@1: 0.9367\tvalid_0's ndcg@2: 0.973988\tvalid_0's ndcg@3: 0.975563\tvalid_0's ndcg@4: 0.975907\tvalid_0's ndcg@5: 0.975966\n",
      "[27]\tvalid_0's ndcg@1: 0.937075\tvalid_0's ndcg@2: 0.974126\tvalid_0's ndcg@3: 0.975714\tvalid_0's ndcg@4: 0.976048\tvalid_0's ndcg@5: 0.976106\n",
      "[28]\tvalid_0's ndcg@1: 0.937075\tvalid_0's ndcg@2: 0.974126\tvalid_0's ndcg@3: 0.975714\tvalid_0's ndcg@4: 0.976048\tvalid_0's ndcg@5: 0.976106\n",
      "[29]\tvalid_0's ndcg@1: 0.937475\tvalid_0's ndcg@2: 0.974306\tvalid_0's ndcg@3: 0.975868\tvalid_0's ndcg@4: 0.976202\tvalid_0's ndcg@5: 0.97626\n",
      "[30]\tvalid_0's ndcg@1: 0.9374\tvalid_0's ndcg@2: 0.974278\tvalid_0's ndcg@3: 0.975865\tvalid_0's ndcg@4: 0.976199\tvalid_0's ndcg@5: 0.976247\n",
      "[31]\tvalid_0's ndcg@1: 0.9381\tvalid_0's ndcg@2: 0.97452\tvalid_0's ndcg@3: 0.97612\tvalid_0's ndcg@4: 0.976443\tvalid_0's ndcg@5: 0.976501\n",
      "[32]\tvalid_0's ndcg@1: 0.938225\tvalid_0's ndcg@2: 0.974661\tvalid_0's ndcg@3: 0.976186\tvalid_0's ndcg@4: 0.976509\tvalid_0's ndcg@5: 0.976567\n",
      "[33]\tvalid_0's ndcg@1: 0.938225\tvalid_0's ndcg@2: 0.974645\tvalid_0's ndcg@3: 0.976195\tvalid_0's ndcg@4: 0.976508\tvalid_0's ndcg@5: 0.976566\n",
      "[34]\tvalid_0's ndcg@1: 0.9383\tvalid_0's ndcg@2: 0.974657\tvalid_0's ndcg@3: 0.97622\tvalid_0's ndcg@4: 0.976521\tvalid_0's ndcg@5: 0.976579\n",
      "[35]\tvalid_0's ndcg@1: 0.938625\tvalid_0's ndcg@2: 0.974793\tvalid_0's ndcg@3: 0.976356\tvalid_0's ndcg@4: 0.976657\tvalid_0's ndcg@5: 0.976705\n",
      "[36]\tvalid_0's ndcg@1: 0.938675\tvalid_0's ndcg@2: 0.974843\tvalid_0's ndcg@3: 0.976381\tvalid_0's ndcg@4: 0.976671\tvalid_0's ndcg@5: 0.976729\n",
      "[37]\tvalid_0's ndcg@1: 0.939175\tvalid_0's ndcg@2: 0.975154\tvalid_0's ndcg@3: 0.976591\tvalid_0's ndcg@4: 0.976882\tvalid_0's ndcg@5: 0.97694\n",
      "[38]\tvalid_0's ndcg@1: 0.9392\tvalid_0's ndcg@2: 0.975195\tvalid_0's ndcg@3: 0.976607\tvalid_0's ndcg@4: 0.976898\tvalid_0's ndcg@5: 0.976956\n",
      "[39]\tvalid_0's ndcg@1: 0.938975\tvalid_0's ndcg@2: 0.975096\tvalid_0's ndcg@3: 0.976521\tvalid_0's ndcg@4: 0.976811\tvalid_0's ndcg@5: 0.976869\n",
      "[40]\tvalid_0's ndcg@1: 0.93945\tvalid_0's ndcg@2: 0.975239\tvalid_0's ndcg@3: 0.976714\tvalid_0's ndcg@4: 0.976984\tvalid_0's ndcg@5: 0.977042\n",
      "[41]\tvalid_0's ndcg@1: 0.9396\tvalid_0's ndcg@2: 0.975326\tvalid_0's ndcg@3: 0.976776\tvalid_0's ndcg@4: 0.977046\tvalid_0's ndcg@5: 0.977104\n",
      "[42]\tvalid_0's ndcg@1: 0.940225\tvalid_0's ndcg@2: 0.975557\tvalid_0's ndcg@3: 0.97702\tvalid_0's ndcg@4: 0.977278\tvalid_0's ndcg@5: 0.977336\n",
      "[43]\tvalid_0's ndcg@1: 0.9401\tvalid_0's ndcg@2: 0.975495\tvalid_0's ndcg@3: 0.97697\tvalid_0's ndcg@4: 0.977229\tvalid_0's ndcg@5: 0.977287\n",
      "[44]\tvalid_0's ndcg@1: 0.94045\tvalid_0's ndcg@2: 0.975624\tvalid_0's ndcg@3: 0.977087\tvalid_0's ndcg@4: 0.977356\tvalid_0's ndcg@5: 0.977414\n",
      "[45]\tvalid_0's ndcg@1: 0.9408\tvalid_0's ndcg@2: 0.975738\tvalid_0's ndcg@3: 0.977213\tvalid_0's ndcg@4: 0.977482\tvalid_0's ndcg@5: 0.97754\n",
      "[46]\tvalid_0's ndcg@1: 0.941175\tvalid_0's ndcg@2: 0.975892\tvalid_0's ndcg@3: 0.977354\tvalid_0's ndcg@4: 0.977624\tvalid_0's ndcg@5: 0.977682\n",
      "[47]\tvalid_0's ndcg@1: 0.94145\tvalid_0's ndcg@2: 0.976009\tvalid_0's ndcg@3: 0.977459\tvalid_0's ndcg@4: 0.977728\tvalid_0's ndcg@5: 0.977786\n",
      "[48]\tvalid_0's ndcg@1: 0.94135\tvalid_0's ndcg@2: 0.975972\tvalid_0's ndcg@3: 0.97741\tvalid_0's ndcg@4: 0.97769\tvalid_0's ndcg@5: 0.977748\n",
      "[49]\tvalid_0's ndcg@1: 0.941825\tvalid_0's ndcg@2: 0.976148\tvalid_0's ndcg@3: 0.977585\tvalid_0's ndcg@4: 0.977865\tvalid_0's ndcg@5: 0.977923\n",
      "[50]\tvalid_0's ndcg@1: 0.9418\tvalid_0's ndcg@2: 0.97617\tvalid_0's ndcg@3: 0.97757\tvalid_0's ndcg@4: 0.977861\tvalid_0's ndcg@5: 0.977919\n",
      "[51]\tvalid_0's ndcg@1: 0.9418\tvalid_0's ndcg@2: 0.976154\tvalid_0's ndcg@3: 0.977567\tvalid_0's ndcg@4: 0.977857\tvalid_0's ndcg@5: 0.977915\n",
      "[52]\tvalid_0's ndcg@1: 0.942075\tvalid_0's ndcg@2: 0.976271\tvalid_0's ndcg@3: 0.977659\tvalid_0's ndcg@4: 0.97796\tvalid_0's ndcg@5: 0.978018\n",
      "[53]\tvalid_0's ndcg@1: 0.942125\tvalid_0's ndcg@2: 0.976274\tvalid_0's ndcg@3: 0.977674\tvalid_0's ndcg@4: 0.977976\tvalid_0's ndcg@5: 0.978034\n",
      "[54]\tvalid_0's ndcg@1: 0.942475\tvalid_0's ndcg@2: 0.976451\tvalid_0's ndcg@3: 0.977813\tvalid_0's ndcg@4: 0.978115\tvalid_0's ndcg@5: 0.978173\n",
      "[55]\tvalid_0's ndcg@1: 0.942475\tvalid_0's ndcg@2: 0.976451\tvalid_0's ndcg@3: 0.977813\tvalid_0's ndcg@4: 0.978115\tvalid_0's ndcg@5: 0.978173\n",
      "[56]\tvalid_0's ndcg@1: 0.942575\tvalid_0's ndcg@2: 0.976472\tvalid_0's ndcg@3: 0.977859\tvalid_0's ndcg@4: 0.97815\tvalid_0's ndcg@5: 0.978208\n",
      "[57]\tvalid_0's ndcg@1: 0.942725\tvalid_0's ndcg@2: 0.976527\tvalid_0's ndcg@3: 0.977915\tvalid_0's ndcg@4: 0.978216\tvalid_0's ndcg@5: 0.978264\n",
      "[58]\tvalid_0's ndcg@1: 0.942675\tvalid_0's ndcg@2: 0.976524\tvalid_0's ndcg@3: 0.977912\tvalid_0's ndcg@4: 0.978203\tvalid_0's ndcg@5: 0.978251\n",
      "[59]\tvalid_0's ndcg@1: 0.943075\tvalid_0's ndcg@2: 0.976672\tvalid_0's ndcg@3: 0.97806\tvalid_0's ndcg@4: 0.97835\tvalid_0's ndcg@5: 0.978399\n",
      "[60]\tvalid_0's ndcg@1: 0.94305\tvalid_0's ndcg@2: 0.976631\tvalid_0's ndcg@3: 0.978044\tvalid_0's ndcg@4: 0.978334\tvalid_0's ndcg@5: 0.978383\n",
      "[61]\tvalid_0's ndcg@1: 0.943425\tvalid_0's ndcg@2: 0.976754\tvalid_0's ndcg@3: 0.978179\tvalid_0's ndcg@4: 0.97847\tvalid_0's ndcg@5: 0.978518\n",
      "[62]\tvalid_0's ndcg@1: 0.9435\tvalid_0's ndcg@2: 0.976782\tvalid_0's ndcg@3: 0.978219\tvalid_0's ndcg@4: 0.978499\tvalid_0's ndcg@5: 0.978547\n",
      "[63]\tvalid_0's ndcg@1: 0.9439\tvalid_0's ndcg@2: 0.976929\tvalid_0's ndcg@3: 0.978367\tvalid_0's ndcg@4: 0.978647\tvalid_0's ndcg@5: 0.978695\n",
      "[64]\tvalid_0's ndcg@1: 0.944125\tvalid_0's ndcg@2: 0.976981\tvalid_0's ndcg@3: 0.978443\tvalid_0's ndcg@4: 0.978723\tvalid_0's ndcg@5: 0.978771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65]\tvalid_0's ndcg@1: 0.94435\tvalid_0's ndcg@2: 0.977079\tvalid_0's ndcg@3: 0.978529\tvalid_0's ndcg@4: 0.978809\tvalid_0's ndcg@5: 0.978858\n",
      "[66]\tvalid_0's ndcg@1: 0.9443\tvalid_0's ndcg@2: 0.977077\tvalid_0's ndcg@3: 0.978514\tvalid_0's ndcg@4: 0.978805\tvalid_0's ndcg@5: 0.978853\n",
      "[67]\tvalid_0's ndcg@1: 0.944675\tvalid_0's ndcg@2: 0.977215\tvalid_0's ndcg@3: 0.978653\tvalid_0's ndcg@4: 0.978943\tvalid_0's ndcg@5: 0.978992\n",
      "[68]\tvalid_0's ndcg@1: 0.9448\tvalid_0's ndcg@2: 0.977293\tvalid_0's ndcg@3: 0.978693\tvalid_0's ndcg@4: 0.979005\tvalid_0's ndcg@5: 0.979044\n",
      "[69]\tvalid_0's ndcg@1: 0.94495\tvalid_0's ndcg@2: 0.977332\tvalid_0's ndcg@3: 0.978745\tvalid_0's ndcg@4: 0.979057\tvalid_0's ndcg@5: 0.979096\n",
      "[70]\tvalid_0's ndcg@1: 0.945025\tvalid_0's ndcg@2: 0.97736\tvalid_0's ndcg@3: 0.978773\tvalid_0's ndcg@4: 0.979085\tvalid_0's ndcg@5: 0.979124\n",
      "[71]\tvalid_0's ndcg@1: 0.9452\tvalid_0's ndcg@2: 0.977409\tvalid_0's ndcg@3: 0.978834\tvalid_0's ndcg@4: 0.979146\tvalid_0's ndcg@5: 0.979185\n",
      "[72]\tvalid_0's ndcg@1: 0.945325\tvalid_0's ndcg@2: 0.977471\tvalid_0's ndcg@3: 0.978896\tvalid_0's ndcg@4: 0.979197\tvalid_0's ndcg@5: 0.979236\n",
      "[73]\tvalid_0's ndcg@1: 0.945475\tvalid_0's ndcg@2: 0.97751\tvalid_0's ndcg@3: 0.978948\tvalid_0's ndcg@4: 0.979249\tvalid_0's ndcg@5: 0.979288\n",
      "[74]\tvalid_0's ndcg@1: 0.94545\tvalid_0's ndcg@2: 0.977517\tvalid_0's ndcg@3: 0.978942\tvalid_0's ndcg@4: 0.979243\tvalid_0's ndcg@5: 0.979282\n",
      "[75]\tvalid_0's ndcg@1: 0.9455\tvalid_0's ndcg@2: 0.977551\tvalid_0's ndcg@3: 0.978964\tvalid_0's ndcg@4: 0.979265\tvalid_0's ndcg@5: 0.979304\n",
      "[76]\tvalid_0's ndcg@1: 0.9458\tvalid_0's ndcg@2: 0.977678\tvalid_0's ndcg@3: 0.979078\tvalid_0's ndcg@4: 0.979379\tvalid_0's ndcg@5: 0.979418\n",
      "[77]\tvalid_0's ndcg@1: 0.945775\tvalid_0's ndcg@2: 0.977621\tvalid_0's ndcg@3: 0.979046\tvalid_0's ndcg@4: 0.979358\tvalid_0's ndcg@5: 0.979397\n",
      "[78]\tvalid_0's ndcg@1: 0.945775\tvalid_0's ndcg@2: 0.977668\tvalid_0's ndcg@3: 0.979068\tvalid_0's ndcg@4: 0.97937\tvalid_0's ndcg@5: 0.979409\n",
      "[79]\tvalid_0's ndcg@1: 0.9458\tvalid_0's ndcg@2: 0.977662\tvalid_0's ndcg@3: 0.979074\tvalid_0's ndcg@4: 0.979376\tvalid_0's ndcg@5: 0.979415\n",
      "[80]\tvalid_0's ndcg@1: 0.945975\tvalid_0's ndcg@2: 0.977711\tvalid_0's ndcg@3: 0.979136\tvalid_0's ndcg@4: 0.979437\tvalid_0's ndcg@5: 0.979476\n",
      "[81]\tvalid_0's ndcg@1: 0.946425\tvalid_0's ndcg@2: 0.977893\tvalid_0's ndcg@3: 0.979318\tvalid_0's ndcg@4: 0.979608\tvalid_0's ndcg@5: 0.979647\n",
      "[82]\tvalid_0's ndcg@1: 0.9463\tvalid_0's ndcg@2: 0.977846\tvalid_0's ndcg@3: 0.979271\tvalid_0's ndcg@4: 0.979562\tvalid_0's ndcg@5: 0.979601\n",
      "[83]\tvalid_0's ndcg@1: 0.94635\tvalid_0's ndcg@2: 0.977881\tvalid_0's ndcg@3: 0.979293\tvalid_0's ndcg@4: 0.979584\tvalid_0's ndcg@5: 0.979623\n",
      "[84]\tvalid_0's ndcg@1: 0.946375\tvalid_0's ndcg@2: 0.97789\tvalid_0's ndcg@3: 0.979302\tvalid_0's ndcg@4: 0.979593\tvalid_0's ndcg@5: 0.979632\n",
      "[85]\tvalid_0's ndcg@1: 0.9465\tvalid_0's ndcg@2: 0.977936\tvalid_0's ndcg@3: 0.979336\tvalid_0's ndcg@4: 0.979638\tvalid_0's ndcg@5: 0.979676\n",
      "[86]\tvalid_0's ndcg@1: 0.94655\tvalid_0's ndcg@2: 0.977939\tvalid_0's ndcg@3: 0.979351\tvalid_0's ndcg@4: 0.979653\tvalid_0's ndcg@5: 0.979691\n",
      "[87]\tvalid_0's ndcg@1: 0.946475\tvalid_0's ndcg@2: 0.977911\tvalid_0's ndcg@3: 0.979324\tvalid_0's ndcg@4: 0.979625\tvalid_0's ndcg@5: 0.979664\n",
      "[88]\tvalid_0's ndcg@1: 0.946725\tvalid_0's ndcg@2: 0.978035\tvalid_0's ndcg@3: 0.979422\tvalid_0's ndcg@4: 0.979724\tvalid_0's ndcg@5: 0.979763\n",
      "[89]\tvalid_0's ndcg@1: 0.946925\tvalid_0's ndcg@2: 0.978109\tvalid_0's ndcg@3: 0.979496\tvalid_0's ndcg@4: 0.979798\tvalid_0's ndcg@5: 0.979836\n",
      "[90]\tvalid_0's ndcg@1: 0.946875\tvalid_0's ndcg@2: 0.978106\tvalid_0's ndcg@3: 0.979481\tvalid_0's ndcg@4: 0.979782\tvalid_0's ndcg@5: 0.979821\n",
      "[91]\tvalid_0's ndcg@1: 0.947\tvalid_0's ndcg@2: 0.978136\tvalid_0's ndcg@3: 0.979524\tvalid_0's ndcg@4: 0.979825\tvalid_0's ndcg@5: 0.979864\n",
      "[92]\tvalid_0's ndcg@1: 0.9471\tvalid_0's ndcg@2: 0.978205\tvalid_0's ndcg@3: 0.97958\tvalid_0's ndcg@4: 0.979871\tvalid_0's ndcg@5: 0.979909\n",
      "[93]\tvalid_0's ndcg@1: 0.9468\tvalid_0's ndcg@2: 0.978094\tvalid_0's ndcg@3: 0.979469\tvalid_0's ndcg@4: 0.97976\tvalid_0's ndcg@5: 0.979799\n",
      "[94]\tvalid_0's ndcg@1: 0.946775\tvalid_0's ndcg@2: 0.978116\tvalid_0's ndcg@3: 0.979466\tvalid_0's ndcg@4: 0.979757\tvalid_0's ndcg@5: 0.979796\n",
      "[95]\tvalid_0's ndcg@1: 0.94685\tvalid_0's ndcg@2: 0.978144\tvalid_0's ndcg@3: 0.979494\tvalid_0's ndcg@4: 0.979785\tvalid_0's ndcg@5: 0.979824\n",
      "[96]\tvalid_0's ndcg@1: 0.947075\tvalid_0's ndcg@2: 0.978274\tvalid_0's ndcg@3: 0.979599\tvalid_0's ndcg@4: 0.979879\tvalid_0's ndcg@5: 0.979918\n",
      "[97]\tvalid_0's ndcg@1: 0.9471\tvalid_0's ndcg@2: 0.978252\tvalid_0's ndcg@3: 0.979602\tvalid_0's ndcg@4: 0.979882\tvalid_0's ndcg@5: 0.979921\n",
      "[98]\tvalid_0's ndcg@1: 0.94715\tvalid_0's ndcg@2: 0.978255\tvalid_0's ndcg@3: 0.979617\tvalid_0's ndcg@4: 0.979897\tvalid_0's ndcg@5: 0.979936\n",
      "[99]\tvalid_0's ndcg@1: 0.9469\tvalid_0's ndcg@2: 0.978147\tvalid_0's ndcg@3: 0.979522\tvalid_0's ndcg@4: 0.979802\tvalid_0's ndcg@5: 0.97984\n",
      "[100]\tvalid_0's ndcg@1: 0.9472\tvalid_0's ndcg@2: 0.978273\tvalid_0's ndcg@3: 0.979636\tvalid_0's ndcg@4: 0.979916\tvalid_0's ndcg@5: 0.979954\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's ndcg@1: 0.9472\tvalid_0's ndcg@2: 0.978273\tvalid_0's ndcg@3: 0.979636\tvalid_0's ndcg@4: 0.979916\tvalid_0's ndcg@5: 0.979954\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id','label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 训练集与验证集的用户分组\n",
    "    train_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_train = train_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = valid_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    \n",
    "    # 定义模型\n",
    "    lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)  \n",
    "    # 训练模型\n",
    "    lgb_ranker.fit(train_idx[lgb_cols], train_idx['label'], group=g_train,\n",
    "                   eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], eval_group= [g_val], \n",
    "                   eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_ranker.predict(valid_idx[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "    \n",
    "    # 对输出结果进行归一化\n",
    "    valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_ranker.predict(tst_user_item_feats_df_rank_model[lgb_cols], lgb_ranker.best_iteration_)\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_ranker_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_ranker_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:22:52.604397Z",
     "start_time": "2020-11-18T04:22:43.253034Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "# 单模型生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:22:58.259730Z",
     "start_time": "2020-11-18T04:22:58.254297Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型及参数的定义\n",
    "lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=500, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:23:11.258774Z",
     "start_time": "2020-11-18T04:23:00.861936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 64190, number of negative: 226880\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046243\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000150 seconds, init for row-wise cost 0.010592 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4130\n",
      "[LightGBM] [Info] Number of data points in the train set: 291070, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220531 -> initscore=-1.262574\n",
      "[LightGBM] [Info] Start training from score -1.262574\n",
      "[LightGBM] [Debug] Re-bagging, using 203746 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203356 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203636 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203579 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203670 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204193 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203611 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204099 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203920 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203774 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203529 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203935 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203994 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203762 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203442 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204102 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203773 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203966 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203849 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204089 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203379 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203559 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203463 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204333 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203793 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204212 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203805 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203460 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203316 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203938 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203813 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203498 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203840 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203613 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203635 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203783 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203871 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203679 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203740 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203908 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204177 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203749 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203722 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203708 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203883 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203713 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203525 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203163 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203605 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203816 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203517 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203314 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204190 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203348 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203941 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203403 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203888 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203998 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203665 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204423 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203505 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203696 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203854 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203908 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203491 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203822 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203684 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203833 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203551 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203418 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203446 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203681 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 203552 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203343 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203529 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203833 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203863 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203958 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203654 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203833 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204250 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203590 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203663 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203756 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203767 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203361 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203972 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203746 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203055 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204012 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203893 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204042 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203816 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204173 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203821 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204030 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203857 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203415 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203557 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203313 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203595 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203818 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203500 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203998 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203582 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203657 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203791 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203371 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204039 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203756 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203812 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203620 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204021 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203169 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203681 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203613 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204204 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203534 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203694 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203773 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203833 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203508 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203776 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203474 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203953 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203476 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204110 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203722 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203829 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203830 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203586 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203585 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203410 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203959 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203682 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203702 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204033 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204128 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203725 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203652 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203766 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203871 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203810 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203830 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203660 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203770 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203906 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203862 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203737 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203734 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203766 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203365 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203757 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203811 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203148 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203654 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203675 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203639 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203674 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204155 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203903 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203993 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203668 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203520 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203732 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203617 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203804 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204055 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203590 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204171 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203757 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203630 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203876 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203343 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204142 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203731 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203399 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203745 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203789 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203957 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203691 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203540 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203587 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203656 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204140 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204042 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203743 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203987 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204031 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203442 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203996 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203745 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203800 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203855 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204111 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203881 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203952 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203447 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203753 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204074 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203540 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203745 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203521 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203975 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203707 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203876 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203472 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203832 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203527 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203750 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203596 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203674 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203469 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203738 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203747 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203563 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204217 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204220 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203850 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203035 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203953 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203485 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 204036 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203448 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203792 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204069 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203389 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204182 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204253 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204035 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203368 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203608 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203984 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203808 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203490 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203563 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203758 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203647 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203754 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203417 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203439 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203685 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203503 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203481 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203604 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204132 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203401 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203770 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203764 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204118 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204017 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204357 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204204 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203887 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203547 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204332 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203868 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203697 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203287 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204091 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203587 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203919 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203310 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204057 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203922 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203652 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203567 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203748 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204003 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203466 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203464 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203623 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203685 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203943 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203506 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203976 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 203885 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203934 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203915 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203504 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203787 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203947 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203839 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203748 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203894 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203770 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203304 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203301 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203787 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203590 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203281 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203768 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 203572 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203996 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203883 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204011 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203742 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203502 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203686 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204038 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203689 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203693 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203819 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203890 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203804 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 203910 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204036 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204065 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204029 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203726 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203666 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204083 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203421 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203401 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204096 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203864 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204102 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203812 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203844 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203615 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204003 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203675 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204096 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204251 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203436 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203782 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204168 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203738 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203444 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203636 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203803 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203555 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203472 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203927 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203722 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203250 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203824 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203679 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204094 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203855 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204102 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204058 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203561 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203869 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203560 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203830 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203599 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204048 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203372 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203952 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203597 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203820 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203516 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203803 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203353 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203838 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203974 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203413 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203429 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203904 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203800 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203642 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 203836 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203848 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203785 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203895 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203691 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203642 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204251 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203879 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203524 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203461 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203835 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203565 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203301 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204006 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 203266 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203591 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203839 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203506 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203668 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203771 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203991 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203798 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 203608 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203945 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203758 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204117 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203730 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203697 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 204112 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204144 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203752 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203703 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203314 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203973 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203897 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203969 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203628 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203669 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204055 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203726 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203489 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203826 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203787 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203621 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 203856 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203889 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203656 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 204061 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203897 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203603 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203583 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 203727 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203477 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203437 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204053 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203860 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204015 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203597 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203547 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203959 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203814 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203343 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203809 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203935 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204020 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203702 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203368 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 204097 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203425 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203959 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203710 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203520 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203201 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203955 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203504 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203705 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203586 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203437 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203456 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203974 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203824 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203658 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203761 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203326 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203713 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203695 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204024 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203534 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203759 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203252 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203883 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203427 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203606 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204331 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203305 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203870 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204070 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203756 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203543 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203422 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204080 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204146 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203537 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203877 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203631 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203894 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203375 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 203351 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203564 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203409 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203495 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203511 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204267 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203426 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203492 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 203513 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203682 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203700 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203583 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203854 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204169 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203883 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203426 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203696 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203950 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203355 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203733 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203665 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 203657 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 204151 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203511 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204275 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203124 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203348 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203670 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203527 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204097 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "if offline:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'],\n",
    "                    eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                    eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:23:19.591396Z",
     "start_time": "2020-11-18T04:23:13.813850Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df['pred_score'] = lgb_Classfication.predict_proba(tst_user_item_feats_df[lgb_cols])[:,1]\n",
    "\n",
    "# 将这里的排序结果保存一份，用户后面的模型融合\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'lgb_cls_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:23:32.352931Z",
     "start_time": "2020-11-18T04:23:22.346609Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:24:11.241196Z",
     "start_time": "2020-11-18T04:23:41.377394Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 51564, number of negative: 181388\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046205\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000121 seconds, init for row-wise cost 0.008484 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4132\n",
      "[LightGBM] [Info] Number of data points in the train set: 232952, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221350 -> initscore=-1.257815\n",
      "[LightGBM] [Info] Start training from score -1.257815\n",
      "[LightGBM] [Debug] Re-bagging, using 163211 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[1]\tvalid_0's auc: 0.763708\tvalid_0's binary_logloss: 0.521805\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 162839 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[2]\tvalid_0's auc: 0.777195\tvalid_0's binary_logloss: 0.520771\n",
      "[LightGBM] [Debug] Re-bagging, using 162808 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[3]\tvalid_0's auc: 0.78016\tvalid_0's binary_logloss: 0.519645\n",
      "[LightGBM] [Debug] Re-bagging, using 162852 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[4]\tvalid_0's auc: 0.789073\tvalid_0's binary_logloss: 0.518\n",
      "[LightGBM] [Debug] Re-bagging, using 162977 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[5]\tvalid_0's auc: 0.79089\tvalid_0's binary_logloss: 0.516466\n",
      "[LightGBM] [Debug] Re-bagging, using 163451 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[6]\tvalid_0's auc: 0.794045\tvalid_0's binary_logloss: 0.515177\n",
      "[LightGBM] [Debug] Re-bagging, using 162826 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[7]\tvalid_0's auc: 0.79507\tvalid_0's binary_logloss: 0.513626\n",
      "[LightGBM] [Debug] Re-bagging, using 163228 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[8]\tvalid_0's auc: 0.795227\tvalid_0's binary_logloss: 0.512758\n",
      "[LightGBM] [Debug] Re-bagging, using 163218 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[9]\tvalid_0's auc: 0.795475\tvalid_0's binary_logloss: 0.511317\n",
      "[LightGBM] [Debug] Re-bagging, using 163058 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[10]\tvalid_0's auc: 0.798329\tvalid_0's binary_logloss: 0.509931\n",
      "[LightGBM] [Debug] Re-bagging, using 162793 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[11]\tvalid_0's auc: 0.798345\tvalid_0's binary_logloss: 0.508945\n",
      "[LightGBM] [Debug] Re-bagging, using 163249 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[12]\tvalid_0's auc: 0.798429\tvalid_0's binary_logloss: 0.508048\n",
      "[LightGBM] [Debug] Re-bagging, using 163340 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[13]\tvalid_0's auc: 0.798256\tvalid_0's binary_logloss: 0.506716\n",
      "[LightGBM] [Debug] Re-bagging, using 163138 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[14]\tvalid_0's auc: 0.798712\tvalid_0's binary_logloss: 0.505295\n",
      "[LightGBM] [Debug] Re-bagging, using 162876 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[15]\tvalid_0's auc: 0.800737\tvalid_0's binary_logloss: 0.504003\n",
      "[LightGBM] [Debug] Re-bagging, using 163428 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[16]\tvalid_0's auc: 0.801815\tvalid_0's binary_logloss: 0.50262\n",
      "[LightGBM] [Debug] Re-bagging, using 163163 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[17]\tvalid_0's auc: 0.80209\tvalid_0's binary_logloss: 0.501508\n",
      "[LightGBM] [Debug] Re-bagging, using 163276 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[18]\tvalid_0's auc: 0.802225\tvalid_0's binary_logloss: 0.500627\n",
      "[LightGBM] [Debug] Re-bagging, using 163079 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[19]\tvalid_0's auc: 0.802707\tvalid_0's binary_logloss: 0.499351\n",
      "[LightGBM] [Debug] Re-bagging, using 163208 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[20]\tvalid_0's auc: 0.803036\tvalid_0's binary_logloss: 0.498834\n",
      "[LightGBM] [Debug] Re-bagging, using 162764 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[21]\tvalid_0's auc: 0.804084\tvalid_0's binary_logloss: 0.497625\n",
      "[LightGBM] [Debug] Re-bagging, using 162942 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[22]\tvalid_0's auc: 0.804183\tvalid_0's binary_logloss: 0.496561\n",
      "[LightGBM] [Debug] Re-bagging, using 162887 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[23]\tvalid_0's auc: 0.803898\tvalid_0's binary_logloss: 0.495384\n",
      "[LightGBM] [Debug] Re-bagging, using 163690 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[24]\tvalid_0's auc: 0.804265\tvalid_0's binary_logloss: 0.49416\n",
      "[LightGBM] [Debug] Re-bagging, using 163057 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[25]\tvalid_0's auc: 0.805151\tvalid_0's binary_logloss: 0.493047\n",
      "[LightGBM] [Debug] Re-bagging, using 163424 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[26]\tvalid_0's auc: 0.805386\tvalid_0's binary_logloss: 0.491882\n",
      "[LightGBM] [Debug] Re-bagging, using 163186 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[27]\tvalid_0's auc: 0.805745\tvalid_0's binary_logloss: 0.49083\n",
      "[LightGBM] [Debug] Re-bagging, using 162685 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[28]\tvalid_0's auc: 0.805994\tvalid_0's binary_logloss: 0.489688\n",
      "[LightGBM] [Debug] Re-bagging, using 162850 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[29]\tvalid_0's auc: 0.806185\tvalid_0's binary_logloss: 0.488569\n",
      "[LightGBM] [Debug] Re-bagging, using 163123 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[30]\tvalid_0's auc: 0.806113\tvalid_0's binary_logloss: 0.487484\n",
      "[LightGBM] [Debug] Re-bagging, using 163011 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[31]\tvalid_0's auc: 0.807748\tvalid_0's binary_logloss: 0.486285\n",
      "[LightGBM] [Debug] Re-bagging, using 162826 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[32]\tvalid_0's auc: 0.808095\tvalid_0's binary_logloss: 0.485246\n",
      "[LightGBM] [Debug] Re-bagging, using 163027 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[33]\tvalid_0's auc: 0.80802\tvalid_0's binary_logloss: 0.484199\n",
      "[LightGBM] [Debug] Re-bagging, using 162790 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[34]\tvalid_0's auc: 0.808207\tvalid_0's binary_logloss: 0.483488\n",
      "[LightGBM] [Debug] Re-bagging, using 162940 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[35]\tvalid_0's auc: 0.808329\tvalid_0's binary_logloss: 0.482451\n",
      "[LightGBM] [Debug] Re-bagging, using 162996 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[36]\tvalid_0's auc: 0.80876\tvalid_0's binary_logloss: 0.481776\n",
      "[LightGBM] [Debug] Re-bagging, using 163113 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[37]\tvalid_0's auc: 0.808966\tvalid_0's binary_logloss: 0.481111\n",
      "[LightGBM] [Debug] Re-bagging, using 162868 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[38]\tvalid_0's auc: 0.809279\tvalid_0's binary_logloss: 0.48007\n",
      "[LightGBM] [Debug] Re-bagging, using 163155 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[39]\tvalid_0's auc: 0.809504\tvalid_0's binary_logloss: 0.479112\n",
      "[LightGBM] [Debug] Re-bagging, using 163018 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[40]\tvalid_0's auc: 0.810022\tvalid_0's binary_logloss: 0.478487\n",
      "[LightGBM] [Debug] Re-bagging, using 163586 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[41]\tvalid_0's auc: 0.810063\tvalid_0's binary_logloss: 0.477864\n",
      "[LightGBM] [Debug] Re-bagging, using 163085 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[42]\tvalid_0's auc: 0.810169\tvalid_0's binary_logloss: 0.476924\n",
      "[LightGBM] [Debug] Re-bagging, using 163081 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[43]\tvalid_0's auc: 0.810119\tvalid_0's binary_logloss: 0.475989\n",
      "[LightGBM] [Debug] Re-bagging, using 163002 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[44]\tvalid_0's auc: 0.81063\tvalid_0's binary_logloss: 0.475067\n",
      "[LightGBM] [Debug] Re-bagging, using 163338 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[45]\tvalid_0's auc: 0.810809\tvalid_0's binary_logloss: 0.47445\n",
      "[LightGBM] [Debug] Re-bagging, using 163024 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46]\tvalid_0's auc: 0.810714\tvalid_0's binary_logloss: 0.473597\n",
      "[LightGBM] [Debug] Re-bagging, using 162961 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[47]\tvalid_0's auc: 0.810831\tvalid_0's binary_logloss: 0.47269\n",
      "[LightGBM] [Debug] Re-bagging, using 162636 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[48]\tvalid_0's auc: 0.810988\tvalid_0's binary_logloss: 0.471914\n",
      "[LightGBM] [Debug] Re-bagging, using 163156 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[49]\tvalid_0's auc: 0.811313\tvalid_0's binary_logloss: 0.471482\n",
      "[LightGBM] [Debug] Re-bagging, using 163027 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[50]\tvalid_0's auc: 0.811468\tvalid_0's binary_logloss: 0.471081\n",
      "[LightGBM] [Debug] Re-bagging, using 162822 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[51]\tvalid_0's auc: 0.811767\tvalid_0's binary_logloss: 0.470239\n",
      "[LightGBM] [Debug] Re-bagging, using 162693 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[52]\tvalid_0's auc: 0.811871\tvalid_0's binary_logloss: 0.469432\n",
      "[LightGBM] [Debug] Re-bagging, using 163258 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[53]\tvalid_0's auc: 0.811774\tvalid_0's binary_logloss: 0.46863\n",
      "[LightGBM] [Debug] Re-bagging, using 162848 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[54]\tvalid_0's auc: 0.811808\tvalid_0's binary_logloss: 0.467819\n",
      "[LightGBM] [Debug] Re-bagging, using 163228 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[55]\tvalid_0's auc: 0.81202\tvalid_0's binary_logloss: 0.467282\n",
      "[LightGBM] [Debug] Re-bagging, using 162911 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[56]\tvalid_0's auc: 0.811944\tvalid_0's binary_logloss: 0.466543\n",
      "[LightGBM] [Debug] Re-bagging, using 163185 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[57]\tvalid_0's auc: 0.811953\tvalid_0's binary_logloss: 0.465734\n",
      "[LightGBM] [Debug] Re-bagging, using 163341 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[58]\tvalid_0's auc: 0.812233\tvalid_0's binary_logloss: 0.465188\n",
      "[LightGBM] [Debug] Re-bagging, using 162965 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[59]\tvalid_0's auc: 0.812568\tvalid_0's binary_logloss: 0.464381\n",
      "[LightGBM] [Debug] Re-bagging, using 163476 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[60]\tvalid_0's auc: 0.812493\tvalid_0's binary_logloss: 0.463659\n",
      "[LightGBM] [Debug] Re-bagging, using 162901 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[61]\tvalid_0's auc: 0.812426\tvalid_0's binary_logloss: 0.462946\n",
      "[LightGBM] [Debug] Re-bagging, using 163039 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[62]\tvalid_0's auc: 0.812706\tvalid_0's binary_logloss: 0.462212\n",
      "[LightGBM] [Debug] Re-bagging, using 163165 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[63]\tvalid_0's auc: 0.813145\tvalid_0's binary_logloss: 0.461653\n",
      "[LightGBM] [Debug] Re-bagging, using 163091 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[64]\tvalid_0's auc: 0.813286\tvalid_0's binary_logloss: 0.460918\n",
      "[LightGBM] [Debug] Re-bagging, using 162757 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[65]\tvalid_0's auc: 0.813534\tvalid_0's binary_logloss: 0.460161\n",
      "[LightGBM] [Debug] Re-bagging, using 163019 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[66]\tvalid_0's auc: 0.813761\tvalid_0's binary_logloss: 0.459491\n",
      "[LightGBM] [Debug] Re-bagging, using 162920 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[67]\tvalid_0's auc: 0.813829\tvalid_0's binary_logloss: 0.458801\n",
      "[LightGBM] [Debug] Re-bagging, using 163218 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[68]\tvalid_0's auc: 0.813949\tvalid_0's binary_logloss: 0.458398\n",
      "[LightGBM] [Debug] Re-bagging, using 162762 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[69]\tvalid_0's auc: 0.814107\tvalid_0's binary_logloss: 0.457741\n",
      "[LightGBM] [Debug] Re-bagging, using 162834 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[70]\tvalid_0's auc: 0.8142\tvalid_0's binary_logloss: 0.457316\n",
      "[LightGBM] [Debug] Re-bagging, using 162686 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[71]\tvalid_0's auc: 0.814374\tvalid_0's binary_logloss: 0.456833\n",
      "[LightGBM] [Debug] Re-bagging, using 162881 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[72]\tvalid_0's auc: 0.814567\tvalid_0's binary_logloss: 0.456237\n",
      "[LightGBM] [Debug] Re-bagging, using 162994 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[73]\tvalid_0's auc: 0.814633\tvalid_0's binary_logloss: 0.455579\n",
      "[LightGBM] [Debug] Re-bagging, using 162821 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[74]\tvalid_0's auc: 0.8148\tvalid_0's binary_logloss: 0.454972\n",
      "[LightGBM] [Debug] Re-bagging, using 162921 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[75]\tvalid_0's auc: 0.81492\tvalid_0's binary_logloss: 0.454295\n",
      "[LightGBM] [Debug] Re-bagging, using 163165 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[76]\tvalid_0's auc: 0.815002\tvalid_0's binary_logloss: 0.453658\n",
      "[LightGBM] [Debug] Re-bagging, using 162975 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[77]\tvalid_0's auc: 0.815146\tvalid_0's binary_logloss: 0.45323\n",
      "[LightGBM] [Debug] Re-bagging, using 162989 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[78]\tvalid_0's auc: 0.815312\tvalid_0's binary_logloss: 0.452631\n",
      "[LightGBM] [Debug] Re-bagging, using 162814 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[79]\tvalid_0's auc: 0.815567\tvalid_0's binary_logloss: 0.45202\n",
      "[LightGBM] [Debug] Re-bagging, using 163083 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[80]\tvalid_0's auc: 0.815722\tvalid_0's binary_logloss: 0.451679\n",
      "[LightGBM] [Debug] Re-bagging, using 163492 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[81]\tvalid_0's auc: 0.816308\tvalid_0's binary_logloss: 0.451249\n",
      "[LightGBM] [Debug] Re-bagging, using 162908 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[82]\tvalid_0's auc: 0.816426\tvalid_0's binary_logloss: 0.450674\n",
      "[LightGBM] [Debug] Re-bagging, using 163009 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[83]\tvalid_0's auc: 0.816418\tvalid_0's binary_logloss: 0.450088\n",
      "[LightGBM] [Debug] Re-bagging, using 163001 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[84]\tvalid_0's auc: 0.816669\tvalid_0's binary_logloss: 0.449445\n",
      "[LightGBM] [Debug] Re-bagging, using 163091 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[85]\tvalid_0's auc: 0.816802\tvalid_0's binary_logloss: 0.449041\n",
      "[LightGBM] [Debug] Re-bagging, using 162777 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[86]\tvalid_0's auc: 0.816973\tvalid_0's binary_logloss: 0.448462\n",
      "[LightGBM] [Debug] Re-bagging, using 163269 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[87]\tvalid_0's auc: 0.817026\tvalid_0's binary_logloss: 0.447925\n",
      "[LightGBM] [Debug] Re-bagging, using 163046 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[88]\tvalid_0's auc: 0.817161\tvalid_0's binary_logloss: 0.447544\n",
      "[LightGBM] [Debug] Re-bagging, using 162398 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[89]\tvalid_0's auc: 0.817264\tvalid_0's binary_logloss: 0.446977\n",
      "[LightGBM] [Debug] Re-bagging, using 163219 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[90]\tvalid_0's auc: 0.817311\tvalid_0's binary_logloss: 0.446419\n",
      "[LightGBM] [Debug] Re-bagging, using 163343 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[91]\tvalid_0's auc: 0.817517\tvalid_0's binary_logloss: 0.446073\n",
      "[LightGBM] [Debug] Re-bagging, using 163291 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[92]\tvalid_0's auc: 0.817566\tvalid_0's binary_logloss: 0.445544\n",
      "[LightGBM] [Debug] Re-bagging, using 163030 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[93]\tvalid_0's auc: 0.817562\tvalid_0's binary_logloss: 0.445018\n",
      "[LightGBM] [Debug] Re-bagging, using 163336 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[94]\tvalid_0's auc: 0.81764\tvalid_0's binary_logloss: 0.444523\n",
      "[LightGBM] [Debug] Re-bagging, using 163064 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[95]\tvalid_0's auc: 0.817718\tvalid_0's binary_logloss: 0.44402\n",
      "[LightGBM] [Debug] Re-bagging, using 163176 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[96]\tvalid_0's auc: 0.818128\tvalid_0's binary_logloss: 0.443627\n",
      "[LightGBM] [Debug] Re-bagging, using 163058 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[97]\tvalid_0's auc: 0.818555\tvalid_0's binary_logloss: 0.443217\n",
      "[LightGBM] [Debug] Re-bagging, using 162727 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[98]\tvalid_0's auc: 0.818603\tvalid_0's binary_logloss: 0.44271\n",
      "[LightGBM] [Debug] Re-bagging, using 162827 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[99]\tvalid_0's auc: 0.81869\tvalid_0's binary_logloss: 0.442437\n",
      "[LightGBM] [Debug] Re-bagging, using 162752 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[100]\tvalid_0's auc: 0.818853\tvalid_0's binary_logloss: 0.44209\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.818853\tvalid_0's binary_logloss: 0.44209\n",
      "[LightGBM] [Info] Number of positive: 51261, number of negative: 181452\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046223\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000125 seconds, init for row-wise cost 0.008506 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4129\n",
      "[LightGBM] [Info] Number of data points in the train set: 232713, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220276 -> initscore=-1.264061\n",
      "[LightGBM] [Info] Start training from score -1.264061\n",
      "[LightGBM] [Debug] Re-bagging, using 163037 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[1]\tvalid_0's auc: 0.769003\tvalid_0's binary_logloss: 0.527166\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 162677 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[2]\tvalid_0's auc: 0.783373\tvalid_0's binary_logloss: 0.526118\n",
      "[LightGBM] [Debug] Re-bagging, using 162642 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[3]\tvalid_0's auc: 0.781297\tvalid_0's binary_logloss: 0.524938\n",
      "[LightGBM] [Debug] Re-bagging, using 162685 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[4]\tvalid_0's auc: 0.79217\tvalid_0's binary_logloss: 0.523259\n",
      "[LightGBM] [Debug] Re-bagging, using 162829 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[5]\tvalid_0's auc: 0.795382\tvalid_0's binary_logloss: 0.521624\n",
      "[LightGBM] [Debug] Re-bagging, using 163277 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[6]\tvalid_0's auc: 0.79835\tvalid_0's binary_logloss: 0.520306\n",
      "[LightGBM] [Debug] Re-bagging, using 162681 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[7]\tvalid_0's auc: 0.799984\tvalid_0's binary_logloss: 0.518688\n",
      "[LightGBM] [Debug] Re-bagging, using 163060 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[8]\tvalid_0's auc: 0.799985\tvalid_0's binary_logloss: 0.517798\n",
      "[LightGBM] [Debug] Re-bagging, using 163025 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[9]\tvalid_0's auc: 0.800145\tvalid_0's binary_logloss: 0.516299\n",
      "[LightGBM] [Debug] Re-bagging, using 162888 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[10]\tvalid_0's auc: 0.801608\tvalid_0's binary_logloss: 0.514886\n",
      "[LightGBM] [Debug] Re-bagging, using 162636 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[11]\tvalid_0's auc: 0.801179\tvalid_0's binary_logloss: 0.513899\n",
      "[LightGBM] [Debug] Re-bagging, using 163054 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[12]\tvalid_0's auc: 0.801354\tvalid_0's binary_logloss: 0.513042\n",
      "[LightGBM] [Debug] Re-bagging, using 163165 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[13]\tvalid_0's auc: 0.801695\tvalid_0's binary_logloss: 0.511663\n",
      "[LightGBM] [Debug] Re-bagging, using 162960 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[14]\tvalid_0's auc: 0.802485\tvalid_0's binary_logloss: 0.510168\n",
      "[LightGBM] [Debug] Re-bagging, using 162699 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[15]\tvalid_0's auc: 0.803494\tvalid_0's binary_logloss: 0.508895\n",
      "[LightGBM] [Debug] Re-bagging, using 163262 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[16]\tvalid_0's auc: 0.803884\tvalid_0's binary_logloss: 0.507482\n",
      "[LightGBM] [Debug] Re-bagging, using 162998 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[17]\tvalid_0's auc: 0.803883\tvalid_0's binary_logloss: 0.506351\n",
      "[LightGBM] [Debug] Re-bagging, using 163124 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[18]\tvalid_0's auc: 0.804014\tvalid_0's binary_logloss: 0.505431\n",
      "[LightGBM] [Debug] Re-bagging, using 162914 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[19]\tvalid_0's auc: 0.804202\tvalid_0's binary_logloss: 0.504167\n",
      "[LightGBM] [Debug] Re-bagging, using 163020 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[20]\tvalid_0's auc: 0.804738\tvalid_0's binary_logloss: 0.503595\n",
      "[LightGBM] [Debug] Re-bagging, using 162594 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[21]\tvalid_0's auc: 0.805614\tvalid_0's binary_logloss: 0.502364\n",
      "[LightGBM] [Debug] Re-bagging, using 162771 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[22]\tvalid_0's auc: 0.805693\tvalid_0's binary_logloss: 0.501281\n",
      "[LightGBM] [Debug] Re-bagging, using 162707 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[23]\tvalid_0's auc: 0.805962\tvalid_0's binary_logloss: 0.500045\n",
      "[LightGBM] [Debug] Re-bagging, using 163538 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[24]\tvalid_0's auc: 0.806078\tvalid_0's binary_logloss: 0.498811\n",
      "[LightGBM] [Debug] Re-bagging, using 162899 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[25]\tvalid_0's auc: 0.806647\tvalid_0's binary_logloss: 0.497662\n",
      "[LightGBM] [Debug] Re-bagging, using 163281 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[26]\tvalid_0's auc: 0.806483\tvalid_0's binary_logloss: 0.496519\n",
      "[LightGBM] [Debug] Re-bagging, using 163019 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[27]\tvalid_0's auc: 0.806588\tvalid_0's binary_logloss: 0.495429\n",
      "[LightGBM] [Debug] Re-bagging, using 162511 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[28]\tvalid_0's auc: 0.807051\tvalid_0's binary_logloss: 0.494226\n",
      "[LightGBM] [Debug] Re-bagging, using 162698 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[29]\tvalid_0's auc: 0.8075\tvalid_0's binary_logloss: 0.49306\n",
      "[LightGBM] [Debug] Re-bagging, using 162961 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[30]\tvalid_0's auc: 0.807474\tvalid_0's binary_logloss: 0.491973\n",
      "[LightGBM] [Debug] Re-bagging, using 162870 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[31]\tvalid_0's auc: 0.808155\tvalid_0's binary_logloss: 0.490911\n",
      "[LightGBM] [Debug] Re-bagging, using 162683 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[32]\tvalid_0's auc: 0.80829\tvalid_0's binary_logloss: 0.48979\n",
      "[LightGBM] [Debug] Re-bagging, using 162851 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[33]\tvalid_0's auc: 0.808359\tvalid_0's binary_logloss: 0.488735\n",
      "[LightGBM] [Debug] Re-bagging, using 162632 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[34]\tvalid_0's auc: 0.808511\tvalid_0's binary_logloss: 0.488016\n",
      "[LightGBM] [Debug] Re-bagging, using 162764 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[35]\tvalid_0's auc: 0.808614\tvalid_0's binary_logloss: 0.486991\n",
      "[LightGBM] [Debug] Re-bagging, using 162823 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[36]\tvalid_0's auc: 0.809098\tvalid_0's binary_logloss: 0.486304\n",
      "[LightGBM] [Debug] Re-bagging, using 162949 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[37]\tvalid_0's auc: 0.809376\tvalid_0's binary_logloss: 0.485599\n",
      "[LightGBM] [Debug] Re-bagging, using 162713 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[38]\tvalid_0's auc: 0.809575\tvalid_0's binary_logloss: 0.484551\n",
      "[LightGBM] [Debug] Re-bagging, using 163009 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[39]\tvalid_0's auc: 0.80991\tvalid_0's binary_logloss: 0.483574\n",
      "[LightGBM] [Debug] Re-bagging, using 162855 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[40]\tvalid_0's auc: 0.810531\tvalid_0's binary_logloss: 0.482954\n",
      "[LightGBM] [Debug] Re-bagging, using 163436 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[41]\tvalid_0's auc: 0.810675\tvalid_0's binary_logloss: 0.482305\n",
      "[LightGBM] [Debug] Re-bagging, using 162924 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[42]\tvalid_0's auc: 0.810707\tvalid_0's binary_logloss: 0.481319\n",
      "[LightGBM] [Debug] Re-bagging, using 162915 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[43]\tvalid_0's auc: 0.810672\tvalid_0's binary_logloss: 0.480382\n",
      "[LightGBM] [Debug] Re-bagging, using 162849 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[44]\tvalid_0's auc: 0.811507\tvalid_0's binary_logloss: 0.479437\n",
      "[LightGBM] [Debug] Re-bagging, using 163166 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[45]\tvalid_0's auc: 0.811683\tvalid_0's binary_logloss: 0.478806\n",
      "[LightGBM] [Debug] Re-bagging, using 162843 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[46]\tvalid_0's auc: 0.811895\tvalid_0's binary_logloss: 0.477903\n",
      "[LightGBM] [Debug] Re-bagging, using 162816 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[47]\tvalid_0's auc: 0.811973\tvalid_0's binary_logloss: 0.476992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 162460 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[48]\tvalid_0's auc: 0.812115\tvalid_0's binary_logloss: 0.476207\n",
      "[LightGBM] [Debug] Re-bagging, using 162973 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[49]\tvalid_0's auc: 0.812476\tvalid_0's binary_logloss: 0.475743\n",
      "[LightGBM] [Debug] Re-bagging, using 162839 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[50]\tvalid_0's auc: 0.812737\tvalid_0's binary_logloss: 0.475328\n",
      "[LightGBM] [Debug] Re-bagging, using 162654 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[51]\tvalid_0's auc: 0.81301\tvalid_0's binary_logloss: 0.474477\n",
      "[LightGBM] [Debug] Re-bagging, using 162531 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[52]\tvalid_0's auc: 0.813051\tvalid_0's binary_logloss: 0.473674\n",
      "[LightGBM] [Debug] Re-bagging, using 163098 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[53]\tvalid_0's auc: 0.813121\tvalid_0's binary_logloss: 0.472844\n",
      "[LightGBM] [Debug] Re-bagging, using 162670 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[54]\tvalid_0's auc: 0.813219\tvalid_0's binary_logloss: 0.472008\n",
      "[LightGBM] [Debug] Re-bagging, using 163036 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[55]\tvalid_0's auc: 0.81353\tvalid_0's binary_logloss: 0.471455\n",
      "[LightGBM] [Debug] Re-bagging, using 162752 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[56]\tvalid_0's auc: 0.813571\tvalid_0's binary_logloss: 0.470636\n",
      "[LightGBM] [Debug] Re-bagging, using 163012 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[57]\tvalid_0's auc: 0.813849\tvalid_0's binary_logloss: 0.469785\n",
      "[LightGBM] [Debug] Re-bagging, using 163161 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[58]\tvalid_0's auc: 0.814014\tvalid_0's binary_logloss: 0.469246\n",
      "[LightGBM] [Debug] Re-bagging, using 162776 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[59]\tvalid_0's auc: 0.814106\tvalid_0's binary_logloss: 0.468464\n",
      "[LightGBM] [Debug] Re-bagging, using 163305 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[60]\tvalid_0's auc: 0.814048\tvalid_0's binary_logloss: 0.467714\n",
      "[LightGBM] [Debug] Re-bagging, using 162731 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[61]\tvalid_0's auc: 0.814166\tvalid_0's binary_logloss: 0.466944\n",
      "[LightGBM] [Debug] Re-bagging, using 162882 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[62]\tvalid_0's auc: 0.814619\tvalid_0's binary_logloss: 0.466199\n",
      "[LightGBM] [Debug] Re-bagging, using 163000 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[63]\tvalid_0's auc: 0.814843\tvalid_0's binary_logloss: 0.465656\n",
      "[LightGBM] [Debug] Re-bagging, using 162904 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[64]\tvalid_0's auc: 0.815128\tvalid_0's binary_logloss: 0.464881\n",
      "[LightGBM] [Debug] Re-bagging, using 162617 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[65]\tvalid_0's auc: 0.815305\tvalid_0's binary_logloss: 0.464169\n",
      "[LightGBM] [Debug] Re-bagging, using 162847 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[66]\tvalid_0's auc: 0.815444\tvalid_0's binary_logloss: 0.463483\n",
      "[LightGBM] [Debug] Re-bagging, using 162755 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[67]\tvalid_0's auc: 0.815537\tvalid_0's binary_logloss: 0.462804\n",
      "[LightGBM] [Debug] Re-bagging, using 163053 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[68]\tvalid_0's auc: 0.815741\tvalid_0's binary_logloss: 0.462387\n",
      "[LightGBM] [Debug] Re-bagging, using 162592 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[69]\tvalid_0's auc: 0.815873\tvalid_0's binary_logloss: 0.461703\n",
      "[LightGBM] [Debug] Re-bagging, using 162656 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[70]\tvalid_0's auc: 0.816059\tvalid_0's binary_logloss: 0.46124\n",
      "[LightGBM] [Debug] Re-bagging, using 162523 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[71]\tvalid_0's auc: 0.816219\tvalid_0's binary_logloss: 0.460768\n",
      "[LightGBM] [Debug] Re-bagging, using 162722 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[72]\tvalid_0's auc: 0.816472\tvalid_0's binary_logloss: 0.460124\n",
      "[LightGBM] [Debug] Re-bagging, using 162815 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[73]\tvalid_0's auc: 0.816732\tvalid_0's binary_logloss: 0.459416\n",
      "[LightGBM] [Debug] Re-bagging, using 162659 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[74]\tvalid_0's auc: 0.816789\tvalid_0's binary_logloss: 0.458788\n",
      "[LightGBM] [Debug] Re-bagging, using 162755 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[75]\tvalid_0's auc: 0.816855\tvalid_0's binary_logloss: 0.45813\n",
      "[LightGBM] [Debug] Re-bagging, using 162981 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[76]\tvalid_0's auc: 0.817039\tvalid_0's binary_logloss: 0.457504\n",
      "[LightGBM] [Debug] Re-bagging, using 162818 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[77]\tvalid_0's auc: 0.817178\tvalid_0's binary_logloss: 0.45706\n",
      "[LightGBM] [Debug] Re-bagging, using 162819 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[78]\tvalid_0's auc: 0.81732\tvalid_0's binary_logloss: 0.456459\n",
      "[LightGBM] [Debug] Re-bagging, using 162660 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[79]\tvalid_0's auc: 0.817541\tvalid_0's binary_logloss: 0.45587\n",
      "[LightGBM] [Debug] Re-bagging, using 162907 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[80]\tvalid_0's auc: 0.817744\tvalid_0's binary_logloss: 0.455466\n",
      "[LightGBM] [Debug] Re-bagging, using 163320 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[81]\tvalid_0's auc: 0.818604\tvalid_0's binary_logloss: 0.454955\n",
      "[LightGBM] [Debug] Re-bagging, using 162742 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[82]\tvalid_0's auc: 0.818681\tvalid_0's binary_logloss: 0.454385\n",
      "[LightGBM] [Debug] Re-bagging, using 162827 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[83]\tvalid_0's auc: 0.818778\tvalid_0's binary_logloss: 0.453779\n",
      "[LightGBM] [Debug] Re-bagging, using 162840 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[84]\tvalid_0's auc: 0.818828\tvalid_0's binary_logloss: 0.453196\n",
      "[LightGBM] [Debug] Re-bagging, using 162916 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[85]\tvalid_0's auc: 0.818967\tvalid_0's binary_logloss: 0.452787\n",
      "[LightGBM] [Debug] Re-bagging, using 162610 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[86]\tvalid_0's auc: 0.819109\tvalid_0's binary_logloss: 0.452174\n",
      "[LightGBM] [Debug] Re-bagging, using 163107 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[87]\tvalid_0's auc: 0.819188\tvalid_0's binary_logloss: 0.451636\n",
      "[LightGBM] [Debug] Re-bagging, using 162859 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[88]\tvalid_0's auc: 0.819236\tvalid_0's binary_logloss: 0.451235\n",
      "[LightGBM] [Debug] Re-bagging, using 162232 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[89]\tvalid_0's auc: 0.819303\tvalid_0's binary_logloss: 0.450691\n",
      "[LightGBM] [Debug] Re-bagging, using 163049 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[90]\tvalid_0's auc: 0.819383\tvalid_0's binary_logloss: 0.450123\n",
      "[LightGBM] [Debug] Re-bagging, using 163180 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[91]\tvalid_0's auc: 0.819584\tvalid_0's binary_logloss: 0.449783\n",
      "[LightGBM] [Debug] Re-bagging, using 163110 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[92]\tvalid_0's auc: 0.819691\tvalid_0's binary_logloss: 0.449244\n",
      "[LightGBM] [Debug] Re-bagging, using 162858 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[93]\tvalid_0's auc: 0.819725\tvalid_0's binary_logloss: 0.448698\n",
      "[LightGBM] [Debug] Re-bagging, using 163200 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[94]\tvalid_0's auc: 0.819909\tvalid_0's binary_logloss: 0.448157\n",
      "[LightGBM] [Debug] Re-bagging, using 162902 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[95]\tvalid_0's auc: 0.82011\tvalid_0's binary_logloss: 0.447623\n",
      "[LightGBM] [Debug] Re-bagging, using 163028 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[96]\tvalid_0's auc: 0.820523\tvalid_0's binary_logloss: 0.44725\n",
      "[LightGBM] [Debug] Re-bagging, using 162898 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[97]\tvalid_0's auc: 0.820949\tvalid_0's binary_logloss: 0.446827\n",
      "[LightGBM] [Debug] Re-bagging, using 162595 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[98]\tvalid_0's auc: 0.821008\tvalid_0's binary_logloss: 0.446319\n",
      "[LightGBM] [Debug] Re-bagging, using 162664 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[99]\tvalid_0's auc: 0.821086\tvalid_0's binary_logloss: 0.446032\n",
      "[LightGBM] [Debug] Re-bagging, using 162594 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[100]\tvalid_0's auc: 0.821279\tvalid_0's binary_logloss: 0.445665\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.821279\tvalid_0's binary_logloss: 0.445665\n",
      "[LightGBM] [Info] Number of positive: 51395, number of negative: 181604\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046232\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000159 seconds, init for row-wise cost 0.007027 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 4131\n",
      "[LightGBM] [Info] Number of data points in the train set: 232999, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220580 -> initscore=-1.262288\n",
      "[LightGBM] [Info] Start training from score -1.262288\n",
      "[LightGBM] [Debug] Re-bagging, using 163245 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[1]\tvalid_0's auc: 0.767648\tvalid_0's binary_logloss: 0.525672\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 162876 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[2]\tvalid_0's auc: 0.780786\tvalid_0's binary_logloss: 0.524641\n",
      "[LightGBM] [Debug] Re-bagging, using 162842 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[3]\tvalid_0's auc: 0.779067\tvalid_0's binary_logloss: 0.523504\n",
      "[LightGBM] [Debug] Re-bagging, using 162881 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[4]\tvalid_0's auc: 0.790473\tvalid_0's binary_logloss: 0.521851\n",
      "[LightGBM] [Debug] Re-bagging, using 163017 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[5]\tvalid_0's auc: 0.794216\tvalid_0's binary_logloss: 0.52024\n",
      "[LightGBM] [Debug] Re-bagging, using 163470 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[6]\tvalid_0's auc: 0.796228\tvalid_0's binary_logloss: 0.518947\n",
      "[LightGBM] [Debug] Re-bagging, using 162846 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[7]\tvalid_0's auc: 0.798532\tvalid_0's binary_logloss: 0.517325\n",
      "[LightGBM] [Debug] Re-bagging, using 163285 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[8]\tvalid_0's auc: 0.799236\tvalid_0's binary_logloss: 0.516429\n",
      "[LightGBM] [Debug] Re-bagging, using 163253 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[9]\tvalid_0's auc: 0.799451\tvalid_0's binary_logloss: 0.514962\n",
      "[LightGBM] [Debug] Re-bagging, using 163071 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[10]\tvalid_0's auc: 0.80183\tvalid_0's binary_logloss: 0.513552\n",
      "[LightGBM] [Debug] Re-bagging, using 162854 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[11]\tvalid_0's auc: 0.801743\tvalid_0's binary_logloss: 0.512567\n",
      "[LightGBM] [Debug] Re-bagging, using 163270 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[12]\tvalid_0's auc: 0.80218\tvalid_0's binary_logloss: 0.511721\n",
      "[LightGBM] [Debug] Re-bagging, using 163366 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[13]\tvalid_0's auc: 0.80255\tvalid_0's binary_logloss: 0.510375\n",
      "[LightGBM] [Debug] Re-bagging, using 163178 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[14]\tvalid_0's auc: 0.803419\tvalid_0's binary_logloss: 0.508914\n",
      "[LightGBM] [Debug] Re-bagging, using 162923 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[15]\tvalid_0's auc: 0.804568\tvalid_0's binary_logloss: 0.507643\n",
      "[LightGBM] [Debug] Re-bagging, using 163460 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[16]\tvalid_0's auc: 0.804274\tvalid_0's binary_logloss: 0.506313\n",
      "[LightGBM] [Debug] Re-bagging, using 163166 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 15\n",
      "[17]\tvalid_0's auc: 0.804344\tvalid_0's binary_logloss: 0.505195\n",
      "[LightGBM] [Debug] Re-bagging, using 163321 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[18]\tvalid_0's auc: 0.80448\tvalid_0's binary_logloss: 0.504329\n",
      "[LightGBM] [Debug] Re-bagging, using 163118 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[19]\tvalid_0's auc: 0.804478\tvalid_0's binary_logloss: 0.503062\n",
      "[LightGBM] [Debug] Re-bagging, using 163252 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[20]\tvalid_0's auc: 0.804885\tvalid_0's binary_logloss: 0.502515\n",
      "[LightGBM] [Debug] Re-bagging, using 162807 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[21]\tvalid_0's auc: 0.805808\tvalid_0's binary_logloss: 0.501325\n",
      "[LightGBM] [Debug] Re-bagging, using 162944 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[22]\tvalid_0's auc: 0.80566\tvalid_0's binary_logloss: 0.500264\n",
      "[LightGBM] [Debug] Re-bagging, using 162905 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[23]\tvalid_0's auc: 0.805828\tvalid_0's binary_logloss: 0.499035\n",
      "[LightGBM] [Debug] Re-bagging, using 163703 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[24]\tvalid_0's auc: 0.805893\tvalid_0's binary_logloss: 0.497817\n",
      "[LightGBM] [Debug] Re-bagging, using 163112 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[25]\tvalid_0's auc: 0.806607\tvalid_0's binary_logloss: 0.496682\n",
      "[LightGBM] [Debug] Re-bagging, using 163473 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[26]\tvalid_0's auc: 0.806603\tvalid_0's binary_logloss: 0.495503\n",
      "[LightGBM] [Debug] Re-bagging, using 163232 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[27]\tvalid_0's auc: 0.806895\tvalid_0's binary_logloss: 0.494408\n",
      "[LightGBM] [Debug] Re-bagging, using 162675 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[28]\tvalid_0's auc: 0.806975\tvalid_0's binary_logloss: 0.493235\n",
      "[LightGBM] [Debug] Re-bagging, using 162876 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[29]\tvalid_0's auc: 0.806966\tvalid_0's binary_logloss: 0.492122\n",
      "[LightGBM] [Debug] Re-bagging, using 163158 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[30]\tvalid_0's auc: 0.806684\tvalid_0's binary_logloss: 0.491044\n",
      "[LightGBM] [Debug] Re-bagging, using 163060 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[31]\tvalid_0's auc: 0.80752\tvalid_0's binary_logloss: 0.489949\n",
      "[LightGBM] [Debug] Re-bagging, using 162872 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[32]\tvalid_0's auc: 0.807529\tvalid_0's binary_logloss: 0.488903\n",
      "[LightGBM] [Debug] Re-bagging, using 163057 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[33]\tvalid_0's auc: 0.807438\tvalid_0's binary_logloss: 0.487832\n",
      "[LightGBM] [Debug] Re-bagging, using 162832 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[34]\tvalid_0's auc: 0.807524\tvalid_0's binary_logloss: 0.487139\n",
      "[LightGBM] [Debug] Re-bagging, using 162967 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[35]\tvalid_0's auc: 0.807585\tvalid_0's binary_logloss: 0.486101\n",
      "[LightGBM] [Debug] Re-bagging, using 163011 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[36]\tvalid_0's auc: 0.808118\tvalid_0's binary_logloss: 0.485424\n",
      "[LightGBM] [Debug] Re-bagging, using 163137 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[37]\tvalid_0's auc: 0.808423\tvalid_0's binary_logloss: 0.484721\n",
      "[LightGBM] [Debug] Re-bagging, using 162911 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[38]\tvalid_0's auc: 0.808839\tvalid_0's binary_logloss: 0.483687\n",
      "[LightGBM] [Debug] Re-bagging, using 163178 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[39]\tvalid_0's auc: 0.80909\tvalid_0's binary_logloss: 0.48274\n",
      "[LightGBM] [Debug] Re-bagging, using 163066 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[40]\tvalid_0's auc: 0.80997\tvalid_0's binary_logloss: 0.482091\n",
      "[LightGBM] [Debug] Re-bagging, using 163626 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[41]\tvalid_0's auc: 0.810053\tvalid_0's binary_logloss: 0.481461\n",
      "[LightGBM] [Debug] Re-bagging, using 163121 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[42]\tvalid_0's auc: 0.810111\tvalid_0's binary_logloss: 0.480477\n",
      "[LightGBM] [Debug] Re-bagging, using 163098 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[43]\tvalid_0's auc: 0.810068\tvalid_0's binary_logloss: 0.479537\n",
      "[LightGBM] [Debug] Re-bagging, using 163034 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[44]\tvalid_0's auc: 0.810397\tvalid_0's binary_logloss: 0.478647\n",
      "[LightGBM] [Debug] Re-bagging, using 163376 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[45]\tvalid_0's auc: 0.810628\tvalid_0's binary_logloss: 0.478025\n",
      "[LightGBM] [Debug] Re-bagging, using 163070 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[46]\tvalid_0's auc: 0.810674\tvalid_0's binary_logloss: 0.477112\n",
      "[LightGBM] [Debug] Re-bagging, using 163017 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[47]\tvalid_0's auc: 0.810689\tvalid_0's binary_logloss: 0.476206\n",
      "[LightGBM] [Debug] Re-bagging, using 162679 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[48]\tvalid_0's auc: 0.810641\tvalid_0's binary_logloss: 0.47544\n",
      "[LightGBM] [Debug] Re-bagging, using 163187 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[49]\tvalid_0's auc: 0.810967\tvalid_0's binary_logloss: 0.474997\n",
      "[LightGBM] [Debug] Re-bagging, using 163061 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[50]\tvalid_0's auc: 0.81107\tvalid_0's binary_logloss: 0.474599\n",
      "[LightGBM] [Debug] Re-bagging, using 162859 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[51]\tvalid_0's auc: 0.811866\tvalid_0's binary_logloss: 0.473723\n",
      "[LightGBM] [Debug] Re-bagging, using 162713 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[52]\tvalid_0's auc: 0.812093\tvalid_0's binary_logloss: 0.472928\n",
      "[LightGBM] [Debug] Re-bagging, using 163286 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[53]\tvalid_0's auc: 0.812095\tvalid_0's binary_logloss: 0.472102\n",
      "[LightGBM] [Debug] Re-bagging, using 162894 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[54]\tvalid_0's auc: 0.812075\tvalid_0's binary_logloss: 0.471287\n",
      "[LightGBM] [Debug] Re-bagging, using 163233 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[55]\tvalid_0's auc: 0.812378\tvalid_0's binary_logloss: 0.470742\n",
      "[LightGBM] [Debug] Re-bagging, using 162937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[56]\tvalid_0's auc: 0.812571\tvalid_0's binary_logloss: 0.469946\n",
      "[LightGBM] [Debug] Re-bagging, using 163223 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[57]\tvalid_0's auc: 0.812547\tvalid_0's binary_logloss: 0.469117\n",
      "[LightGBM] [Debug] Re-bagging, using 163387 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[58]\tvalid_0's auc: 0.812723\tvalid_0's binary_logloss: 0.468552\n",
      "[LightGBM] [Debug] Re-bagging, using 162973 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[59]\tvalid_0's auc: 0.812893\tvalid_0's binary_logloss: 0.467747\n",
      "[LightGBM] [Debug] Re-bagging, using 163504 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[60]\tvalid_0's auc: 0.812783\tvalid_0's binary_logloss: 0.466975\n",
      "[LightGBM] [Debug] Re-bagging, using 162922 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[61]\tvalid_0's auc: 0.812846\tvalid_0's binary_logloss: 0.466248\n",
      "[LightGBM] [Debug] Re-bagging, using 163093 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[62]\tvalid_0's auc: 0.813062\tvalid_0's binary_logloss: 0.465513\n",
      "[LightGBM] [Debug] Re-bagging, using 163195 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[63]\tvalid_0's auc: 0.813305\tvalid_0's binary_logloss: 0.464987\n",
      "[LightGBM] [Debug] Re-bagging, using 163127 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[64]\tvalid_0's auc: 0.813588\tvalid_0's binary_logloss: 0.464214\n",
      "[LightGBM] [Debug] Re-bagging, using 162805 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[65]\tvalid_0's auc: 0.81358\tvalid_0's binary_logloss: 0.46348\n",
      "[LightGBM] [Debug] Re-bagging, using 163046 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[66]\tvalid_0's auc: 0.813737\tvalid_0's binary_logloss: 0.462792\n",
      "[LightGBM] [Debug] Re-bagging, using 162954 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[67]\tvalid_0's auc: 0.813828\tvalid_0's binary_logloss: 0.462079\n",
      "[LightGBM] [Debug] Re-bagging, using 163235 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[68]\tvalid_0's auc: 0.814\tvalid_0's binary_logloss: 0.461675\n",
      "[LightGBM] [Debug] Re-bagging, using 162797 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[69]\tvalid_0's auc: 0.814166\tvalid_0's binary_logloss: 0.461008\n",
      "[LightGBM] [Debug] Re-bagging, using 162858 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[70]\tvalid_0's auc: 0.81426\tvalid_0's binary_logloss: 0.460549\n",
      "[LightGBM] [Debug] Re-bagging, using 162712 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[71]\tvalid_0's auc: 0.814359\tvalid_0's binary_logloss: 0.460085\n",
      "[LightGBM] [Debug] Re-bagging, using 162926 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[72]\tvalid_0's auc: 0.814502\tvalid_0's binary_logloss: 0.459482\n",
      "[LightGBM] [Debug] Re-bagging, using 163028 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[73]\tvalid_0's auc: 0.81485\tvalid_0's binary_logloss: 0.458751\n",
      "[LightGBM] [Debug] Re-bagging, using 162843 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[74]\tvalid_0's auc: 0.814925\tvalid_0's binary_logloss: 0.458124\n",
      "[LightGBM] [Debug] Re-bagging, using 162969 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[75]\tvalid_0's auc: 0.815299\tvalid_0's binary_logloss: 0.457392\n",
      "[LightGBM] [Debug] Re-bagging, using 163202 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[76]\tvalid_0's auc: 0.815452\tvalid_0's binary_logloss: 0.456742\n",
      "[LightGBM] [Debug] Re-bagging, using 163009 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[77]\tvalid_0's auc: 0.815788\tvalid_0's binary_logloss: 0.456262\n",
      "[LightGBM] [Debug] Re-bagging, using 163037 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[78]\tvalid_0's auc: 0.815908\tvalid_0's binary_logloss: 0.455657\n",
      "[LightGBM] [Debug] Re-bagging, using 162850 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[79]\tvalid_0's auc: 0.816254\tvalid_0's binary_logloss: 0.455034\n",
      "[LightGBM] [Debug] Re-bagging, using 163119 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[80]\tvalid_0's auc: 0.816458\tvalid_0's binary_logloss: 0.454644\n",
      "[LightGBM] [Debug] Re-bagging, using 163533 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[81]\tvalid_0's auc: 0.817288\tvalid_0's binary_logloss: 0.454145\n",
      "[LightGBM] [Debug] Re-bagging, using 162935 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[82]\tvalid_0's auc: 0.817381\tvalid_0's binary_logloss: 0.453563\n",
      "[LightGBM] [Debug] Re-bagging, using 163025 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[83]\tvalid_0's auc: 0.817529\tvalid_0's binary_logloss: 0.452965\n",
      "[LightGBM] [Debug] Re-bagging, using 163042 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[84]\tvalid_0's auc: 0.817577\tvalid_0's binary_logloss: 0.452369\n",
      "[LightGBM] [Debug] Re-bagging, using 163124 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[85]\tvalid_0's auc: 0.817975\tvalid_0's binary_logloss: 0.451899\n",
      "[LightGBM] [Debug] Re-bagging, using 162788 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[86]\tvalid_0's auc: 0.818031\tvalid_0's binary_logloss: 0.451335\n",
      "[LightGBM] [Debug] Re-bagging, using 163308 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[87]\tvalid_0's auc: 0.8182\tvalid_0's binary_logloss: 0.450803\n",
      "[LightGBM] [Debug] Re-bagging, using 163050 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[88]\tvalid_0's auc: 0.818363\tvalid_0's binary_logloss: 0.450367\n",
      "[LightGBM] [Debug] Re-bagging, using 162425 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[89]\tvalid_0's auc: 0.818456\tvalid_0's binary_logloss: 0.449798\n",
      "[LightGBM] [Debug] Re-bagging, using 163239 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[90]\tvalid_0's auc: 0.818546\tvalid_0's binary_logloss: 0.449214\n",
      "[LightGBM] [Debug] Re-bagging, using 163373 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[91]\tvalid_0's auc: 0.818761\tvalid_0's binary_logloss: 0.448868\n",
      "[LightGBM] [Debug] Re-bagging, using 163319 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[92]\tvalid_0's auc: 0.818842\tvalid_0's binary_logloss: 0.448344\n",
      "[LightGBM] [Debug] Re-bagging, using 163035 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[93]\tvalid_0's auc: 0.818897\tvalid_0's binary_logloss: 0.4478\n",
      "[LightGBM] [Debug] Re-bagging, using 163386 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[94]\tvalid_0's auc: 0.818953\tvalid_0's binary_logloss: 0.447296\n",
      "[LightGBM] [Debug] Re-bagging, using 163089 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[95]\tvalid_0's auc: 0.819089\tvalid_0's binary_logloss: 0.446794\n",
      "[LightGBM] [Debug] Re-bagging, using 163245 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[96]\tvalid_0's auc: 0.819465\tvalid_0's binary_logloss: 0.446417\n",
      "[LightGBM] [Debug] Re-bagging, using 163120 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[97]\tvalid_0's auc: 0.819902\tvalid_0's binary_logloss: 0.445984\n",
      "[LightGBM] [Debug] Re-bagging, using 162777 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[98]\tvalid_0's auc: 0.819994\tvalid_0's binary_logloss: 0.445501\n",
      "[LightGBM] [Debug] Re-bagging, using 162871 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[99]\tvalid_0's auc: 0.820167\tvalid_0's binary_logloss: 0.445213\n",
      "[LightGBM] [Debug] Re-bagging, using 162805 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[100]\tvalid_0's auc: 0.820376\tvalid_0's binary_logloss: 0.444826\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.820376\tvalid_0's binary_logloss: 0.444826\n",
      "[LightGBM] [Info] Number of positive: 51288, number of negative: 181508\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046267\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000083 seconds, init for row-wise cost 0.008115 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4130\n",
      "[LightGBM] [Info] Number of data points in the train set: 232796, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220313 -> initscore=-1.263843\n",
      "[LightGBM] [Info] Start training from score -1.263843\n",
      "[LightGBM] [Debug] Re-bagging, using 163095 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[1]\tvalid_0's auc: 0.77422\tvalid_0's binary_logloss: 0.526938\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 162736 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[2]\tvalid_0's auc: 0.783366\tvalid_0's binary_logloss: 0.525872\n",
      "[LightGBM] [Debug] Re-bagging, using 162703 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[3]\tvalid_0's auc: 0.782443\tvalid_0's binary_logloss: 0.524733\n",
      "[LightGBM] [Debug] Re-bagging, using 162747 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[4]\tvalid_0's auc: 0.791775\tvalid_0's binary_logloss: 0.5231\n",
      "[LightGBM] [Debug] Re-bagging, using 162882 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[5]\tvalid_0's auc: 0.795104\tvalid_0's binary_logloss: 0.521493\n",
      "[LightGBM] [Debug] Re-bagging, using 163338 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[6]\tvalid_0's auc: 0.796921\tvalid_0's binary_logloss: 0.520211\n",
      "[LightGBM] [Debug] Re-bagging, using 162713 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[7]\tvalid_0's auc: 0.799346\tvalid_0's binary_logloss: 0.51859\n",
      "[LightGBM] [Debug] Re-bagging, using 163132 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[8]\tvalid_0's auc: 0.799003\tvalid_0's binary_logloss: 0.517739\n",
      "[LightGBM] [Debug] Re-bagging, using 163074 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[9]\tvalid_0's auc: 0.799528\tvalid_0's binary_logloss: 0.516251\n",
      "[LightGBM] [Debug] Re-bagging, using 162943 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[10]\tvalid_0's auc: 0.801459\tvalid_0's binary_logloss: 0.514897\n",
      "[LightGBM] [Debug] Re-bagging, using 162680 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[11]\tvalid_0's auc: 0.800934\tvalid_0's binary_logloss: 0.51392\n",
      "[LightGBM] [Debug] Re-bagging, using 163135 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[12]\tvalid_0's auc: 0.800669\tvalid_0's binary_logloss: 0.513051\n",
      "[LightGBM] [Debug] Re-bagging, using 163242 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[13]\tvalid_0's auc: 0.800871\tvalid_0's binary_logloss: 0.511673\n",
      "[LightGBM] [Debug] Re-bagging, using 163039 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[14]\tvalid_0's auc: 0.802063\tvalid_0's binary_logloss: 0.51022\n",
      "[LightGBM] [Debug] Re-bagging, using 162743 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[15]\tvalid_0's auc: 0.802679\tvalid_0's binary_logloss: 0.508988\n",
      "[LightGBM] [Debug] Re-bagging, using 163307 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[16]\tvalid_0's auc: 0.802741\tvalid_0's binary_logloss: 0.507595\n",
      "[LightGBM] [Debug] Re-bagging, using 163058 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[17]\tvalid_0's auc: 0.802646\tvalid_0's binary_logloss: 0.506485\n",
      "[LightGBM] [Debug] Re-bagging, using 163179 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[18]\tvalid_0's auc: 0.802466\tvalid_0's binary_logloss: 0.505582\n",
      "[LightGBM] [Debug] Re-bagging, using 162981 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[19]\tvalid_0's auc: 0.802541\tvalid_0's binary_logloss: 0.504297\n",
      "[LightGBM] [Debug] Re-bagging, using 163087 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[20]\tvalid_0's auc: 0.802897\tvalid_0's binary_logloss: 0.503755\n",
      "[LightGBM] [Debug] Re-bagging, using 162649 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[21]\tvalid_0's auc: 0.803826\tvalid_0's binary_logloss: 0.502554\n",
      "[LightGBM] [Debug] Re-bagging, using 162822 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[22]\tvalid_0's auc: 0.803953\tvalid_0's binary_logloss: 0.501471\n",
      "[LightGBM] [Debug] Re-bagging, using 162781 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[23]\tvalid_0's auc: 0.803976\tvalid_0's binary_logloss: 0.500264\n",
      "[LightGBM] [Debug] Re-bagging, using 163598 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[24]\tvalid_0's auc: 0.804248\tvalid_0's binary_logloss: 0.499019\n",
      "[LightGBM] [Debug] Re-bagging, using 162957 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[25]\tvalid_0's auc: 0.804635\tvalid_0's binary_logloss: 0.497921\n",
      "[LightGBM] [Debug] Re-bagging, using 163336 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[26]\tvalid_0's auc: 0.804771\tvalid_0's binary_logloss: 0.496772\n",
      "[LightGBM] [Debug] Re-bagging, using 163068 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[27]\tvalid_0's auc: 0.80513\tvalid_0's binary_logloss: 0.495709\n",
      "[LightGBM] [Debug] Re-bagging, using 162571 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[28]\tvalid_0's auc: 0.805466\tvalid_0's binary_logloss: 0.494538\n",
      "[LightGBM] [Debug] Re-bagging, using 162755 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[29]\tvalid_0's auc: 0.80575\tvalid_0's binary_logloss: 0.49341\n",
      "[LightGBM] [Debug] Re-bagging, using 163005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[30]\tvalid_0's auc: 0.805782\tvalid_0's binary_logloss: 0.492363\n",
      "[LightGBM] [Debug] Re-bagging, using 162938 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[31]\tvalid_0's auc: 0.80623\tvalid_0's binary_logloss: 0.491332\n",
      "[LightGBM] [Debug] Re-bagging, using 162746 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[32]\tvalid_0's auc: 0.806339\tvalid_0's binary_logloss: 0.490275\n",
      "[LightGBM] [Debug] Re-bagging, using 162906 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[33]\tvalid_0's auc: 0.806619\tvalid_0's binary_logloss: 0.489221\n",
      "[LightGBM] [Debug] Re-bagging, using 162696 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[34]\tvalid_0's auc: 0.806635\tvalid_0's binary_logloss: 0.488496\n",
      "[LightGBM] [Debug] Re-bagging, using 162823 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[35]\tvalid_0's auc: 0.806698\tvalid_0's binary_logloss: 0.487436\n",
      "[LightGBM] [Debug] Re-bagging, using 162890 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[36]\tvalid_0's auc: 0.807195\tvalid_0's binary_logloss: 0.48679\n",
      "[LightGBM] [Debug] Re-bagging, using 162978 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[37]\tvalid_0's auc: 0.807356\tvalid_0's binary_logloss: 0.486111\n",
      "[LightGBM] [Debug] Re-bagging, using 162754 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[38]\tvalid_0's auc: 0.807456\tvalid_0's binary_logloss: 0.485106\n",
      "[LightGBM] [Debug] Re-bagging, using 163061 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[39]\tvalid_0's auc: 0.807611\tvalid_0's binary_logloss: 0.484187\n",
      "[LightGBM] [Debug] Re-bagging, using 162939 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[40]\tvalid_0's auc: 0.808207\tvalid_0's binary_logloss: 0.483551\n",
      "[LightGBM] [Debug] Re-bagging, using 163469 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[41]\tvalid_0's auc: 0.808533\tvalid_0's binary_logloss: 0.482883\n",
      "[LightGBM] [Debug] Re-bagging, using 162969 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[42]\tvalid_0's auc: 0.808852\tvalid_0's binary_logloss: 0.481889\n",
      "[LightGBM] [Debug] Re-bagging, using 162981 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[43]\tvalid_0's auc: 0.808792\tvalid_0's binary_logloss: 0.481\n",
      "[LightGBM] [Debug] Re-bagging, using 162888 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[44]\tvalid_0's auc: 0.809039\tvalid_0's binary_logloss: 0.48013\n",
      "[LightGBM] [Debug] Re-bagging, using 163209 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[45]\tvalid_0's auc: 0.809421\tvalid_0's binary_logloss: 0.479473\n",
      "[LightGBM] [Debug] Re-bagging, using 162899 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[46]\tvalid_0's auc: 0.809401\tvalid_0's binary_logloss: 0.478594\n",
      "[LightGBM] [Debug] Re-bagging, using 162872 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[47]\tvalid_0's auc: 0.809492\tvalid_0's binary_logloss: 0.477716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 162542 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[48]\tvalid_0's auc: 0.809541\tvalid_0's binary_logloss: 0.476946\n",
      "[LightGBM] [Debug] Re-bagging, using 163031 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[49]\tvalid_0's auc: 0.809866\tvalid_0's binary_logloss: 0.476505\n",
      "[LightGBM] [Debug] Re-bagging, using 162901 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[50]\tvalid_0's auc: 0.810083\tvalid_0's binary_logloss: 0.4761\n",
      "[LightGBM] [Debug] Re-bagging, using 162714 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[51]\tvalid_0's auc: 0.810318\tvalid_0's binary_logloss: 0.475301\n",
      "[LightGBM] [Debug] Re-bagging, using 162579 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[52]\tvalid_0's auc: 0.810439\tvalid_0's binary_logloss: 0.4745\n",
      "[LightGBM] [Debug] Re-bagging, using 163153 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[53]\tvalid_0's auc: 0.810481\tvalid_0's binary_logloss: 0.473662\n",
      "[LightGBM] [Debug] Re-bagging, using 162733 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[54]\tvalid_0's auc: 0.810476\tvalid_0's binary_logloss: 0.472865\n",
      "[LightGBM] [Debug] Re-bagging, using 163095 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[55]\tvalid_0's auc: 0.810719\tvalid_0's binary_logloss: 0.472327\n",
      "[LightGBM] [Debug] Re-bagging, using 162796 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[56]\tvalid_0's auc: 0.811171\tvalid_0's binary_logloss: 0.471463\n",
      "[LightGBM] [Debug] Re-bagging, using 163068 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[57]\tvalid_0's auc: 0.811458\tvalid_0's binary_logloss: 0.47065\n",
      "[LightGBM] [Debug] Re-bagging, using 163223 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[58]\tvalid_0's auc: 0.811623\tvalid_0's binary_logloss: 0.470114\n",
      "[LightGBM] [Debug] Re-bagging, using 162849 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[59]\tvalid_0's auc: 0.811931\tvalid_0's binary_logloss: 0.469284\n",
      "[LightGBM] [Debug] Re-bagging, using 163377 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[60]\tvalid_0's auc: 0.811849\tvalid_0's binary_logloss: 0.468535\n",
      "[LightGBM] [Debug] Re-bagging, using 162775 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[61]\tvalid_0's auc: 0.811881\tvalid_0's binary_logloss: 0.467811\n",
      "[LightGBM] [Debug] Re-bagging, using 162935 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[62]\tvalid_0's auc: 0.81222\tvalid_0's binary_logloss: 0.467064\n",
      "[LightGBM] [Debug] Re-bagging, using 163054 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[63]\tvalid_0's auc: 0.812462\tvalid_0's binary_logloss: 0.466561\n",
      "[LightGBM] [Debug] Re-bagging, using 162968 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[64]\tvalid_0's auc: 0.812816\tvalid_0's binary_logloss: 0.465769\n",
      "[LightGBM] [Debug] Re-bagging, using 162675 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[65]\tvalid_0's auc: 0.812861\tvalid_0's binary_logloss: 0.465052\n",
      "[LightGBM] [Debug] Re-bagging, using 162922 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[66]\tvalid_0's auc: 0.812987\tvalid_0's binary_logloss: 0.464371\n",
      "[LightGBM] [Debug] Re-bagging, using 162796 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[67]\tvalid_0's auc: 0.813022\tvalid_0's binary_logloss: 0.463686\n",
      "[LightGBM] [Debug] Re-bagging, using 163094 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[68]\tvalid_0's auc: 0.813179\tvalid_0's binary_logloss: 0.463274\n",
      "[LightGBM] [Debug] Re-bagging, using 162649 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[69]\tvalid_0's auc: 0.813338\tvalid_0's binary_logloss: 0.462638\n",
      "[LightGBM] [Debug] Re-bagging, using 162700 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[70]\tvalid_0's auc: 0.813462\tvalid_0's binary_logloss: 0.462188\n",
      "[LightGBM] [Debug] Re-bagging, using 162601 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[71]\tvalid_0's auc: 0.813627\tvalid_0's binary_logloss: 0.461727\n",
      "[LightGBM] [Debug] Re-bagging, using 162798 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[72]\tvalid_0's auc: 0.813955\tvalid_0's binary_logloss: 0.461125\n",
      "[LightGBM] [Debug] Re-bagging, using 162886 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[73]\tvalid_0's auc: 0.814174\tvalid_0's binary_logloss: 0.460416\n",
      "[LightGBM] [Debug] Re-bagging, using 162719 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[74]\tvalid_0's auc: 0.814276\tvalid_0's binary_logloss: 0.459797\n",
      "[LightGBM] [Debug] Re-bagging, using 162824 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[75]\tvalid_0's auc: 0.814464\tvalid_0's binary_logloss: 0.459106\n",
      "[LightGBM] [Debug] Re-bagging, using 163050 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[76]\tvalid_0's auc: 0.814512\tvalid_0's binary_logloss: 0.458486\n",
      "[LightGBM] [Debug] Re-bagging, using 162866 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[77]\tvalid_0's auc: 0.814745\tvalid_0's binary_logloss: 0.457997\n",
      "[LightGBM] [Debug] Re-bagging, using 162884 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[78]\tvalid_0's auc: 0.814887\tvalid_0's binary_logloss: 0.457413\n",
      "[LightGBM] [Debug] Re-bagging, using 162727 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[79]\tvalid_0's auc: 0.815123\tvalid_0's binary_logloss: 0.456818\n",
      "[LightGBM] [Debug] Re-bagging, using 162989 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[80]\tvalid_0's auc: 0.815342\tvalid_0's binary_logloss: 0.456482\n",
      "[LightGBM] [Debug] Re-bagging, using 163381 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[81]\tvalid_0's auc: 0.815951\tvalid_0's binary_logloss: 0.456049\n",
      "[LightGBM] [Debug] Re-bagging, using 162797 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[82]\tvalid_0's auc: 0.816103\tvalid_0's binary_logloss: 0.455477\n",
      "[LightGBM] [Debug] Re-bagging, using 162878 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[83]\tvalid_0's auc: 0.816096\tvalid_0's binary_logloss: 0.454915\n",
      "[LightGBM] [Debug] Re-bagging, using 162899 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[84]\tvalid_0's auc: 0.816209\tvalid_0's binary_logloss: 0.454333\n",
      "[LightGBM] [Debug] Re-bagging, using 162987 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[85]\tvalid_0's auc: 0.816344\tvalid_0's binary_logloss: 0.453934\n",
      "[LightGBM] [Debug] Re-bagging, using 162660 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[86]\tvalid_0's auc: 0.816475\tvalid_0's binary_logloss: 0.453347\n",
      "[LightGBM] [Debug] Re-bagging, using 163158 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[87]\tvalid_0's auc: 0.816674\tvalid_0's binary_logloss: 0.452793\n",
      "[LightGBM] [Debug] Re-bagging, using 162933 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[88]\tvalid_0's auc: 0.816829\tvalid_0's binary_logloss: 0.452381\n",
      "[LightGBM] [Debug] Re-bagging, using 162288 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[89]\tvalid_0's auc: 0.816841\tvalid_0's binary_logloss: 0.451837\n",
      "[LightGBM] [Debug] Re-bagging, using 163112 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[90]\tvalid_0's auc: 0.816921\tvalid_0's binary_logloss: 0.451287\n",
      "[LightGBM] [Debug] Re-bagging, using 163242 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[91]\tvalid_0's auc: 0.817094\tvalid_0's binary_logloss: 0.450955\n",
      "[LightGBM] [Debug] Re-bagging, using 163179 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[92]\tvalid_0's auc: 0.817221\tvalid_0's binary_logloss: 0.450392\n",
      "[LightGBM] [Debug] Re-bagging, using 162921 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[93]\tvalid_0's auc: 0.817291\tvalid_0's binary_logloss: 0.449849\n",
      "[LightGBM] [Debug] Re-bagging, using 163218 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[94]\tvalid_0's auc: 0.817412\tvalid_0's binary_logloss: 0.449303\n",
      "[LightGBM] [Debug] Re-bagging, using 162946 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[95]\tvalid_0's auc: 0.817497\tvalid_0's binary_logloss: 0.448801\n",
      "[LightGBM] [Debug] Re-bagging, using 163078 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[96]\tvalid_0's auc: 0.817969\tvalid_0's binary_logloss: 0.448421\n",
      "[LightGBM] [Debug] Re-bagging, using 162967 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[97]\tvalid_0's auc: 0.818385\tvalid_0's binary_logloss: 0.448006\n",
      "[LightGBM] [Debug] Re-bagging, using 162649 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[98]\tvalid_0's auc: 0.818415\tvalid_0's binary_logloss: 0.447509\n",
      "[LightGBM] [Debug] Re-bagging, using 162723 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 16\n",
      "[99]\tvalid_0's auc: 0.818594\tvalid_0's binary_logloss: 0.447216\n",
      "[LightGBM] [Debug] Re-bagging, using 162649 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[100]\tvalid_0's auc: 0.818719\tvalid_0's binary_logloss: 0.446879\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.818719\tvalid_0's binary_logloss: 0.446879\n",
      "[LightGBM] [Info] Number of positive: 51252, number of negative: 181568\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046238\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000089 seconds, init for row-wise cost 0.008302 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4131\n",
      "[LightGBM] [Info] Number of data points in the train set: 232820, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220136 -> initscore=-1.264876\n",
      "[LightGBM] [Info] Start training from score -1.264876\n",
      "[LightGBM] [Debug] Re-bagging, using 163113 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[1]\tvalid_0's auc: 0.771374\tvalid_0's binary_logloss: 0.527857\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 162750 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[2]\tvalid_0's auc: 0.782783\tvalid_0's binary_logloss: 0.526833\n",
      "[LightGBM] [Debug] Re-bagging, using 162723 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[3]\tvalid_0's auc: 0.782251\tvalid_0's binary_logloss: 0.525662\n",
      "[LightGBM] [Debug] Re-bagging, using 162754 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[4]\tvalid_0's auc: 0.793712\tvalid_0's binary_logloss: 0.524018\n",
      "[LightGBM] [Debug] Re-bagging, using 162909 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[5]\tvalid_0's auc: 0.79602\tvalid_0's binary_logloss: 0.522399\n",
      "[LightGBM] [Debug] Re-bagging, using 163352 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[6]\tvalid_0's auc: 0.798063\tvalid_0's binary_logloss: 0.521056\n",
      "[LightGBM] [Debug] Re-bagging, using 162731 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[7]\tvalid_0's auc: 0.799467\tvalid_0's binary_logloss: 0.519466\n",
      "[LightGBM] [Debug] Re-bagging, using 163143 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[8]\tvalid_0's auc: 0.800051\tvalid_0's binary_logloss: 0.518544\n",
      "[LightGBM] [Debug] Re-bagging, using 163103 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[9]\tvalid_0's auc: 0.80033\tvalid_0's binary_logloss: 0.51703\n",
      "[LightGBM] [Debug] Re-bagging, using 162942 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[10]\tvalid_0's auc: 0.801586\tvalid_0's binary_logloss: 0.51566\n",
      "[LightGBM] [Debug] Re-bagging, using 162721 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[11]\tvalid_0's auc: 0.801041\tvalid_0's binary_logloss: 0.514684\n",
      "[LightGBM] [Debug] Re-bagging, using 163148 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[12]\tvalid_0's auc: 0.801064\tvalid_0's binary_logloss: 0.513775\n",
      "[LightGBM] [Debug] Re-bagging, using 163259 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[13]\tvalid_0's auc: 0.801635\tvalid_0's binary_logloss: 0.512391\n",
      "[LightGBM] [Debug] Re-bagging, using 163028 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[14]\tvalid_0's auc: 0.8023\tvalid_0's binary_logloss: 0.510944\n",
      "[LightGBM] [Debug] Re-bagging, using 162779 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[15]\tvalid_0's auc: 0.803439\tvalid_0's binary_logloss: 0.509687\n",
      "[LightGBM] [Debug] Re-bagging, using 163337 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[16]\tvalid_0's auc: 0.803746\tvalid_0's binary_logloss: 0.508298\n",
      "[LightGBM] [Debug] Re-bagging, using 163067 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[17]\tvalid_0's auc: 0.803654\tvalid_0's binary_logloss: 0.507201\n",
      "[LightGBM] [Debug] Re-bagging, using 163191 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[18]\tvalid_0's auc: 0.803622\tvalid_0's binary_logloss: 0.506294\n",
      "[LightGBM] [Debug] Re-bagging, using 162992 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[19]\tvalid_0's auc: 0.803746\tvalid_0's binary_logloss: 0.505015\n",
      "[LightGBM] [Debug] Re-bagging, using 163108 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[20]\tvalid_0's auc: 0.804246\tvalid_0's binary_logloss: 0.504452\n",
      "[LightGBM] [Debug] Re-bagging, using 162679 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[21]\tvalid_0's auc: 0.80499\tvalid_0's binary_logloss: 0.503234\n",
      "[LightGBM] [Debug] Re-bagging, using 162838 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[22]\tvalid_0's auc: 0.805425\tvalid_0's binary_logloss: 0.502126\n",
      "[LightGBM] [Debug] Re-bagging, using 162793 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[23]\tvalid_0's auc: 0.805662\tvalid_0's binary_logloss: 0.500892\n",
      "[LightGBM] [Debug] Re-bagging, using 163604 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[24]\tvalid_0's auc: 0.805644\tvalid_0's binary_logloss: 0.499688\n",
      "[LightGBM] [Debug] Re-bagging, using 162960 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[25]\tvalid_0's auc: 0.806279\tvalid_0's binary_logloss: 0.498541\n",
      "[LightGBM] [Debug] Re-bagging, using 163357 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[26]\tvalid_0's auc: 0.806186\tvalid_0's binary_logloss: 0.497409\n",
      "[LightGBM] [Debug] Re-bagging, using 163104 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[27]\tvalid_0's auc: 0.806333\tvalid_0's binary_logloss: 0.49633\n",
      "[LightGBM] [Debug] Re-bagging, using 162584 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[28]\tvalid_0's auc: 0.806669\tvalid_0's binary_logloss: 0.495144\n",
      "[LightGBM] [Debug] Re-bagging, using 162778 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[29]\tvalid_0's auc: 0.807151\tvalid_0's binary_logloss: 0.493969\n",
      "[LightGBM] [Debug] Re-bagging, using 163040 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[30]\tvalid_0's auc: 0.807027\tvalid_0's binary_logloss: 0.492902\n",
      "[LightGBM] [Debug] Re-bagging, using 162948 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[31]\tvalid_0's auc: 0.808169\tvalid_0's binary_logloss: 0.491774\n",
      "[LightGBM] [Debug] Re-bagging, using 162747 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[32]\tvalid_0's auc: 0.808393\tvalid_0's binary_logloss: 0.490681\n",
      "[LightGBM] [Debug] Re-bagging, using 162907 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[33]\tvalid_0's auc: 0.808435\tvalid_0's binary_logloss: 0.489637\n",
      "[LightGBM] [Debug] Re-bagging, using 162718 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[34]\tvalid_0's auc: 0.808629\tvalid_0's binary_logloss: 0.48892\n",
      "[LightGBM] [Debug] Re-bagging, using 162827 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[35]\tvalid_0's auc: 0.808548\tvalid_0's binary_logloss: 0.487883\n",
      "[LightGBM] [Debug] Re-bagging, using 162888 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[36]\tvalid_0's auc: 0.808979\tvalid_0's binary_logloss: 0.487206\n",
      "[LightGBM] [Debug] Re-bagging, using 163035 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[37]\tvalid_0's auc: 0.809376\tvalid_0's binary_logloss: 0.486502\n",
      "[LightGBM] [Debug] Re-bagging, using 162781 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[38]\tvalid_0's auc: 0.809689\tvalid_0's binary_logloss: 0.485438\n",
      "[LightGBM] [Debug] Re-bagging, using 163075 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[39]\tvalid_0's auc: 0.809774\tvalid_0's binary_logloss: 0.484486\n",
      "[LightGBM] [Debug] Re-bagging, using 162942 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[40]\tvalid_0's auc: 0.81007\tvalid_0's binary_logloss: 0.483871\n",
      "[LightGBM] [Debug] Re-bagging, using 163475 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[41]\tvalid_0's auc: 0.810231\tvalid_0's binary_logloss: 0.483228\n",
      "[LightGBM] [Debug] Re-bagging, using 162982 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[42]\tvalid_0's auc: 0.810364\tvalid_0's binary_logloss: 0.482255\n",
      "[LightGBM] [Debug] Re-bagging, using 162971 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[43]\tvalid_0's auc: 0.810285\tvalid_0's binary_logloss: 0.481338\n",
      "[LightGBM] [Debug] Re-bagging, using 162919 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[44]\tvalid_0's auc: 0.810526\tvalid_0's binary_logloss: 0.480438\n",
      "[LightGBM] [Debug] Re-bagging, using 163255 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[45]\tvalid_0's auc: 0.810689\tvalid_0's binary_logloss: 0.479785\n",
      "[LightGBM] [Debug] Re-bagging, using 162919 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[46]\tvalid_0's auc: 0.810592\tvalid_0's binary_logloss: 0.478916\n",
      "[LightGBM] [Debug] Re-bagging, using 162876 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47]\tvalid_0's auc: 0.810783\tvalid_0's binary_logloss: 0.478019\n",
      "[LightGBM] [Debug] Re-bagging, using 162561 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[48]\tvalid_0's auc: 0.810804\tvalid_0's binary_logloss: 0.47724\n",
      "[LightGBM] [Debug] Re-bagging, using 163060 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[49]\tvalid_0's auc: 0.811116\tvalid_0's binary_logloss: 0.476816\n",
      "[LightGBM] [Debug] Re-bagging, using 162927 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[50]\tvalid_0's auc: 0.811289\tvalid_0's binary_logloss: 0.476411\n",
      "[LightGBM] [Debug] Re-bagging, using 162720 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[51]\tvalid_0's auc: 0.811776\tvalid_0's binary_logloss: 0.475544\n",
      "[LightGBM] [Debug] Re-bagging, using 162577 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[52]\tvalid_0's auc: 0.811767\tvalid_0's binary_logloss: 0.474752\n",
      "[LightGBM] [Debug] Re-bagging, using 163162 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[53]\tvalid_0's auc: 0.811831\tvalid_0's binary_logloss: 0.473893\n",
      "[LightGBM] [Debug] Re-bagging, using 162749 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[54]\tvalid_0's auc: 0.811893\tvalid_0's binary_logloss: 0.473057\n",
      "[LightGBM] [Debug] Re-bagging, using 163115 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[55]\tvalid_0's auc: 0.812148\tvalid_0's binary_logloss: 0.472506\n",
      "[LightGBM] [Debug] Re-bagging, using 162821 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[56]\tvalid_0's auc: 0.812468\tvalid_0's binary_logloss: 0.471677\n",
      "[LightGBM] [Debug] Re-bagging, using 163086 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[57]\tvalid_0's auc: 0.812767\tvalid_0's binary_logloss: 0.47083\n",
      "[LightGBM] [Debug] Re-bagging, using 163242 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[58]\tvalid_0's auc: 0.81311\tvalid_0's binary_logloss: 0.470279\n",
      "[LightGBM] [Debug] Re-bagging, using 162861 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[59]\tvalid_0's auc: 0.813297\tvalid_0's binary_logloss: 0.469452\n",
      "[LightGBM] [Debug] Re-bagging, using 163398 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 14\n",
      "[60]\tvalid_0's auc: 0.813279\tvalid_0's binary_logloss: 0.468706\n",
      "[LightGBM] [Debug] Re-bagging, using 162804 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[61]\tvalid_0's auc: 0.813317\tvalid_0's binary_logloss: 0.467973\n",
      "[LightGBM] [Debug] Re-bagging, using 162957 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[62]\tvalid_0's auc: 0.813788\tvalid_0's binary_logloss: 0.4672\n",
      "[LightGBM] [Debug] Re-bagging, using 163051 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[63]\tvalid_0's auc: 0.814056\tvalid_0's binary_logloss: 0.466685\n",
      "[LightGBM] [Debug] Re-bagging, using 162982 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[64]\tvalid_0's auc: 0.814284\tvalid_0's binary_logloss: 0.465929\n",
      "[LightGBM] [Debug] Re-bagging, using 162692 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[65]\tvalid_0's auc: 0.814555\tvalid_0's binary_logloss: 0.465144\n",
      "[LightGBM] [Debug] Re-bagging, using 162931 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[66]\tvalid_0's auc: 0.81473\tvalid_0's binary_logloss: 0.464455\n",
      "[LightGBM] [Debug] Re-bagging, using 162838 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[67]\tvalid_0's auc: 0.814795\tvalid_0's binary_logloss: 0.463756\n",
      "[LightGBM] [Debug] Re-bagging, using 163123 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[68]\tvalid_0's auc: 0.814975\tvalid_0's binary_logloss: 0.463331\n",
      "[LightGBM] [Debug] Re-bagging, using 162667 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[69]\tvalid_0's auc: 0.81524\tvalid_0's binary_logloss: 0.462649\n",
      "[LightGBM] [Debug] Re-bagging, using 162738 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[70]\tvalid_0's auc: 0.815335\tvalid_0's binary_logloss: 0.462196\n",
      "[LightGBM] [Debug] Re-bagging, using 162608 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[71]\tvalid_0's auc: 0.815533\tvalid_0's binary_logloss: 0.461709\n",
      "[LightGBM] [Debug] Re-bagging, using 162792 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[72]\tvalid_0's auc: 0.815995\tvalid_0's binary_logloss: 0.461071\n",
      "[LightGBM] [Debug] Re-bagging, using 162907 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[73]\tvalid_0's auc: 0.816271\tvalid_0's binary_logloss: 0.460357\n",
      "[LightGBM] [Debug] Re-bagging, using 162748 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[74]\tvalid_0's auc: 0.816387\tvalid_0's binary_logloss: 0.459735\n",
      "[LightGBM] [Debug] Re-bagging, using 162844 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[75]\tvalid_0's auc: 0.81652\tvalid_0's binary_logloss: 0.459079\n",
      "[LightGBM] [Debug] Re-bagging, using 163061 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[76]\tvalid_0's auc: 0.816595\tvalid_0's binary_logloss: 0.458423\n",
      "[LightGBM] [Debug] Re-bagging, using 162890 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 8\n",
      "[77]\tvalid_0's auc: 0.81667\tvalid_0's binary_logloss: 0.457986\n",
      "[LightGBM] [Debug] Re-bagging, using 162882 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[78]\tvalid_0's auc: 0.816776\tvalid_0's binary_logloss: 0.457378\n",
      "[LightGBM] [Debug] Re-bagging, using 162741 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[79]\tvalid_0's auc: 0.817141\tvalid_0's binary_logloss: 0.456721\n",
      "[LightGBM] [Debug] Re-bagging, using 163003 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[80]\tvalid_0's auc: 0.817359\tvalid_0's binary_logloss: 0.456333\n",
      "[LightGBM] [Debug] Re-bagging, using 163401 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[81]\tvalid_0's auc: 0.817933\tvalid_0's binary_logloss: 0.455895\n",
      "[LightGBM] [Debug] Re-bagging, using 162810 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[82]\tvalid_0's auc: 0.818063\tvalid_0's binary_logloss: 0.45531\n",
      "[LightGBM] [Debug] Re-bagging, using 162894 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[83]\tvalid_0's auc: 0.818138\tvalid_0's binary_logloss: 0.454724\n",
      "[LightGBM] [Debug] Re-bagging, using 162915 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[84]\tvalid_0's auc: 0.818196\tvalid_0's binary_logloss: 0.45414\n",
      "[LightGBM] [Debug] Re-bagging, using 162996 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[85]\tvalid_0's auc: 0.818403\tvalid_0's binary_logloss: 0.453716\n",
      "[LightGBM] [Debug] Re-bagging, using 162684 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[86]\tvalid_0's auc: 0.818549\tvalid_0's binary_logloss: 0.45312\n",
      "[LightGBM] [Debug] Re-bagging, using 163195 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[87]\tvalid_0's auc: 0.818645\tvalid_0's binary_logloss: 0.452565\n",
      "[LightGBM] [Debug] Re-bagging, using 162913 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[88]\tvalid_0's auc: 0.818866\tvalid_0's binary_logloss: 0.452134\n",
      "[LightGBM] [Debug] Re-bagging, using 162310 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 9\n",
      "[89]\tvalid_0's auc: 0.818905\tvalid_0's binary_logloss: 0.451571\n",
      "[LightGBM] [Debug] Re-bagging, using 163126 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[90]\tvalid_0's auc: 0.818945\tvalid_0's binary_logloss: 0.451006\n",
      "[LightGBM] [Debug] Re-bagging, using 163258 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[91]\tvalid_0's auc: 0.819153\tvalid_0's binary_logloss: 0.450646\n",
      "[LightGBM] [Debug] Re-bagging, using 163195 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[92]\tvalid_0's auc: 0.819308\tvalid_0's binary_logloss: 0.450107\n",
      "[LightGBM] [Debug] Re-bagging, using 162932 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 13\n",
      "[93]\tvalid_0's auc: 0.819346\tvalid_0's binary_logloss: 0.44955\n",
      "[LightGBM] [Debug] Re-bagging, using 163259 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 10\n",
      "[94]\tvalid_0's auc: 0.819374\tvalid_0's binary_logloss: 0.449017\n",
      "[LightGBM] [Debug] Re-bagging, using 162980 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[95]\tvalid_0's auc: 0.819522\tvalid_0's binary_logloss: 0.448503\n",
      "[LightGBM] [Debug] Re-bagging, using 163094 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[96]\tvalid_0's auc: 0.819932\tvalid_0's binary_logloss: 0.448108\n",
      "[LightGBM] [Debug] Re-bagging, using 162981 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[97]\tvalid_0's auc: 0.820351\tvalid_0's binary_logloss: 0.447664\n",
      "[LightGBM] [Debug] Re-bagging, using 162645 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 12\n",
      "[98]\tvalid_0's auc: 0.820375\tvalid_0's binary_logloss: 0.447184\n",
      "[LightGBM] [Debug] Re-bagging, using 162736 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[99]\tvalid_0's auc: 0.820459\tvalid_0's binary_logloss: 0.446892\n",
      "[LightGBM] [Debug] Re-bagging, using 162662 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and max_depth = 11\n",
      "[100]\tvalid_0's auc: 0.820618\tvalid_0's binary_logloss: 0.44654\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.820618\tvalid_0's binary_logloss: 0.44654\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id', 'label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 模型及参数的定义\n",
    "    lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  \n",
    "    # 训练模型\n",
    "    lgb_Classfication.fit(train_idx[lgb_cols], train_idx['label'],eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], \n",
    "                          eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_Classfication.predict_proba(valid_idx[lgb_cols], \n",
    "                                                              num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "    # 对输出结果进行归一化 分类模型输出的值本身就是一个概率值不需要进行归一化\n",
    "    # valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_Classfication.predict_proba(tst_user_item_feats_df_rank_model[lgb_cols], \n",
    "                                                     num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_cls_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_cls_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:24:23.074237Z",
     "start_time": "2020-11-18T04:24:13.812284Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户的历史点击行为列表\n",
    "这个是为后面的DIN模型服务的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:24:30.508213Z",
     "start_time": "2020-11-18T04:24:27.426372Z"
    }
   },
   "outputs": [],
   "source": [
    "if offline:\n",
    "    all_data = pd.read_csv('./data_raw/train_click_log.csv')\n",
    "else:\n",
    "    trn_data = pd.read_csv('./data_raw/train_click_log.csv')\n",
    "    tst_data = pd.read_csv('./data_raw/testA_click_log.csv')\n",
    "    all_data = trn_data.append(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:25:28.082071Z",
     "start_time": "2020-11-18T04:24:33.649524Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbe = LabelEncoder()\n",
    "all_data['click_article_id'] = lbe.fit_transform(all_data['click_article_id'].values)\n",
    "\n",
    "hist_click =all_data[['user_id', 'click_article_id']].groupby('user_id').agg({list}).reset_index()\n",
    "his_behavior_df = pd.DataFrame()\n",
    "his_behavior_df['user_id'] = hist_click['user_id']\n",
    "his_behavior_df['hist_click_article_id'] = hist_click['click_article_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:25:52.925866Z",
     "start_time": "2020-11-18T04:25:52.863922Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df.copy()\n",
    "else: \n",
    "    val_user_item_feats_df_din_model = None\n",
    "    \n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:26:00.070681Z",
     "start_time": "2020-11-18T04:25:56.417197Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')\n",
    "else:\n",
    "    val_user_item_feats_df_din_model = None\n",
    "\n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIN模型简介\n",
    "我们下面尝试使用DIN模型， DIN的全称是Deep Interest Network， 这是阿里2018年基于前面的深度学习模型无法表达用户多样化的兴趣而提出的一个模型， 它可以通过考虑【给定的候选广告】和【用户的历史行为】的相关性，来计算用户兴趣的表示向量。具体来说就是通过引入局部激活单元，通过软搜索历史行为的相关部分来关注相关的用户兴趣，并采用加权和来获得有关候选广告的用户兴趣的表示。与候选广告相关性较高的行为会获得较高的激活权重，并支配着用户兴趣。该表示向量在不同广告上有所不同，大大提高了模型的表达能力。所以该模型对于此次新闻推荐的任务也比较适合， 我们在这里通过当前的候选文章与用户历史点击文章的相关性来计算用户对于文章的兴趣。 该模型的结构如下：\n",
    "\n",
    "![image-20201116201646983](http://ryluo.oss-cn-chengdu.aliyuncs.com/abc/image-20201116201646983.png)\n",
    "\n",
    "\n",
    "我们这里直接调包来使用这个模型， 关于这个模型的详细细节部分我们会在下一期的推荐系统组队学习中给出。下面说一下该模型如何具体使用：deepctr的函数原型如下：\n",
    "> def DIN(dnn_feature_columns, history_feature_list, dnn_use_bn=False,\n",
    ">        dnn_hidden_units=(200, 80), dnn_activation='relu', att_hidden_size=(80, 40), att_activation=\"dice\",\n",
    ">       att_weight_normalization=False, l2_reg_dnn=0, l2_reg_embedding=1e-6, dnn_dropout=0, seed=1024,\n",
    ">        task='binary'):\n",
    "> \n",
    "> * dnn_feature_columns: 特征列， 包含数据所有特征的列表\n",
    "> * history_feature_list: 用户历史行为列， 反应用户历史行为的特征的列表\n",
    "> * dnn_use_bn: 是否使用BatchNormalization\n",
    "> * dnn_hidden_units: 全连接层网络的层数和每一层神经元的个数， 一个列表或者元组\n",
    "> * dnn_activation_relu: 全连接网络的激活单元类型\n",
    "> * att_hidden_size: 注意力层的全连接网络的层数和每一层神经元的个数\n",
    "> * att_activation: 注意力层的激活单元类型\n",
    "> * att_weight_normalization: 是否归一化注意力得分\n",
    "> * l2_reg_dnn: 全连接网络的正则化系数\n",
    "> * l2_reg_embedding: embedding向量的正则化稀疏\n",
    "> * dnn_dropout: 全连接网络的神经元的失活概率\n",
    "> * task: 任务， 可以是分类， 也可是是回归\n",
    "\n",
    "在具体使用的时候， 我们必须要传入特征列和历史行为列， 但是再传入之前， 我们需要进行一下特征列的预处理。具体如下：\n",
    "\n",
    "1. 首先，我们要处理数据集， 得到数据， 由于我们是基于用户过去的行为去预测用户是否点击当前文章， 所以我们需要把数据的特征列划分成数值型特征， 离散型特征和历史行为特征列三部分， 对于每一部分， DIN模型的处理会有不同\n",
    "    1. 对于离散型特征， 在我们的数据集中就是那些类别型的特征， 比如user_id这种， 这种类别型特征， 我们首先要经过embedding处理得到每个特征的低维稠密型表示， 既然要经过embedding， 那么我们就需要为每一列的类别特征的取值建立一个字典，并指明embedding维度， 所以在使用deepctr的DIN模型准备数据的时候， 我们需要通过SparseFeat函数指明这些类别型特征, 这个函数的传入参数就是列名， 列的唯一取值(建立字典用)和embedding维度。\n",
    "    2. 对于用户历史行为特征列， 比如文章id， 文章的类别等这种， 同样的我们需要先经过embedding处理， 只不过和上面不一样的地方是，对于这种特征， 我们在得到每个特征的embedding表示之后， 还需要通过一个Attention_layer计算用户的历史行为和当前候选文章的相关性以此得到当前用户的embedding向量， 这个向量就可以基于当前的候选文章与用户过去点击过得历史文章的相似性的程度来反应用户的兴趣， 并且随着用户的不同的历史点击来变化，去动态的模拟用户兴趣的变化过程。这类特征对于每个用户都是一个历史行为序列， 对于每个用户， 历史行为序列长度会不一样， 可能有的用户点击的历史文章多，有的点击的历史文章少， 所以我们还需要把这个长度统一起来， 在为DIN模型准备数据的时候， 我们首先要通过SparseFeat函数指明这些类别型特征， 然后还需要通过VarLenSparseFeat函数再进行序列填充， 使得每个用户的历史序列一样长， 所以这个函数参数中会有个maxlen，来指明序列的最大长度是多少。\n",
    "    3. 对于连续型特征列， 我们只需要用DenseFeat函数来指明列名和维度即可。\n",
    "2. 处理完特征列之后， 我们把相应的数据与列进行对应，就得到了最后的数据。\n",
    "\n",
    "下面根据具体的代码感受一下， 逻辑是这样， 首先我们需要写一个数据准备函数， 在这里面就是根据上面的具体步骤准备数据， 得到数据和特征列， 然后就是建立DIN模型并训练， 最后基于模型进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:26:08.405211Z",
     "start_time": "2020-11-18T04:26:04.887013Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入deepctr\n",
    "from deepctr.models import DIN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import * \n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:26:13.485712Z",
     "start_time": "2020-11-18T04:26:13.476042Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据准备函数\n",
    "def get_din_feats_columns(df, dense_fea, sparse_fea, behavior_fea, his_behavior_fea, emb_dim=32, max_len=100):\n",
    "    \"\"\"\n",
    "    数据准备函数:\n",
    "    df: 数据集\n",
    "    dense_fea: 数值型特征列\n",
    "    sparse_fea: 离散型特征列\n",
    "    behavior_fea: 用户的候选行为特征列\n",
    "    his_behavior_fea: 用户的历史行为特征列\n",
    "    embedding_dim: embedding的维度， 这里为了简单， 统一把离散型特征列采用一样的隐向量维度\n",
    "    max_len: 用户序列的最大长度\n",
    "    \"\"\"\n",
    "    \n",
    "    sparse_feature_columns = [SparseFeat(feat, vocabulary_size=df[feat].nunique() + 1, embedding_dim=emb_dim) \n",
    "                              for feat in sparse_fea]\n",
    "    \n",
    "    dense_feature_columns = [DenseFeat(feat, 1, ) for feat in dense_fea]\n",
    "    \n",
    "    var_feature_columns = [VarLenSparseFeat(SparseFeat(feat, vocabulary_size=df['click_article_id'].nunique() + 1,\n",
    "                                    embedding_dim=emb_dim, embedding_name='click_article_id'), maxlen=max_len) \n",
    "                           for feat in hist_behavior_fea]\n",
    "    \n",
    "    dnn_feature_columns = sparse_feature_columns + dense_feature_columns + var_feature_columns\n",
    "    \n",
    "    # 建立x, x是一个字典的形式\n",
    "    x = {}\n",
    "    for name in get_feature_names(dnn_feature_columns):\n",
    "        if name in his_behavior_fea:\n",
    "            # 这是历史行为序列\n",
    "            his_list = [l for l in df[name]]\n",
    "            x[name] = pad_sequences(his_list, maxlen=max_len, padding='post')      # 二维数组\n",
    "        else:\n",
    "            lbe = LabelEncoder()\n",
    "            x[name] = lbe.fit_transform(df[name].values)\n",
    "            \n",
    "#             x[name] = df[name].values\n",
    "    \n",
    "    return x, dnn_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:26:18.783217Z",
     "start_time": "2020-11-18T04:26:18.776795Z"
    }
   },
   "outputs": [],
   "source": [
    "# 把特征分开\n",
    "sparse_fea = ['user_id', 'click_article_id', 'category_id', 'click_environment', 'click_deviceGroup', \n",
    "              'click_os', 'click_country', 'click_region', 'click_referrer_type', 'is_cat_hab']\n",
    "\n",
    "behavior_fea = ['click_article_id']\n",
    "\n",
    "hist_behavior_fea = ['hist_click_article_id']\n",
    "\n",
    "dense_fea = ['sim0', 'time_diff0', 'word_diff0', 'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'score',\n",
    "             'rank','click_size','time_diff_mean','active_level','user_time_hob1','user_time_hob2',\n",
    "             'words_hbo','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:26:25.469810Z",
     "start_time": "2020-11-18T04:26:24.779347Z"
    }
   },
   "outputs": [],
   "source": [
    "# dense特征进行归一化, 神经网络训练都需要将数值进行归一化处理\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "# 下面是做一些特殊处理，当在其他的地方出现无效值的时候，不处理无法进行归一化，刚开始可以先把他注释掉，在运行了下面的代码\n",
    "# 之后如果发现报错，应该先去想办法处理如何不出现inf之类的值\n",
    "# trn_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "# tst_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "for feat in dense_fea:\n",
    "    trn_user_item_feats_df_din_model[feat] = mm.fit_transform(trn_user_item_feats_df_din_model[[feat]])\n",
    "    \n",
    "    if val_user_item_feats_df_din_model is not None:\n",
    "        val_user_item_feats_df_din_model[feat] = mm.fit_transform(val_user_item_feats_df_din_model[[feat]])\n",
    "    \n",
    "    tst_user_item_feats_df_din_model[feat] = mm.fit_transform(tst_user_item_feats_df_din_model[[feat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:26:36.727753Z",
     "start_time": "2020-11-18T04:26:28.854705Z"
    }
   },
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "x_trn, dnn_feature_columns = get_din_feats_columns(trn_user_item_feats_df_din_model, dense_fea, \n",
    "                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "y_trn = trn_user_item_feats_df_din_model['label'].values\n",
    "\n",
    "if offline:\n",
    "    # 准备验证数据\n",
    "    x_val, dnn_feature_columns = get_din_feats_columns(val_user_item_feats_df_din_model, dense_fea, \n",
    "                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "    y_val = val_user_item_feats_df_din_model['label'].values\n",
    "    \n",
    "dense_fea = [x for x in dense_fea if x != 'label']\n",
    "x_tst, dnn_feature_columns = get_din_feats_columns(tst_user_item_feats_df_din_model, dense_fea, \n",
    "                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:26:45.146318Z",
     "start_time": "2020-11-18T04:26:40.423914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer_2/local_activation_unit_2/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer_2/local_activation_unit_2/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_article_id (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_id (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_environment (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_deviceGroup (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_os (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_country (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_region (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_referrer_type (InputLayer [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "is_cat_hab (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 32)        1600032     user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sparse_seq_emb_hist_click_artic multiple             525664      click_article_id[0][0]           \n",
      "                                                                 hist_click_article_id[0][0]      \n",
      "                                                                 click_article_id[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_category_id (Embeddi (None, 1, 32)        7776        category_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_environment (E (None, 1, 32)        128         click_environment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_deviceGroup (E (None, 1, 32)        160         click_deviceGroup[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_os (Embedding) (None, 1, 32)        288         click_os[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_country (Embed (None, 1, 32)        384         click_country[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_region (Embedd (None, 1, 32)        928         click_region[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_referrer_type  (None, 1, 32)        256         click_referrer_type[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_is_cat_hab (Embeddin (None, 1, 32)        64          is_cat_hab[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_10 (NoMask)             (None, 1, 32)        0           sparse_emb_user_id[0][0]         \n",
      "                                                                 sparse_seq_emb_hist_click_article\n",
      "                                                                 sparse_emb_category_id[0][0]     \n",
      "                                                                 sparse_emb_click_environment[0][0\n",
      "                                                                 sparse_emb_click_deviceGroup[0][0\n",
      "                                                                 sparse_emb_click_os[0][0]        \n",
      "                                                                 sparse_emb_click_country[0][0]   \n",
      "                                                                 sparse_emb_click_region[0][0]    \n",
      "                                                                 sparse_emb_click_referrer_type[0]\n",
      "                                                                 sparse_emb_is_cat_hab[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hist_click_article_id (InputLay [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1, 320)       0           no_mask_10[0][0]                 \n",
      "                                                                 no_mask_10[1][0]                 \n",
      "                                                                 no_mask_10[2][0]                 \n",
      "                                                                 no_mask_10[3][0]                 \n",
      "                                                                 no_mask_10[4][0]                 \n",
      "                                                                 no_mask_10[5][0]                 \n",
      "                                                                 no_mask_10[6][0]                 \n",
      "                                                                 no_mask_10[7][0]                 \n",
      "                                                                 no_mask_10[8][0]                 \n",
      "                                                                 no_mask_10[9][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_11 (NoMask)             (None, 1, 320)       0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_sequence_pooling_laye (None, 1, 32)        13961       sparse_seq_emb_hist_click_article\n",
      "                                                                 sparse_seq_emb_hist_click_article\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1, 352)       0           no_mask_11[0][0]                 \n",
      "                                                                 attention_sequence_pooling_layer_\n",
      "__________________________________________________________________________________________________\n",
      "sim0 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_diff0 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_diff0 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_max (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_min (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_sum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_mean (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "score (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rank (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_size (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_diff_mean (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "active_level (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_time_hob1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_time_hob2 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "words_hbo (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "words_count (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 352)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_13 (NoMask)             (None, 1)            0           sim0[0][0]                       \n",
      "                                                                 time_diff0[0][0]                 \n",
      "                                                                 word_diff0[0][0]                 \n",
      "                                                                 sim_max[0][0]                    \n",
      "                                                                 sim_min[0][0]                    \n",
      "                                                                 sim_sum[0][0]                    \n",
      "                                                                 sim_mean[0][0]                   \n",
      "                                                                 score[0][0]                      \n",
      "                                                                 rank[0][0]                       \n",
      "                                                                 click_size[0][0]                 \n",
      "                                                                 time_diff_mean[0][0]             \n",
      "                                                                 active_level[0][0]               \n",
      "                                                                 user_time_hob1[0][0]             \n",
      "                                                                 user_time_hob2[0][0]             \n",
      "                                                                 words_hbo[0][0]                  \n",
      "                                                                 words_count[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_12 (NoMask)             (None, 352)          0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16)           0           no_mask_13[0][0]                 \n",
      "                                                                 no_mask_13[1][0]                 \n",
      "                                                                 no_mask_13[2][0]                 \n",
      "                                                                 no_mask_13[3][0]                 \n",
      "                                                                 no_mask_13[4][0]                 \n",
      "                                                                 no_mask_13[5][0]                 \n",
      "                                                                 no_mask_13[6][0]                 \n",
      "                                                                 no_mask_13[7][0]                 \n",
      "                                                                 no_mask_13[8][0]                 \n",
      "                                                                 no_mask_13[9][0]                 \n",
      "                                                                 no_mask_13[10][0]                \n",
      "                                                                 no_mask_13[11][0]                \n",
      "                                                                 no_mask_13[12][0]                \n",
      "                                                                 no_mask_13[13][0]                \n",
      "                                                                 no_mask_13[14][0]                \n",
      "                                                                 no_mask_13[15][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 352)          0           no_mask_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 16)           0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_14 (NoMask)             multiple             0           flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 368)          0           no_mask_14[0][0]                 \n",
      "                                                                 no_mask_14[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dnn_2 (DNN)                     (None, 80)           89880       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            80          dnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "prediction_layer_2 (PredictionL (None, 1)            1           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,239,602\n",
      "Trainable params: 2,239,362\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立模型\n",
    "model = DIN(dnn_feature_columns, behavior_fea)\n",
    "\n",
    "# 查看模型结构\n",
    "model.summary()\n",
    "\n",
    "# 模型编译\n",
    "model.compile('adam', 'binary_crossentropy',metrics=['binary_crossentropy', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "(291070,)\n",
      "\n",
      "click_article_id\n",
      "(291070,)\n",
      "\n",
      "category_id\n",
      "(291070,)\n",
      "\n",
      "click_environment\n",
      "(291070,)\n",
      "\n",
      "click_deviceGroup\n",
      "(291070,)\n",
      "\n",
      "click_os\n",
      "(291070,)\n",
      "\n",
      "click_country\n",
      "(291070,)\n",
      "\n",
      "click_region\n",
      "(291070,)\n",
      "\n",
      "click_referrer_type\n",
      "(291070,)\n",
      "\n",
      "is_cat_hab\n",
      "(291070,)\n",
      "\n",
      "sim0\n",
      "(291070,)\n",
      "\n",
      "time_diff0\n",
      "(291070,)\n",
      "\n",
      "word_diff0\n",
      "(291070,)\n",
      "\n",
      "sim_max\n",
      "(291070,)\n",
      "\n",
      "sim_min\n",
      "(291070,)\n",
      "\n",
      "sim_sum\n",
      "(291070,)\n",
      "\n",
      "sim_mean\n",
      "(291070,)\n",
      "\n",
      "score\n",
      "(291070,)\n",
      "\n",
      "rank\n",
      "(291070,)\n",
      "\n",
      "click_size\n",
      "(291070,)\n",
      "\n",
      "time_diff_mean\n",
      "(291070,)\n",
      "\n",
      "active_level\n",
      "(291070,)\n",
      "\n",
      "user_time_hob1\n",
      "(291070,)\n",
      "\n",
      "user_time_hob2\n",
      "(291070,)\n",
      "\n",
      "words_hbo\n",
      "(291070,)\n",
      "\n",
      "words_count\n",
      "(291070,)\n",
      "\n",
      "hist_click_article_id\n",
      "(291070, 50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in x_trn.items():\n",
    "    print(k)\n",
    "    print(v.shape)\n",
    "    print()\n",
    "\n",
    "# len(y_trn)\n",
    "\n",
    "# type(x_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2342, 16104,     0, ...,     0,     0,     0],\n",
       "       [  241, 30021, 16049, ...,     0,     0,     0],\n",
       "       [  241, 30021, 16049, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 3299,  3177, 15226, ...,     0,     0,     0],\n",
       "       [ 6869,  6972,     0, ...,     0,     0,     0],\n",
       "       [27293, 29946,     0, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trn['hist_click_article_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16426"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbe = LabelEncoder()\n",
    "r = lbe.fit_transform(x_tst['click_article_id'])\n",
    "\n",
    "len(pd.Series(r).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    226880\n",
      "1.0     64190\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y_trn).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291070\n"
     ]
    }
   ],
   "source": [
    "print(len(y_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:28:43.885773Z",
     "start_time": "2020-11-18T04:26:48.746787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[165,0] = 33113 is not in [0, 16427)\n\t [[node functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup_2 (defined at <ipython-input-110-a1ddaec98eb8>:7) ]]\n  (1) Invalid argument:  indices[165,0] = 33113 is not in [0, 16427)\n\t [[node functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup_2 (defined at <ipython-input-110-a1ddaec98eb8>:7) ]]\n\t [[gradient_tape/functional_5/sparse_emb_user_id/embedding_lookup/VariableShape/_10]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_15714]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup_2:\n functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup/13949 (defined at /home/wangxs/anaconda3/lib/python3.6/contextlib.py:81)\n\nInput Source operations connected to node functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup_2:\n functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup/13949 (defined at /home/wangxs/anaconda3/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-a1ddaec98eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 也可以使用上面的语句用自己采样出来的验证集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# history = model.fit(x_trn, y_trn, verbose=1, epochs=3, validation_split=0.3, batch_size=256)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[165,0] = 33113 is not in [0, 16427)\n\t [[node functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup_2 (defined at <ipython-input-110-a1ddaec98eb8>:7) ]]\n  (1) Invalid argument:  indices[165,0] = 33113 is not in [0, 16427)\n\t [[node functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup_2 (defined at <ipython-input-110-a1ddaec98eb8>:7) ]]\n\t [[gradient_tape/functional_5/sparse_emb_user_id/embedding_lookup/VariableShape/_10]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_15714]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup_2:\n functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup/13949 (defined at /home/wangxs/anaconda3/lib/python3.6/contextlib.py:81)\n\nInput Source operations connected to node functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup_2:\n functional_5/sparse_seq_emb_hist_click_article_id/embedding_lookup/13949 (defined at /home/wangxs/anaconda3/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "if offline:\n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=10, validation_data=(x_val, y_val) , batch_size=256)\n",
    "else:\n",
    "    # 也可以使用上面的语句用自己采样出来的验证集\n",
    "    # history = model.fit(x_trn, y_trn, verbose=1, epochs=3, validation_split=0.3, batch_size=256)\n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:29:20.436591Z",
     "start_time": "2020-11-18T04:28:58.102057Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df_din_model['pred_score'] = model.predict(x_tst, verbose=1, batch_size=256)\n",
    "tst_user_item_feats_df_din_model[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'din_rank_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:29:34.985535Z",
     "start_time": "2020-11-18T04:29:26.264531Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df_din_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "submit(rank_results, topk=5, model_name='din')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T06:15:49.490705Z",
     "start_time": "2020-11-15T06:15:49.473794Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:38:53.760383Z",
     "start_time": "2020-11-18T04:29:51.737721Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_din_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id', 'label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "dense_fea = [x for x in dense_fea if x != 'label']\n",
    "x_tst, dnn_feature_columns = get_din_feats_columns(tst_user_item_feats_df_din_model, dense_fea, \n",
    "                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 准备训练数据\n",
    "    x_trn, dnn_feature_columns = get_din_feats_columns(train_idx, dense_fea, \n",
    "                                                       sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "    y_trn = train_idx['label'].values\n",
    "\n",
    "    # 准备验证数据\n",
    "    x_val, dnn_feature_columns = get_din_feats_columns(valid_idx, dense_fea, \n",
    "                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "    y_val = valid_idx['label'].values\n",
    "    \n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=2, validation_data=(x_val, y_val) , batch_size=256)\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = model.predict(x_val, verbose=1, batch_size=256)   \n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += model.predict(x_tst, verbose=1, batch_size=256)[:, 0]   \n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_din_cls_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_din_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_din_model['pred_score'] = tst_user_item_feats_df_din_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_din_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_din_model['pred_rank'] = tst_user_item_feats_df_din_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_din_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_din_cls_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:44:27.351996Z",
     "start_time": "2020-11-18T04:44:26.561275Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取多个模型的排序结果文件\n",
    "lgb_ranker = pd.read_csv(save_path + 'lgb_ranker_score.csv')\n",
    "lgb_cls = pd.read_csv(save_path + 'lgb_cls_score.csv')\n",
    "din_ranker = pd.read_csv(save_path + 'din_rank_score.csv')\n",
    "\n",
    "# 这里也可以换成交叉验证输出的测试结果进行加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:44:31.593981Z",
     "start_time": "2020-11-18T04:44:31.589439Z"
    }
   },
   "outputs": [],
   "source": [
    "rank_model = {'lgb_ranker': lgb_ranker, \n",
    "              'lgb_cls': lgb_cls, \n",
    "              'din_ranker': din_ranker}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:44:36.135860Z",
     "start_time": "2020-11-18T04:44:36.130577Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ensumble_predict_topk(rank_model, topk=5):\n",
    "    final_recall = rank_model['lgb_cls'].append(rank_model['din_ranker'])\n",
    "    rank_model['lgb_ranker']['pred_score'] = rank_model['lgb_ranker']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    final_recall = final_recall.append(rank_model['lgb_ranker'])\n",
    "    final_recall = final_recall.groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "    \n",
    "    submit(final_recall, topk=topk, model_name='ensemble_fuse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:44:51.659270Z",
     "start_time": "2020-11-18T04:44:40.445659Z"
    }
   },
   "outputs": [],
   "source": [
    "get_ensumble_predict_topk(rank_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:44:58.025992Z",
     "start_time": "2020-11-18T04:44:56.146962Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取多个模型的交叉验证生成的结果文件\n",
    "# 训练集\n",
    "trn_lgb_ranker_feats = pd.read_csv(save_path + 'trn_lgb_ranker_feats.csv')\n",
    "trn_lgb_cls_feats = pd.read_csv(save_path + 'trn_lgb_cls_feats.csv')\n",
    "trn_din_cls_feats = pd.read_csv(save_path + 'trn_din_cls_feats.csv')\n",
    "\n",
    "# 测试集\n",
    "tst_lgb_ranker_feats = pd.read_csv(save_path + 'tst_lgb_ranker_feats.csv')\n",
    "tst_lgb_cls_feats = pd.read_csv(save_path + 'tst_lgb_cls_feats.csv')\n",
    "tst_din_cls_feats = pd.read_csv(save_path + 'tst_din_cls_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:45:07.701862Z",
     "start_time": "2020-11-18T04:45:07.644335Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将多个模型输出的特征进行拼接\n",
    "\n",
    "finall_trn_ranker_feats = trn_lgb_ranker_feats[['user_id', 'click_article_id', 'label']]\n",
    "finall_tst_ranker_feats = tst_lgb_ranker_feats[['user_id', 'click_article_id']]\n",
    "\n",
    "for idx, trn_model in enumerate([trn_lgb_ranker_feats, trn_lgb_cls_feats, trn_din_cls_feats]):\n",
    "    for feat in [ 'pred_score', 'pred_rank']:\n",
    "        col_name = feat + '_' + str(idx)\n",
    "        finall_trn_ranker_feats[col_name] = trn_model[feat]\n",
    "\n",
    "for idx, tst_model in enumerate([tst_lgb_ranker_feats, tst_lgb_cls_feats, tst_din_cls_feats]):\n",
    "    for feat in [ 'pred_score', 'pred_rank']:\n",
    "        col_name = feat + '_' + str(idx)\n",
    "        finall_tst_ranker_feats[col_name] = tst_model[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:45:15.044242Z",
     "start_time": "2020-11-18T04:45:13.138252Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义一个逻辑回归模型再次拟合交叉验证产生的特征对测试集进行预测\n",
    "# 这里需要注意的是，在做交叉验证的时候可以构造多一些与输出预测值相关的特征，来丰富这里简单模型的特征\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "feat_cols = ['pred_score_0', 'pred_rank_0', 'pred_score_1', 'pred_rank_1', 'pred_score_2', 'pred_rank_2']\n",
    "\n",
    "trn_x = finall_trn_ranker_feats[feat_cols]\n",
    "trn_y = finall_trn_ranker_feats['label']\n",
    "\n",
    "tst_x = finall_tst_ranker_feats[feat_cols]\n",
    "\n",
    "# 定义模型\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 模型训练\n",
    "lr.fit(trn_x, trn_y)\n",
    "\n",
    "# 模型预测\n",
    "finall_tst_ranker_feats['pred_score'] = lr.predict_proba(tst_x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T04:45:29.018764Z",
     "start_time": "2020-11-18T04:45:19.423130Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = finall_tst_ranker_feats[['user_id', 'click_article_id', 'pred_score']]\n",
    "submit(rank_results, topk=5, model_name='ensumble_staking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "本章主要学习了三个排序模型，包括LGB的Rank， LGB的Classifier还有深度学习的DIN模型， 当然，对于这三个模型的原理部分，我们并没有给出详细的介绍， 请大家课下自己探索原理，也欢迎大家把自己的探索与所学分享出来，我们一块学习和进步。最后，我们进行了简单的模型融合策略，包括简单的加权和Stacking。\n",
    "\n",
    "关于Datawhale： Datawhale是一个专注于数据科学与AI领域的开源组织，汇集了众多领域院校和知名企业的优秀学习者，聚合了一群有开源精神和探索精神的团队成员。Datawhale 以“for the learner，和学习者一起成长”为愿景，鼓励真实地展现自我、开放包容、互信互助、敢于试错和勇于担当。同时 Datawhale 用开源的理念去探索开源内容、开源学习和开源方案，赋能人才培养，助力人才成长，建立起人与人，人与知识，人与企业和人与未来的联结。 本次数据挖掘路径学习，专题知识将在天池分享，详情可关注Datawhale：\n",
    "\n",
    "![image-20201119112159065](http://ryluo.oss-cn-chengdu.aliyuncs.com/abc/image-20201119112159065.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "170px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
